\documentclass[10pt,a4paper]{report}
\usepackage[a4paper,left=25mm,right=25mm,top=25mm,bottom=20mm]{geometry}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{graphicx}
\graphicspath{{./images/}}
\usepackage{csquotes}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{epstopdf}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{listings, xcolor}
\usepackage{witharrows}
\usepackage{color}
\usepackage{listings}

\begin{document}

\clearpage
%\input{cover}

\tableofcontents

\chapter{Peer to Peer Systems}


\section{Introduction}
\iffalse
\label{sec:introduction}
\textbf{Assessment}: final project with oral examination (questions on topics not covered by projects and discussion of projects). The release date of the project is supposed to be in May, 2023.
New topic/project type this new: the introduction of cross-chain and syde-chain (\textit{e.g. Polygon}). The standard project include develop a DApp or a Smart Contract over a blockchain or testnet.

Two main parts of the course:
\begin{itemize}
	\item 
	\textit{First part (mid march)}: basics (DHT and IPFS)
	\item 
	\textit{Second part (March to end)}: common data structure and mechanism in Bitcoin and Eth blockchain (\textit{with introduction of Proof of Stake in ETH}). For each topic we will see \textit{distributed algorithms, cyptography and probabilistic data structure}.
\end{itemize}
\subsubsection{Detailed program}\label{sec:detailed-program}\begin{itemize}
	\item 
	\textbf{Overlay network}: allows to create a network abstraction at application level. There are two types:
	\begin{itemize}
		\item 
		\textbf{Unstructured overlays}: Flooding Random Walk, epidemic protocols
		\item 
		\textbf{Structured overlays}: DHT, Kademlia (\textit{under the hood of BitTorrent, ETH P2P Network, IPFS}).
	\end{itemize}
	\item 
	\textbf{IPFS (Interplanetary File System)}
	\item 
	\textbf{Cryptographic and DS}: Bloom Filter, Merkle trees Merkle Patricia tries, cryptographic accumulators, Zero-Knowledge proofs (\textit{ZK-Snarks: Zokrates}).
	\item 
	\textbf{Consensus Protocol}: Nakamoto Consensus Proof of Work, Proof of Stake, Byzantine agreement, Practical Byzantine Fault Tolerance.
	\item 
	\textbf{Bitcoin}: Structure of transaction and blocks, consensus, double spending, P2P Network, wallet and weight clients, \textit{pseudo-anonymity (fast introduction, no time)} .
	\item 
	\textbf{Ethereum}: differences to BTC, smart contract with Solidty (\textit{gas, pitfails and hazards}).
	\item 
	\textbf{Blockchains scalability}: Lightning Network, cross-chain protocols
\end{itemize}
\fi
The client server paradigms is charaterized by the two component:
\begin{itemize}
	\item 
	\textbf{Client}: runs on end-host with an on/off behaviour. Is usually a service consumer that issues requests and do not communicate directly. Surely need to known the server IP address and never communicate each other.
	\item 
	\textbf{Server}: it's the service provider that receive requests and satisfy all clients requested.
\end{itemize}

\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230222120810.png}
	\caption{P2P Topology}
	\label{p2p-schema}
\end{figure}

\subsubsection{Peer-to-peer systems}\label{sec:peer-to-peer-systems}
Differently, in \textbf{peer to peer}, we have onyl a single component: the \textbf{Peer}
A \textbf{peer} runs on end-host, have a dynamic behaviour (enter/exit che network continously). The peer usually need to join a network: can be a problem because, differently from server, we don't have a fix static IP address to join or connect. \\
We need to connect to a node already in the net: in the scenario pictured in \ref{p2p-schema} we indicate it as \textbf{S} (\textit{Server}) that is used to \textbf{boostrap} the network. It's an entrypoin to the network of peers: following to the peer's joins the server can be "detacthed" or deleted.\\
Peer needs also to discover each other: use a \textit{gossip protocol} to discover and connenct two different peers: this allows the peers to provide and consume services each other, acting both as a provider and consumers based on each peer offered/requested service.
There is also the need to defines \textbf{communicaton rules} to prevent, for example, \textit{free riding} (\textit{the problem in which we provide a service without nothing in exchange}) and incentivate participation and reciprocation.

As a first definition of P2P, we can state that:
"\textit{A peer to peer system is a set of \textbf{autonomous entities} (peers) able to \textbf{auto-organize} and sharing a set of distributed resources in a computer network. The system exploits such resources to give a service in a \textbf{complete or partial decentralized way}}"

The resources that can be \textbf{shared} are:
\begin{itemize}
	\item 
	Ledgers
	\item 
	Storage Space (\textit{e.g. Distributed File System})
	\item 
	\textbf{Computing power}
	\item 
	\textbf{Bandwitdth}
\end{itemize}

A more refined definition of P2P is:
"\textit{A P2P system is a distributed system defined by a set on nodes interconnected able to \textbf{auto-organize} and to build different topologies with the goal of \textbf{sharing resources} like CPU cycles, memory, bandwidth. The system is able to adapt to a \textbf{continous churn} of the nodes maintaining connectivity and reasonable performances without a centralized entity (like a server)}"
\subsubsection{History case: Napster}
\label{sec:history-case-napster}
The download of the content was based on P2P but the index for search the content was centralized: the following evolutions that give birth to service like Gnutella, FastTrack, or BitTorrent have also search and content trasfer entirely completely distributed.
So P2P cient acts like \textbf{servlet}: a peer behaves like a web server and the user that want to download a file behaves as a client.
\subsection{Blockchain definitions}
\label{sec:blockchain-definitions}
The \textbf{\#1 definition} is:
"\textit{A shared database stored in multiple copies on computers throughout the world and is maintained without the need for a central authority (e.g. a bank, a government, Google, etc.)}"

Seems like a classical distributed database, which take to the \textbf{\#2 definition}:
"\textit{replicated and consistent, \textbf{immutable}, append-only data storage system resistant to tampering}".\\
The \textbf{\#3 definition} is the complete definition:\\
"A write-only, decentralized, state machine that is maintained by untrusted
actors, secured by economic incentive in which the data cannot be deleted and cannot be shut down or censored. It supports defined operations agreed upon by participants that may not known each other and are \textbf{untrusted} but act in their best interect according to rules that incentivizes partecipation".
\\
The blockchain store the transaction: what is exactly the semantic of this transanction depends in the nature/purpose of the application. At high level, the \textbf{basics step of the blockchain process} are the following:
\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.60] {images/Pasted image 20230224141628.png}
	\caption{Blockchain overview working scheme}
\end{figure}

\subsection{Ethereum overview}\label{sec:ethereum-overview}
Implement smart contracts based on protocols that use a blockckahin: they use a Turing-complete languages like  \textit{Solidity} or \textit{Serpent}. The smart contract is executed by all nodes as the consensus algorithm is used to obtain an agreement between every node of the network on the result of the computation.

The \textbf{Ethereum blockchain} introduces smart contract that can be executed by blockchain's nodes: differently from Bitcoin where th script have only limited computational power, in Eth they can solve any computational problem (Turing-completeness). To avoid some sort of \textbf{Denial of Service} the concept of \textit{gas fees} is used. See the section \ref{chap:ethereum} for more information.\\

Generally, we can identify a \textbf{taxonomy} for the blockchains that can be charaterized along 2 axis: \textbf{Permissionless vs Permissioned} and \textbf{Public vs Private}, detailed in \ref{fig:taxonomy}:
\begin{figure}
	\centering
	\includegraphics[scale=0.70]{images/Pasted image 20230224142730.png}
	\caption{Classification of blockchains}
	\label{fig:taxonomy}
\end{figure}

In this context, for \textit{scalability} we means the number of transaction that can be confirmed/immutable registered in an unit of time.

To understand the \textbf{target scenario} for using a blockchain we must consider several elements. As an example, applications that require shared common, append-only database with limit capacity, based on specific necessity, as referred in \ref{diagram1}:
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230224144251.png}
	\caption{Flow to identify a target scenario}
	\label{diagram1}
\end{figure}


There are some advantages on using P2P, like exploiting computation resources in excess like idle CPU cycles to have in return other resources or service from network's nodes.
There is a shift of paradigms in blockchain that is concretely represented by its scientific challenges: the classic old metholodigies for the development of distributed system cannot be exploited in a context with million of nodes so classical alg/technique do not scale on networks of this size.
System dynamically and of those size needs new tools like \textit{consensus algorithms, cryptographic distributed techniques, complex system analysis tools and strategier for the peer cooperation (Nash equilibrium).}

With \textbf{blockchain trilemma} we mean a big scientific challenge in which reside the optimal equilibrium between scalability, security and high level of decentralization. Those three properties are the desiredata from those systems but are not easy to gain because, for e.g., BTC is high security and high decentralized but it's low scalable.
\clearpage

\section{P2P Overlay Network}\label{sec:p2p-overlays---unstructured-overlays}


\subsubsection{Napster/Gnutella overview}\label{sec:napstergnutella-overview}
The basic idea of \textit{Napster} was to outsource the storage and exchange of files to the users so most of the service was provided by users themselves. Napster was able to locate the users that can provide the file while the server was only an index of contents.

In a simplified scenario, Napster was a P2P music file sharing with a centralized index server or \textit{Master server} with several peers: a peer get the index of contents from the master server with the address/reference to all the peers which have the desired information.
There were pros of this system like the \textbf{resource sharing} in which every node pays its pariticpation by providing access to its resources. Also some cons are corcerned with the \textbf{centralization point} that still exists and were represented by the master server, which is a single point of failure.

\textbf{Gnutella} as Napster was a distributed, irregular network of peers without a central authority or server: the connections between the node define an \textbf{overlay network}. Peers establish \textbf{non transient direct (e.g. TCP connections) connection} between themselves: they broadcast a query throught the virtual connection of the overlay network.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.70]{images/Pasted image 20230224151453.png}
	\caption{Gnutella network topology}
\end{figure}


As for Napster, the main pros was that there was no additional infrastructure, no administration and not a single point of failure but was an high network traffic with possibility of free riding.
\subsection{Overlay Network}\label{sec:overlay-network}
We define an overlay network as a \textit{logical network} build on top of a physical network. Overlay links are \textbf{tunnels} through the underlying network: each logical link may correspond to a set of physical links and may transverse of a set of a router. (\textit{See \ref{p2p-overlay}}).
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230224151810.png}
	\caption{General overlay network schema}
	\label{p2p-overlay}
\end{figure}


The three main types of overlay network and an hybrid type as pictured in \ref{overlay-taxonomy}:
	\begin{itemize}
		\item \textit{Unstructured overlay}
		\item \textit{Structured overlay}
		\item \textit{SuperPeer}
	\end{itemize}
\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230224152607.png}
	\caption{Overlay network taxonomy}
	\label{overlay-taxonomy}
\end{figure}

A \textbf{P2P protocol} defines a set of messages that the peers exchange, their format and semantics and it's usually defined over the P2P overlay.
All P2P protocols shares common charateristics, like:
\begin{itemize}
	\item 
	Define a routing strategy at application level of stack TCP/IP stack
	\item 
	Identification of the peer through \textbf{unique identifiers} which are usually computed by an hash function. Particular \textit{cryptographic hashing function} allows to reduce the collision of uuid generated.
	\item 
	Charaterized by a header and payload like packets at IP level
\end{itemize}
\subsection{Unstruncured overlays}
\label{sec:unstruncured-overlays}
In an \textbf{unstructured overlay network} peers are arbitrarly connected: the resulting overlay network is unstructured and make use of \textbf{look-up algorithms} by flooding the network with queries, expading the ring and use a random walk (\textit{for example, see later}). \\
There are pros like \textit{easy to code/mantain},\textit{high resiliency} and some cons like \textbf{high lookup cost} that usually are linear in n (\textit{n = \#nodes})  due to an absence of centralization authority (\textit{like an index in Napster}) and \textbf{low scalability}.
Some example of unstructured network are \textit{Gnutella (v.04), BitTorrent (use DHT) and Bitcoin.}


\paragraph{Gnutella: a case of unstructured P2P overlay network}
\label{sec:gnutella-a-case-of-unstructured-p2p-overlay-network}
The basic idea is it that propagates the query to the network, \textbf{flooding} it: there was no index information used. The connection between peers are defined \textbf{at random}: the node that requested the content choose randomly the nodes that have the desired content. The established connection for transfering content is closed after finishing so it's transient, differently from the connections used to query the nodes that are \textbf{permanent}.
Gnutella protocol includes some TTL, representing a constrained on the area of network the query is propagated, limiting the node reacheable from the source: this can cause false negative but it's not reacheable from the requester.

Some general problem related to P2P network are, for example on \textbf{how to boostrap the network} or \textbf{how to find content without a central index}.
The first problem on bootstrapping can be solved as pictured in \ref{gnutella-p2p}:  a new joining peer can be boostrapped by a third component called \textbf{repository} that provide the peer descriptors by querying known DNS servers storing the IP address of a set of stable peers (\textit{which are always on the network}). It's also widely used an \textbf{intenal cache} mechanism in which each client stores the IP address of peers contacted in the current and previous sessions: the cache can be dynamically update by gossiping with neighbour peers to drop addresses of nodes that exited the network.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.70]{images/Pasted image 20230224154330.png}
	\caption{Bootstrapping nodes without authority centralization}
	\label{gnutella-p2p}
\end{figure}

Let's deep dive into a \textbf{Network Discovery}  for an \textit{unstructured P2P Network} in which the network topology is tipycally random. The \textbf{Network Discovery} follows those steps:
\begin{itemize}
	\item 
	\textbf{Step 0}: join the network
	\item 
	\textbf{Step 1}: determine “who is on the network” by “ping” message to announce your presence on the network so other peers can respond with a “pong” message and also forward your “ping” to other already connected peers. A pong packet also contains info on the peer sending it, allowing two not-directly connected peers to communicate.
	\item 
	\textbf{Step 2}: after established a connection with a set of peers, the searching is possible by sending a  "\textit{query}"  that asks other peer for some content: an example of a query packet “do you have any content that matches the string “\textit{Back to Black?}””. In unstructured network, the querying is executed by broadcasting, implementing a sort of \textbf{flooding}. By receiving the query peers check to see if they have matches and respond (if they have matches), otherwise send packet to connected peers if not to verify if other peers can answer the given query.
	\item 
	\textbf{Step 3}: downloading when the desired resource is founded. The content transfer use \textbf{direct connections using HTTP's GET method}.
\end{itemize}

The described steps are applied to the scenario pictured in \ref{flooding-scenario}: the schema refers the \textit{ping-pong} protocol in \textit{Gnutella}. In this schema the \textit{TTL - Time To Live} is used to limit flooding: when TTL is equal to 0 is discarded.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230225085817.png}
	\caption{Broadcasting request by flooding}
	\label{flooding-scenario}
\end{figure}


.
\subsubsection{Searching by flooding}\label{sec:searching-by-flooding}
For the first case, consider the scenario pictured in \ref{peer-conn}. The connection between the peers (\textit{black one}) are \textbf{stable} while the red one is only used for transfer content through an HTTP connection. Finally, the \textbf{blue connections} are used to forward query to their neighbours.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230301111905.png}
	\caption{Distinction of connection}
	\label{peer-conn}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230301112043.png}
	\caption{Base scenario: Red node search red content, same for yellow}
	\label{search-eg1}
\end{figure}

In the pictured scenario of \ref{search-eg1} scenario, red node are searching for red content and yellow node are searching for yellow content: usually there are multiple copies of content for redundancy purpose.
By \textbf{flooding}, as pictured in \ref{search-eg1-flooding}, they are able to detect some of the content they're interested: some of the copies are not finded due to the use of TTL tgat limits the number of nodes to query.
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230301112212.png}
	\caption{Node visited after flooding}
	\label{search-eg1-flooding}
\end{figure}

When the content is found on a node, the protocol allows to implement \textit{backward routing} to the original node that executed the request and carried the information to connect directly to the node and transfer the content. This poses a problem due to \textit{backward routing} mechanism: each node needs to mantain a table and usually an huge number of connesions on the requester (\textit{node S}) is not suitable for scalable networks.\\
The use of TTL can also result in \textbf{false negatives} due to the limit on the number of hops setted by TTL: this also reduce scalability on the entire network.
So \textbf{backward routing} is used to reply messagge through the \textit{non-transient} connections.
\\
Making a parallelism with a \textit{bitcoin transaction}, we have to connect (or we are) a full node (enabled and with the full blockchain data) and to add a transaction, perform the \textit{flooding} to all nodes to propagate this transaction in the P2P net underlying the blockchain.\\
Many popular P2P network are \textit{unstructued} and use \textbf{flooding}: so overlay is used for content detection and use a direct HTTP connection for content download.
\subsubsection{Expanding ring/Iterative deepening}\label{sec:expanding-ringiterative-deepening}
It's a method to avoid TTL to limit and possible not finding the content: the key diea is to use a \textbf{sequence of flood with increasing TTL}. Follows those steps:
\begin{enumerate}
	\item 
	Choose a ratio of the neighbors (\textit{random subset}) or all of them
	\item 
	Start a BFS with a low TTL value
	\item 
	If the search is not successuffl, repeat BFS at increasing depth by increasing TTL
	
\end{enumerate}
\subsubsection{Random walk / Drunkard's walk}\label{sec:random-walk--drunkards-walk}
The key idea is to build a path by taking succesive steps in random directions: the path is described by a \textit{Markov chain} so previous states are irrelevant for predicting the subsequent state. The probability of distribution of the future state is a function of the present state alone.
\\
Another version if based on sending out \textbf{k query message} to an equal number of randomly chosen neighbors: is called \textbf{K-Random Walk}. Each step follows each own path by choosing one neighboard to forward it and still the TTL s used to stop the search. Each path is called a \textbf{walker}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230301113813.png}
	\caption{Drunkard's walk example}
	\label{drunkard-walk}
\end{figure}


The routing is a \textbf{content-based routing} so the searching is driven by particular hash data structure (\textit{See DHT}). %todo add ref to DHT sec/chapter
There are two main methods to \textit{terminate each walker}:
\begin{itemize}
	\item 
	Based on TTL
	\item 
	Checking methods like walkers periodcailly check with the query source if the stop condition has been met.
	There are approaches in which the nodes are not choosen randomly but probabilistic information are used to direct to high degree neighbor: this allows to tune the probability yo choose a neighbor and drive the searching to \textit{good} neighbos (\textit{the one with the desired content}).
\end{itemize}


\subsection{Structured P2P overlay}\label{sec:structured-p2p-overlay-intro}
In this type of overlay network, the choice of neighbors is defined according to a given criteria so the resulting overlay is \textbf{structured}.\\
This approach tends to guarantee \textit{scalability}: it use a \textit{key-based} loopkup, the network structure guarantees that the lookup of information has a complexity of $log(n)$ and this complxity is also guaranteed for peers joins.
\subsubsection{Hierarchical overlays}\label{sec:hierarchical-overlays}
We have two different of peers: \textbf{peers} and \textbf{super-peers}. The simple peers are connected to super-peers, super-peers are connected each other: they usually have high bandwith and better performance respect to simple peers. Super-peers are used for indexing the resources and usually the flooding is restricted only to them, so too the content trasnfer was limited between super-peers.\\
The revolutionary part of this schema in Gnutella and Skype is that the \textbf{election} of super peer was automatic: in Gnutella there was a concept of \textit{self-promotion}, in Skype ultrapeers are statically defined.

\subsubsection{Overlay classification summary}
\label{sec:overlay-classification-summary}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230301115346.png}
	\caption{Overlay classification summary}
	\label{overlay-summary}
\end{figure}

As pictured in \ref{overlay-summary}, in \textit{DHT - Distribute Hash Table} the complexities are represented by mantaining the fixed structure, considering also the join/leave of the peers that can give more churn an lose the given fixed structure and the   theoretical cost of operations.



\section{Distribute Hash Tables: Chord}\label{sec:introduction-to-distributed-hash-tables}
The problem of retrieve content in P2P network can be summarized by asking where the information should be stoed and how to find it without a centralized server.
In this scenario, the action to carried out are two:
\begin{itemize}
	\item 
	\textbf{Searching}: search guided by the value of a set of attributes of the content
	\item 
	\textbf{Addressing}: pair \textbf{unique identifier ID} to the content and use ID to retrieve it. Usually the \textbf{id} is the \textbf{hash of the content} obtained from applying a cryptographic function (\textbf{e.g. SHA}) that return a \textbf{fixed-length identifier}.
	Surely the pros are the efficient object detection, the cons are the complexities of mantaining the addressing structure.
	In this scenario, those two action allows to drive towards a distributed network content like \textbf{IPFS}.
\end{itemize}
The \textit{motivation} that pushed DHT are implied by the following two different way to find a solution to the previous two points of \textit{searching} and \textit{addressing} the content:
\begin{itemize}
	\item 
	\textbf{Centralized approach}: a server that index the data. The search time will be $O(1)$ and the spare required is $O(N)$ with \textit{N =  Amount of shared content} and also complex query are easily managed.
	\item 
	\textbf{Fully Distributed Approach}: in an unstructured network, the \textbf{search worst-case} is $O(N^{2})$ because each node contact each of its neighbours. Despite this, optimizations can be done by using \textbf{TTL or identifiers to avoid cyclic paths}, obtaining a serach cost of $O(N)$.
	Also the space required is $O(1)$ because does not depend on the number of nodes in the system so no data structure to route queries (\textbf{by flooding}).
\end{itemize}

The key idea behing DHT is to use an \textbf{hash table} that have a $O(log(n))$ number of entries and allows to retrieve data in $O(log(n))$, avoid false negative and it's suitable for self-organizing systems with an high dynamic of node that leave/join. A sketch of the previous evaluation is pictured in \ref{dht-diagram-rationale}.

\begin{figure}[h]
 	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230301120652.png}
	\caption{DHT rationale: trade-off between communication overhead and scalability}
	\label{dht-diagram-rationale}
\end{figure}

\subsubsection{Memcached}\label{sec:memcached}
Memcached is a distributed memory-object caching system for dynamic web caching: a pool of caching server to provide fast access to information. This allows to reduce database server load so acces to the database only on cache misses. It's implemented by splitting an hash table in serveral parts hosted by differents server so to bypass memory limitation of a single computer.
\subsection{Scaling out - Distribute Hashing}\label{sec:scaling-out---distribute-hashing}
The key idea is split the hash table into several parts and distribute it to several servers: use \textbf{hash of resources (or URLs of resources)} allows to map them to a dynamically changing set of web caches. So the URL's \textbf{hash} is the key to access the content and the chosen cryptographic function allow to map the key to a single server. Each machine (user) can locally compute which cache should contain the required resource, referenced by an URL (\textbf{this avoid inter-cache communication}).

The \textbf{rehashing problem} describe how manage the system in case of distributed hash table: in case failure of one server the content of this server is lost so it's not suitable for large data chunk that need to be moved or \textbf{remapped} each failure. \\
Let's make an example: suppose to have as cryptographic hash function a classical hash function that support 4 caching nodes. Store the resource with URL \textit{x} at the cache, implies calculate:
\begin{center}
	\textit{SHA(x)  $\rightarrow$ ID-160 bit \% 4 $\rightarrow$ Cache ID}
\end{center}

Now, if the storage gets bigger so suppose to add more $2$ caches: with $6$ caches, need to recalculate where all the URLs are stored. The only URL stored on the same node as before are those were:
\begin{center}
	\textit{SHA(URL) mod 4 == SHA(URL) mod 6}
\end{center}
so with 10 buckets, and 1000 keys abot 99\% percent of keys have to be remapped and this implies an huge data traffic load on nodes.\\
To partially solve this problem, we can evaluate the \textbf{consistent hashing} method. It's an hash techniques that guarantees that adding/remove nodes allows to remove/move a small percentange of full data.\\
The idea is to \textbf{map a contigous interval of hash values} to the same node, not a set of sparse value. To map an interval to a node, in addition to hashing the name of the object (\textbf{whenever they're URLs or IP addresses}), it's necessary to also hash the names of the nodes in same space (\textbf{same space means to the same co-domain; the identifier of a node is obtained by hashing their IP addresses}).
The distribution scheme does not depend directly on the number of servers: each node manages an \textbf{interval of consecutive hash keys} and not a set of sparse keys. Intervals are \textbf{joined/splitted} when nodes join/leave the network and key ridistributed between adjacent peers.
\subsubsection{Chord: construct a DHT}\label{sec:chord-construct-a-dht}



Chord is a DHT which uses a  \textbf{logical ring} as the data structure to distribute the contents.
Use a logical name space, called \textbf{identifier name space} consistiting of identifiers ${0,1,2,,....n}$ : they are defined as a logical ring \textbf{modulo} \textit{n}.
Every node picks a \textbf{random identifier} through \textbf{hash $H$}, used both for nodes and content.

The picture in \ref{ring-map} shows how nodes are mapped in the ring: each node also has a \textbf{successor} to it thus the successor can be defined via function \texttt{succ(NUMBER)}.  The parameter \texttt{NUMBER} belongs to the hashes set. The successor is the next hash in \textbf{clockwise direction.}
\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230303114227.png}
	\caption{Chord logical ring}
	\label{ring-map}.
\end{figure}


The actual content is mapped to the ring but in case the hash does not correspond to a node, it is mapped to the node \textbf{subsequent} to it \ref{mapping-content}. As one node is \textbf{removed from the network, its content is remapped to its successor}, as showed in \ref{remapped-ring}.


\begin{figure}
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{images/Pasted image 20230303114328.png}
		\caption{Initial mapping}
		\label{mapping-content}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.8\linewidth]{images/Pasted image 20230303114352.png}
		\caption{Remapping the content}
		\label{remapped-ring}
	\end{subfigure}
	\caption{Chord logical ring}
	\label{chord-logical-ring}
\end{figure}



Instead of remapping all the keys, only the key of a leaving node are remapped so having $n$ number of servers and $k$ number of keys, the ones to be remapped are $k/n$ on average.
\subsection{Node Join}\label{sec:node-join}
As for the \textbf{introduction of the new nodes}, inserting a new node brings the \textbf{issue of remapping some of the content hashed between its successor and predecessor}. The following figures show the crown moving from 11 to 10, as 10 joins the network. As the successor of 9 now becomes 10 instead of 11.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230303114516.png}
	\caption{Joining node sketch}
	\label{chord-join}
\end{figure}


There is the distinction of two types of leaves from the network:
\begin{itemize}
	\item 
	\textbf{Voluntary leave}: in this case all the content stored on the node is redistributed. All the other nodes remove it from their routing table.
	\item 
	\textbf{Node failure}: to prevent any content loss that can happen in this case, there is the use of \textbf{data replication} to add redundancy to the ring. The routing tables are updated periodically by exploring the routing paths and finding offline nodes.
	
\end{itemize}
In a \textbf{voluntary leave}, for a node there is the partitioning of its address space to the neighbouring nodes.

\subsection{Lookup}\label{sec:lookup}
Lookup for nodes only connected to one node (\textbf{who is its}) successor in the \textbf{routing table} is seen in the pseudocode pictured in \ref{alg-ID}.\\
The lookup is recursive, the nodes which the query is forwarded do not return the next node to lookup up. Instead they will recursively search for the originator. The result is returned at the end of the process to the originator. The originator does not control the query flow.
To find the \textit{successor} of an \textit{ID} the \textit{predocessor} must be founded first. This means entails travelling the logical circle. The \textit{predocessor} is the first \textbf{non-NULL node in the ring} which as an ID associated.
The algorithm to find the successor of a node, given the ID is sketched in \ref{alg-ID}:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.20]{images/Pasted image 20230303114856.png}
	\caption{Pseudo-code to find the successor}
	\label{alg-ID}
\end{figure}

Instead of connecting only to the successor, a node could store connection with other nodes in the interval of $(n+1, n+2, n+4, ..., n+2^{M-1})$ where:
\begin{itemize}
	\item 
	$M$ is the routing table size (\textbf{node table})
	\item 
	$N$ is the modulo
	\item 
	$N$ ans $M$ are in a relation of $N = 2^{M} \leq M = log(N)$ which is the number of the entries in the routing table
	So, in the following picture, starting from node 0 we can compute \textit{succ(n+1), succ(n+2), succ(n+4), succ(n+8) ... }$succ(n+2^{M-1})$ . So for all $i$ in range $1..M$ every node known $successor(n+2^{i-1})$. The key idea is pictured in \ref{ring-successor}
	\begin{figure}
		\centering
		\includegraphics[scale=0.70]{images/Pasted image 20230303115451.png}
		\caption{Node connect with other nodes in interval $(n+1, n+2, n+4, ..., n+2^{M-1})$}
		\label{ring-successor}	
\end{figure}
	
\end{itemize}

The particularity of the system is how it searches for the successors if the current does not store the content: the nodes in the routing table of a node could be all the nodes (\textbf{but not likely, as it requires space}) or just the successor node. The latter case has a complexity of $O(N)$ to find a content, having $N$ nodes: its use can be seen in the following snippet \ref{fig:findClosestAlg} where instead of only asking for the \textit{successor} of a node, we also search for the \textit{closestPrecedingNode} to \textbf{forward the query around the circle}.

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230303121015.png}
	\caption{Pseudo-code to search also for \texttt{closestPrecedingNode}}
	\label{fig:findClosestAlg}

\end{figure}

\textit{Finger(i)} in the previous snippet is the \textbf{hash} of the node identified by $i$. The value computed is used to find the closest preceding node to the current node. Given that this is a blind area for the current node: this allows to find a node when the predocessor considered at first is NIL.
\paragraph{An example}\label{sec:an-example}
\begin{figure}[b!]
	\includegraphics[scale=0.030]{images/Pasted image 20230303115814.png}
	\caption{Chord Ring operations example}
	\label{dht-example}
\end{figure}

The example in \ref{dht-example} shows the nodes in the routing table of a node and the lookup of an item on node 15.
The table has size  $N=16$, which means than $M=4$.
Node 1 has $ID_{1}=1$ and the routing tables entries as: \textbf{$2(ID1+2^{0}),3(ID1+2^{1}),5(ID1+ 2^{2}),9(ID1+2^{3})$.}


\clearpage

\section{Kademlia DHT}\label{sec:kademlia-dht}
Summarizing the Chord DHT, we have a virtual space address: we assign the keys to the first node encountered going clockwise starting from key. The keys are represented with the same \textbf{color} of the node they are mapped to. This colors forms a partitions, as showed here:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230303141647.png}
	\caption{Chord DHT simplified}
	\label{kademlia-dht}
\end{figure}


\textbf{Kademlia} uses a different approach. It represent the \textit{de facto standard} searching algorithm for P2P networks on the internet. It's a protocol spefification for storing and retrieving data across P2P network charaterized by:
\begin{itemize}
	\item 
	\textit{Decentralized}: data is not stoed on a central server, but rather dedundantly stored on peers
	\item 
	\textit{Fault Tolerant:} if one or more peers drops out of the network, the data is stored on multiple peers so should still be retrievable
	\item 
	\textit{Easy storing technique}: data is stored in key-value pairs
\end{itemize}

Respect to other DHTs, Kademlia have success because in query routing, the propagation of the query allows the peers to \textit{enrich} their routing query. So propagating the query allows to add information on a peers table in a symmetric way. Also, the querying method allows to send the query in \textbf{parallel} trhough different paths.
Kademlia also uses \textbf{iterative routing} so the peers that submitted the query is able to control the query ad each steps (\textit{differently from recursive routing}).
\paragraph{Structure of identifier space}\label{sec:structure-of-identifier-space}
The identifiers of node and data are organized in a \textbf{complete binary trie}: it comprises a \textit{k-ary search tree or a prefix tree, allowing locate specific keys within a set}.
In the \textit{trie}, edge are annotated with binary digits: a \textit{path} identifies a key whose value may be stored in the leaf. The general idea is skected in \ref{kademlia-id-space}. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230303142817.png}
	\caption{Structure of identifier space with 3 level trie}
	\label{kamdelia-id-space}
\end{figure}

The logical identifier space is defines by the leaves of the tree, so nodes and content have identifiers in the leaves. In the image, the circled binary corresponds to the nodes. Nodes are positioned as leaves in the trie (\textit{sure not all leaves corresponds to peers}). It's necessary to define a rule to partition the keys (\textit{contnet}) among the nodes: this should also respect the rules of consistent hashing.
A new node entering the network now is part of the trie but each node does not store the entire trie on its own but only a subset of them that allows to guarantee a logarithmic cost of operations.
\subparagraph{Mapping keys to nodes}\label{sec:mapping-keys-to-nodes}
A key is assigned to the node with the \textit{lower common ancestor}: first find the \textbf{longest prefix} between the key and the node identifier and assign the key to that node, as sketched in \ref{kademlia-mapping-keys}.
\begin{figure}[b]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230303143423.png}
	\caption{Kademlia mapping keys to nodes}
	\label{kademlia-mapping-keys}
\end{figure}

In the figure \ref{kademlia-mapping-keys}, leaves are pointed by the vertical arrows and corresponds the nodes. The pale colored leaves are assigned to the circled nodes. In the example, the red leaves are in common \textit{0} so the assigned peer is \textit{000}, in blue despite \textit{100} and \textit{101} shared \textit{10}, they are assigned to peer \textit{110}: this is an arbitrary choice becayse they only shared with the two peers in the same subtree only \textit{1}, in this case the choice was \textit{110} but also can be \textit{111}.
This \textit{arbitrary property} can be exploit to alleviate a known problem in DHT about balancing the workload among peers: despite the using of cryptographic hash function, in a scenario with popular content highly requested and other content never requested, this can create a workload balancing problem.

If two computers tie for the longest common prefix, they must look to the \textit{Most signicant bit (MSB)} where they differ, of index $b$ so assign the key to the node whose id bit $b$ equals bit $b$ of the key.
As an example, consider key 100 and nodes ids 110 and 111. The keys and the node ids share a common prefix of 1. The node ids 110 and 111 differ in the last bit so the last bit of the key is 0: assign the key to 110.

To compute the \textbf{closeness (or distance)} between a key and a node, giving the scenario in \ref{example-distance}:
\begin{enumerate}
	\item 
	Initialize the distance value at 0
	\item 
	Compare the key and compute ID bit by bit
	\item 
	If the key and the node id differ at the $i^{th}$ least significant bit, add a penalty of $2^{i}$ to te distance value.
	4
	It corresponds to the \textit{\textbf{XOR Operation}}: it compute the distance betwwen the identifiers and the nodes, interpreted as an \textit{unsigned integer}.
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.60]{images/Pasted image 20230303144637.png}
		\caption{Example on ID distance computation}
		\label{example-distance}	
\end{figure}
	
\end{enumerate}

\begin{figure}
	\includegraphics[scale=0.60]{images/Pasted image 20230303144852.png}
	\caption{undefined undefined}\end{figure}

The clostet node is the \textbf{Node B} because  $4 < C$ and $4 < 9$ and should store \textbf{ID, 94.29.160.5,  34665}.
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230304104122.png}
	\caption{undefined undefined}
 	\label{}
\end{figure}

The XOR operation represent a valid \textbf{metric for the distance} and guarantees properties like:
\begin{itemize}
	\item 
	$d(x,x) = 0$
	\item 
	$d(x,y) > 0,$ if $x!=y$
	\item 
	$\forall x,y: d(x,y) = d(y,x)$ - \textit{\textbf{Symmetry}}
	\item 
	$d(x,y) \oplus d(y,z) = d(x,z)$ - \textit{\textbf{Transitivity}}
	\item 
	$d(x,y) \oplus d(y,z) \geq d(x,z)$ - \textit{\textbf{Triangular inequality}}
	\item 
	\textit{\textbf{Unidirectionality}}: there is a single node at minimal distance with the key.
	Given $x$ and a distance $\delta$ , it exists a single $y$ such that $d(x,y) = \delta$. For example, if $x=1001, \delta=0001$ the only point at distance $\delta$ from $x$ is $y = 1000$.
\end{itemize}

The symmetry is showed in a geometric interpretation in figure \ref{symm-geometric}: consider 4 peers (\textit{colored one}) the y-axis is the \textbf{distance between the colored peers and the peer on the x-axis}.
\begin{figure}
	\centering
	\includegraphics[scale=0.30]{images/Pasted image 20230304104327.png}
	\caption{Symmetry property under geometric interpretation}
	\label{symm-geometric}
\end{figure}

The distance graph looks the same in both halves but \textit{shifted} along the y-axis: \textit{smaller the distance with any per in the same half space}.
The \textbf{symmetric} property allows Kademlia to learn contacts from ordinary queries it receives, helping building the \textit{routing tables} (\textit{not symmetric distances like in chords does not allow this}) while \textbf{undirectional} property allows to determine a single node ad a \textit{minimal distance} with the key so lookup for the same key \textbf{converge to the same path} so caching items along this path is good to avoid hotspots.

Taking two nodes identifiers, \textbf{the larger the common prefix, the smallest is the distance (\textit{computed by XOR})} so close nodes are charetrized by a long common prefix. In figure \ref{eg-distance} is pictued an example.
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230303145655.png}
	\caption{Node identifiers distance example}
\label{eg-distance}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230303145932.png}
	\caption{Identifier tree}
\label{eg2-identifier-tree}
\end{figure}

As the picture \ref{eg2-identifier-tree} clarify, two leaves may be close in the tree and also numerically close, but they are \textbf{distant} according to the metrics given by the XOR:
\begin{center}
	$1000 \oplus 0111 = 1111 = 15$
\end{center}

(\textit{which is also the maximum distance in this scenario}) while the \textit{numerical difference} between is 1.
\paragraph{Distances and identifier tree}\label{sec:distances-and-identifier-tree}
Consider two identifiers $x$ and $y$ of length $L$ that share a \textbf{common prefix} of lenght $p$ and differ in the last $i = L - p$ bits, their distance, according to XOR metric will be s.t.:
\begin{center}
$2^{i-1} \leq d(x,y) \le 2^{i}$
\end{center}
An example of \textit{minimal distance} and \textit{maximal distance} are pictured in \ref{eg3-distance-computation}

\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230304104814.png}
	\caption{\texttt{XOR}-based distance computation}
\label{eg3-distance-computation}
\end{figure}

This enables to \textbf{pair the nodes} of the subtree with an \textbf{identifier range}.
Consider the scenario pictured in \ref{eg4-identifier-space}, based on the previous one, with a third nodes with identifier \texttt{1111}. 
\begin{figure}[h]
	\includegraphics[scale=0.60]{images/Pasted image 20230304104911.png}
	\caption{Shared-prefix induce a variations of the distance}
\label{eg4-identifier-space}
\end{figure}


The leaf $1000$ and $0111$ have a shared prefix length of $0$: the distance varies according to
\begin{center}
	$2^{3} \leq d \le 2^{4}$
\end{center}

\begin{figure}[h]
	\includegraphics[scale=0.60]{images/Pasted image 20230304105059.png}
	\caption{Refer the identifiers pictured in \ref{eg5-space-id}}
	\label{eg5-xor}
\end{figure}

\begin{figure}[h]
	\includegraphics[scale=0.60]{images/Pasted image 20230304105143.png}
	\caption{Adjacent identifier, refer the computation in \ref{eg5-xor}}
	\label{eg5-space-id}
\end{figure}

In figure \ref{eg5-space-id}, the distance between the two nodes in the figure is \textit{minimal}: they differ only in the last bit so $2^{0} \leq d \le 2^{1}$  and $0110 \oplus 0111 = 0001 = 1$.
\clearpage
\subsection{Peers tree: an alternative representation}\label{sec:peers-tree-an-alternative-representation}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230304105337.png}
	\caption{Peers alternative representation: a tree}
	\label{peer-tree-represent}
\end{figure}

The peers in the network are much lesser than the identifiers because the space of identifier is huge so not all the identifiers are paired with a peer.
The \textit{node/peer tree} is an \textbf{unbalanced binary tree} showing only the identifiers of peers present in the network (\textit{subset of all identifiers}): \textbf{each leaf of the tree is a peer, not for all identifiers}. So a leaf in the node tree corresponds to an identifier prefix: the peer paired with the leaf is the unique node with that prefix so there is a unique correspondence between peers and identifiers (\textit{e.g $0011$ uniquely identifies the red peer, no other peer have the same prefix and the deepest part of the path is not useful to identify the peer.})
\subsubsection{Routing table}\label{sec:routing-table}
The main goal is to define look-up operation and store only addresses of a small amount of nodes, guarantee a runtime of $O(log(n))$ by storing  a log number of node ids and their corresponding IP addresses along some contact taken from the identifier trie. The general idea is sketched in \ref{yellow-tree}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{images/Pasted image 20230304105841.png}
	\caption{Routing table tree view}
	\label{yellow-tree}
\end{figure}


For a given node, take the the path from that node to the root: for every \textbf{sibling node} of a node met on that path
\begin{enumerate}
	\item 
	store the identifiers of \textit{k} nodes whose ids are descendent of the sbling
	\item 
	create a \textit{sibling bucket} that contains the \textit{k} contact for each level, forming a  \textbf{k-bucket}.
\end{enumerate}
\clearpage
The pictured in \ref{bucket-structure} shows the contacts in the routing table of the red peer, including  $k = 2$ contact for each subtree, forming 4 different buckets (\textit{in yellow the buckets that contains the contact in the routing table of the \textbf{red peer})}.
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230303151057.png}
	\caption{Contacts for each read peer, $k=2$ for each subtree so 4 buckets}
\label{bucket-structure}
\end{figure}


The rows of the routing table are \textbf{k-buckets}* ($1 \leq i \leq 160$): each row contans $k$ contact and corresponds to a subtree. The contact are stored a \textit{(ID, IP, UDP Port)} and each row contains the contact with distance $d$ from the peer name where $2^{i-1} \leq d \le 2^{i}$. So each entry corresponds to a \textit{common prefix}: the lower the entry the longest the common prefix. A general idea is sketched in \ref{routing-entry}.
\begin{figure}[h]
	\centering
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230304110327.png}
	\caption{Routing table entries}
	\label{routing-entry}
\end{figure}

Each k-bucket corresponds to a prefix and covers a subset of the identifier space: the set of all the k-buckets cover the whole identifier space. The first entries of the routing table correspond to peers sharing a \textit{long prefix} with the owner of the routing table.
The \textbf{last entry} of the routing table corresponds to peers sharing a smaller prefix and cover a larget set of identifiers: may include a larger number of contacts but never more than $k$ contacts.
The value of $k$ is defined such that the \textbf{probability that a crash of more of $k$ nodes is a rare event}.
The nodes in each bucket are mantained in ordered such that \textbf{least recently contacted nodes are in the first positions of the list}.
\subsubsection{K-Buckets management: add contact}\label{sec:k-buckets-management-add-contact}
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230303151751.png}
	\caption{Bucket add contact flow}
	\label{bucket-flow}

\end{figure}

As shown in the flow pictured in \ref{}, the last peer contacted is putted at the end of the table. If the information does not exists in the buckets, check if the bucket is full: if not remove the least recently node (first position of the list) and if there is no response drop it, applying a sort of \textit{self-healing} update.
This approach prefers to mantain the oldest nodes as first choice instead of the new one: this choice is based on analysis made on Gnutella protocol tracing data that shown that \textit{the longer a node has been up, the more likley it's to remain up another hour} so by keeping the oldest live contacts around, k-buckets \textbf{maximize} the porbability that the nodes they contain will remain online. This mechanism is also known as \textbf{Least Recently Seen Eviction}.
Other secondary benefit of the k-buckets is the resistance to the DoS attacks where an attacker cannot flush the nodes routing state by flooding the system with new nodes.

The k-buckets are \textbf{refreshed} for each query passing through the node: if a node has left the network, new information received from the queries refreshes the k-bucket list.
Can also happen thath a k-bucket is not refeshed for a given period of time due to the lack of messages from nodes in the range covered by the k-bucket.
Usually a refresh is \textbf{periodically executed by the protocol}: Kademlia chooses an identifier belonging to the range covered by the bucket at random and search the identifier so if the node with that identifier sends a reply it is inserted in the k-bucket.



\subsection{Key look-up}\label{sec:key-look-up}
Given an identifier, retrieve the associate content/node using the XOR metric for minimum distance (\textit{closest node to the key}) as sketched in \ref{kademlia-lookup}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{images/Pasted image 20230308112052.png}
	\caption{Step 1 of key lookup}
\label{kademlia-lookup}
\end{figure}

In the previous figure \ref{kademlia-lookup}, is considered $k = 1$ but usually $k \ge 1$.
In step 2, pictued in \ref{kademlia-lookup2} the subject node is the \textbf{blue node} that contains the reference to the green node, contained in its routing table.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230308112246.png}
	\caption{Step 2 of key lookup}
	\label{kademlia-lookup2}
\end{figure}


The procedure is \textit{iterative} because the routing information are returned to the original querying node: node $n$ sending the lookup request manages all the search process and at eacj routing step, the node waits for a reply that includes a notification of the next routing step.

To efficiently find the target node, a \textbf{parallel routing} is necessary to discover the target node even by routing the requested to the most distant node in the current node routing table. An example is skected in \ref{eg6-lookup}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230308112720.png}
	\caption{Parallel routing for efficient key lookup}
	\label{eg6-lookup}
\end{figure}

The \textit{blue node} $0011$ looks for the red node $1101$: it has a reference to the green nodes ($1001$ and $1110$) with:
\begin{center}
	$dist (1101, 1001)=4$, and $dist(1101,1110)= 3$
\end{center}

So it's possible that the node 1001, which is more distant from the target, has a reference to the target while the closest node 1110 has no reference to it. The parallel routing allows the blue node to \textbf{send requests to both nodes}.
The degree of parallelism is defined by $\alpha$.
The query is sent to $\alpha \ge 1$ nodes closest to target: \textit{the unidirectionality of the XOR metric guarantees that all the pahts converge towards the target}.
\subsection{Basic Protocol Operations}\label{sec:basic-protocol-operations}
Kademlia consists of 4 primitives (\textit{not iterative}) operations, defined as \textit{RPCs} that exploits UDP:
\begin{enumerate}
	\item 
	\texttt{FIND\_NODE(v) -> w (T)}: \texttt{v,w} are nodes while \texttt{T} target if the lookup. The recipient of the message \texttt{w} return \texttt{k} (\texttt{IP Add, UDP port, Node ID}) triples for the k nodes it knowns abut the closest to the target \texttt{T}. These triples can come from a single k-bucket, or they may come from multiple k-buckets if the closest k-bucket is not full.
	\item 
	\texttt{FIND\_VALUE(v) -> w (T)}: the in parameter is a 160 bit ID representing a value. The returned value corresponds to T if is presented in the queried node (\texttt{w}) and the associated data is returned. If not present, is equivalent to \texttt{FIND\_NODE} and  \texttt{w} return a set of \texttt{k} triples. So this operation return a list of other peers, it's up to the requester to continue searching fo the desired value from that list.
	\item 
	\texttt{PING}: probe node \texttt{w} to see if it's online
	\item 
	\texttt{STORE(v) -> w}: instruct node \texttt{w} to store a \texttt{<key,value>} pair.
\end{enumerate}
\subsection{Node lookup}\label{sec:node-lookup}
To be able to locate the \texttt{k} \textbf{closest node to a given ID} an iterative algorithm is followed based on the basic primitive \texttt{FIND\_NODE}: many \texttt{FIND\_NODE} operations are execute in paralle according to the pamater $\alpha$ that is the sysyem-wide \textbf{concurrency parameter}. Based on $\alpha$ value:
\begin{itemize}
	\item 
	\textit{$\alpha = 1$}: lookup algorithm is similar to Chord, one step progress each ti,e
	\item 
	$\alpha \ge 1$: allows the flexibility of choosing any one of $k$ nodes to forward a request to, at each test
	The \textit{lookup} of a node is exploited both for \textbf{finding nodes} and \textbf{finding values}: both this type of searching need to stop when the value/node is reached/founded.
\end{itemize}
\paragraph{Complete lookup example}\label{sec:complete-lookup-example}
The node \texttt{P} looks for the key \texttt{Q} (\textit{which is the identifier of a node/content}) (\textit{in figure \ref{complete-lookup-1}}) so \texttt{P}:
\begin{enumerate}
	\item 
	look in the bucket list of the nodes closest to \texttt{Q}
	\item 
	looks in the $k$-bucket closest to the key and not empty: if the bucket includes less than $\alpha$ nodes, looks in close buckets.
	\item 
	selected contacts may belong to different buckets
	\begin{figure}[b]
		\centering
		\includegraphics[scale=0.60]{images/Pasted image 20230310114149.png}
		\caption{Key lookup example: contacts may be in different buckets}
		\label{complete-lookup-1}
	
\end{figure}
	
	This allows \texttt{P} to selects $\alpha$ nodes from the selected bucket: this allows \texttt{P} to sends the query in \textbf{parallel} to all the selected nodes (\textit{using RPC\texttt{FIND\_NODE(Q)}}).
	Each contacted node finds out, in turn, \texttt{k} nodes closer to the key: each node may exploit a different bucket of its routing table.
	The \textbf{routing is iterative} because:
	\item 
	Each node returns the results to \texttt{P}
	\item 
	The results are inserted in a list which is ordered on the basis of the distance between the node and \texttt{Q}
	\item 
	Node \texttt{P} continues the routing process through the results obtained from \texttt{P}
\end{enumerate}

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230310114507.png}
	\caption{Bucket update with received information}
	\label{complete-lookup-2}

\end{figure}

At each step, the node \texttt{P} selects $\alpha$ nodes from the received information: if it obtains nodes closer to the rarget with respect to the preceding nodes, it performs lookup on these nodes. Otherwise, chooses further nodes from those which have not been still contacted.
The algorithm terminate when a round of \texttt{FINDW\_NODE(T)} fails to return any closer node.
The entire algorithm is sketched here:
% bash null
\begin{verbatim}
	k-closest= alpha contacts from the non-empty k-bucket closest to the key 
	
	if there are fewer than a contacts in that bucket then 
	k-closest = k-closest U closest contacts from other buckets. 
	
	closestNode = the closest node in k-closest 
	
	/* recursive step 
	repeat {  
		1. select from k-closest, alpha closest contacts which have not been queried yet 
		2. send in parallel, asynchronously FIND_NODE to the delected contacts each contact, if live, returns k nodes 
		3. add to k-closest the new received nodes and update closestNode 
	}
	
	until no node closer to the target than closestNode is returned 
	send in parallel asynchronously FIND_NODE to the k closest nodes it has not already queried 
	
	return the k closest nodes
\end{verbatim}

To store a \textbf{(key, value)} pair, the lookup operation first find the k closest nodes to the key and sends them \texttt{STORE} RPCs. The contacts data is replicated on those nodes.
The \textbf{republishing mechanism} allows each node to re-publish the (key,value) pair to keep them alive. This mechanism is needed when some of the k nodes that initially get the pair leave the network or when new nodes enter the network with an identifier closer to key than the nodes on which the key-value paiir was originally published. In Kademlia, the \textbf{republish} happen every 24 hours.


\subsubsection{Node Join/Leave}\label{sec:node-joinleave}
The \texttt{new} node (\textit{or joining node}) borrow an alive node's ID offline (to the \textit{boostrap node \texttt{boot}}): the initial routing table of the joined new node has a single k-bucket containing \texttt{new} and \texttt{boot}.\\
To enlarge the knowledge of the network, the node need to advertise himself and expand the entries of the routing table: to do this, the node send a \texttt{FIND\_NODE} with the identifier ID of the node itself. By sending this message, other messages return the reference to the joined neighborhood nodes and other nodes insert the \texttt{new} node in their routing table.\\
Some buckets corresponding to a range of identifiers can be empty: to enlarge the knowledge of those peers the node can also execute a \texttt{FIND\_NODE} operation with as identifier a subset of the range missing in the routing table.\\
When the routing table is full in each of $k$ buckets, we can also make an optimization by considering alternative paths by considering the TTL to contact a node: a node can misure the TTL with another one by using the \texttt{PING} primitives.\\

The \textbf{leaving operation} is minimal: the node leaving does not require further operations. If a node does not reply, it will be discarted from the k-buckets so by \textit{auto-healing} the topology structucture created by the nodes disconnection.
\subsection{Strenghts/Weaknesses}\label{sec:strenghtsweaknesses}
Between the weaknesses there are:
\begin{enumerate}
	\item 
	non-uniform distribution of nodes in ID-space that also result into imbalanced routing table and inefficient routing.
	\item 
	the balacing of storage load is not truly solved despite the uses of different path to get the target node: some techniques used in IPFS to solve the storage load balancing use a modification of distribute the content to other peers to be able to manage the load.
\end{enumerate}

Despite, between Kademlia stenghts there are:
\begin{itemize}
	\item 
	low control message overhead
	\item 
		tolerance to node failure and leave
	\item 
	capable of selecting low-latency path for query routing
	\item 
	provable performance bounds
\end{itemize}

See a summary here: \href{https://kelseyc18.github.io/kademlia_vis/basics/1/}{https://kelseyc18.github.io/kademlia\_vis/basics/1/}.
\subsubsection{Kamdelia as Prefix Matching DHT}\label{sec:kamdelia-as-prefix-matching-dht}
Kamdelia is an instance of more general concept of prefix matching due to its routing mechanism based on XOR metrics on prefixes.
The basic ideas is a generalization of the routing to hypercurbes: mapping of nodes and keys to the numbers of \textit{\texttt{m}} digits of a certain base \texttt{base}. and assign each key to the node with which it shared the \textbf{longest prefix} (\textit{if possible}). Different bases allows to change the pedix of the logarithmic factor in operations. It's the same idea as Kademlia but enlarged to a identification space of base and not only binary.
In \ref{prefix-dht} is sketched the basic idea:

\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230310120027.png}
	\caption{Prefix matching DHT}
	\label{prefix-dht}
\end{figure}

The initial file request are served by a centralized server: further requests served by peers which have already received an replicated the files.




\subsection{Content Distribution Network (CDN)}
\label{sec:content-distribution-network-cdn}
A \textbf{Content Distribution Network (CDN)} is a distributed network of servers that are designed to deliver web content to end-users with high availability and performance. The CDN works by caching web content, such as images, videos, and static HTML pages, on servers located around the world. When a user requests a particular piece of content, the CDN will route the request to the nearest server that has a cached copy of the content, reducing latency and improving response time.

CDNs typically consist of three main components: \textbf{edge servers, a caching infrastructure, and a global network}. Edge servers are distributed geographically to bring the content as close to the end-users as possible. The caching infrastructure is used to store and manage the content, and the global network is responsible for routing traffic to the appropriate edge server.

As an example, let's consider a popular e-commerce website that sells products globally. The website's static content, such as images, product descriptions, and videos, can be cached on a CDN. When a user requests a product page, the CDN will route the request to the nearest edge server that has a cached copy of the page. This reduces the latency and improves the user experience. The CDN can also provide security features like DDoS protection and SSL/TLS encryption to improve website security.

Some popular CDN providers include Amazon CloudFront, Akamai, Cloudflare, and Fastly. These providers offer a wide range of features and configurations to meet the needs of various websites and applications.
\section{BitTorrent Protocol}\label{sec:bittorrent-protocol}
BitTorrent is a \textbf{content distribution network}, not based entirely on P2P paradigm. The problem is how distribute the contents to hundres of thousends of simultaneous users.
The \textit{efficient content distribution} is developed using \textbf{file swarming}, later discussed, which is based on the idea that \textit{a peer makes whatever portion of the file that is downloaded immediately available for sharing}.
Some issues have to been addressed:
\begin{itemize}
	\item 
	Flash crowd phenomena: large number of request in small time period implies the ability to manage a high degree of unexpected traffic
	\item 
	CDN (Content Delivery Network): data and services replication on different mirror servers to optimize bandwidth usage
\end{itemize}

The basic idea is to import the CDN mechanism in a P2P environment, without the intervention of a centralized server: differently from a P2P system, it does not perform all the functionsof a typical P2P system like \textit{searching}.\\
The initial file reques are served by a centralized server but further requests served by peers which have already received and replicated the files.
The server distribute two further pieces: in parallel, so previous pieces are distributed. When all pieces are distributed among peers, the server is no more inolved in the file dsitribution.
The distribution and recomposition on request of those piaces of file allows to avoid an unexpected and high load on a single node/server.
\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230311093749.png}
	\caption{CDN example: interaction between clients and tracker}
\end{figure}

In summary, more nodes can serve thc ontent, not only one server: there is the need to detect which node is currently providing the content by introducing the \textbf{tracker} that taking trace of who is currently providing the content. In the example, \textit{JOE} connects to the tracker announcing the content he store and the tracker update the information \textit{"JOE provide the content x"}.
If \textit{BOB} want to download the red content:
\begin{enumerate}
	\item 
	Open a connection ti the tracker and learn that \textit{JOE} is providing the content
	\item 
	Establish a direct connection with \textit{JOE}
	\item 
	\textit{JOE} sends the content, from now on the distributon of the file goes on the directly between peers
	\item 
	\textit{BOB} then announces the tracker that is can also provide the red content, as pictured in \ref{example-1}.


\end{enumerate}

	\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.45]{images/Pasted image 20230311094106.png}
	\caption{}
	\label{example-1}
\end{figure}
\subsubsection{Glossary}\label{sec:glossary}
A general summary is sketched in \ref{cdn-components}, with the following elements:
\begin{itemize}
	\item 
	\textbf{Descriptor}: The file descriptor \texttt{.torrent} are managed by centralized server and not fully by the nodes. The descriptor includes the reference to a \textit{tracker}.
	\item 
	\textbf{Tracker}: entity which coordinates the peers sharing the file
	\item 
	\textbf{Swarm}: set of peers collaborating to the distribution of the same file coordinate by the same tracker
	\item 
	\textbf{Seeder}: peer which own all the parts of the file, having reconsturcted the entire content. At starting time a single seeder S exists
	\item 
	\textbf{Leecher}: is a peer which has some part of no part of the file and downloads the file from the seeders and/or from other leechers.
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.35]{images/Pasted image 20230311094156.png}
		\caption{BitTorrent key elements}
		\label{cdn-components}
	\end{figure}
	
\end{itemize}
\subsection{Protocol overview}\label{sec:protocol-overview}
The protocol is briefly sketched in \ref{torrent-protocol}.

	\begin{figure}[h!]
		\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230311094220.png}
	\caption{BitTorrent protocol interaction}
	\label{torrent-protocol}

\end{figure}


In the pictued schema, the \textbf{peer Seeder} is going to share a file by:
\begin{enumerate}
	\item 
	Upload the \texttt{.torrent} on a Torrent Server
	\item 
	Opens a connection to the \textbf{tracker} and informs it of iwn own existenceUnknown Node :: textDirective
	the moment, it's the only peer which own the file
	The \textbf{peer Peer} is going to download the file by:
	\item 
	Retrieve the \textit{file description (\texttt{.torrent})} and opens it through the BitTorrent client
	\item 
	Open a conenction to the tracker and informs it of itw own existence and recieve from the tracker a list of \textbf{peers of the swarm}
	\item 
	(and step \texttt{6}): opens a set of connections with other peers of the \textbf{Swarm} so ask other peer about the parts they own, declaring its interest in some part of the file. Continues by exchaing the information with the peers in the swarm.
	If \textbf{Peer} remains online when it has finished the file download, it goes on distributing the file, so becoming a \textbf{Seeder}.
\end{enumerate}

In picture \ref{block-eg} is summarized the explained protocol.
\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230311094713.png}
.	\caption{undefined undefined}
	\label{block-eg}
\end{figure}


\subsubsection{Pieces and suboieces (blocks)}\label{sec:pieces-and-suboieces-blocks}
The content is split into chucks called \textbf{pieces} of a choosen dimension between $256KB$ and $2MB$: later those pieces are divided into \textbf{blocks} of $16KB$.
The hash of \textbf{each piece} in $SHA-1$ is stored in the \texttt{.torrent} file descriptor: pieces are the \textit{smaller unit of retransmission} so when the pieces are retrieved from seeders, the hash in file descriptor and the computed one are compared to verify the correctness of the piece to determine if retransmission is needed. (\ref{block-image})

	\begin{figure}[h!]
		\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230311094937.png}
	\caption{Formation of pieces and blocks of BitTorrent content file}
	\label{block-image}
	
\end{figure}

\subsection{Publishing}\label{sec:publishing}
Torrent publishing is a process of distributing large files over the internet using a peer-to-peer (P2P) network. The process involves breaking the file into small pieces and distributing them to multiple users or peers. Each peer downloads and shares small pieces of the file with other peers, allowing for faster and more efficient downloading.

To publish a file on a torrent network, the following actions are typically taken:
\begin{enumerate}
	\item 
	Create a Torrent File: The first step is to create a small metadata file known as a torrent file (\ref{bittorrent-metadata}). The torrent file contains information about the file being distributed, such as its name, size, and checksums of each piece. It also contains a list of tracker servers that are used to coordinate the sharing of pieces between peers.
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230311095142.png}
		\caption{Torrent file metadata}
		\label{bittorrent-metadata}
	\end{figure}
	
	\item 
	Upload the Torrent File: The torrent file is then uploaded to a torrent website or tracker server. The tracker server acts as a central coordinator between peers, keeping track of which peers have which pieces of the file.
	\item 
	Share the Torrent File: Once the torrent file is uploaded, it can be shared with others through various means such as email, social media, or file sharing platforms. Peers can then download the torrent file and open it using a torrent client.
	\item 
	Download the File: After opening the torrent file with a torrent client, the client connects to the tracker server and begins downloading the file by requesting pieces from other peers. As pieces are downloaded, the torrent client verifies their integrity using the checksums in the torrent file.
	\item 
	Seed the File: Once the file has been fully downloaded, the torrent client can continue to upload or "seed" the file to other peers. This helps to improve the download speeds of other peers and contributes to the overall health of the torrent network.
\end{enumerate}

The \texttt{.torrent} file descriptor are automatically generated by ad-hoc tools like \textit{maketorrent} or by the BItTorrent client: some informations are required by the client like set-up info, address of a known tracker etc. To serialize the content it's used the \textbf{Bencode}: it's a serialization code similar to JSON but only used in \texttt{.torrent} files. The bencode serialization provide only 4 datatypes: \texttt{String, Integer, List, Dictionaries} and a set of simple rules, here listed:
\begin{enumerate}
	\item 
	Strings: A string in Bencode is a sequence of bytes. It is encoded as follows: \texttt{<length>:<string>}. Here, \texttt{<length>} is the length of the string in bytes, and \texttt{<string>} is the actual string.
\end{enumerate}

For example, the string "hello" would be encoded as \texttt{5:hello}.
\begin{enumerate}
	\item 
	Integers: An integer in Bencode is a number encoded as follows: \texttt{i<integer>e}. Here, \texttt{<integer>} is the actual integer value.
\end{enumerate}

For example, the integer 42 would be encoded as \texttt{i42e}.
\begin{enumerate}
	\item 
	Lists: A list in Bencode is a collection of other Bencode data types, including strings, integers, lists, and dictionaries. It is encoded as follows: \texttt{l<item1><item2>...<itemN>e}. Here, \texttt{<item1>...<itemN>} are the individual items in the list.
\end{enumerate}

For example, a list containing the integers 1, 2, and 3 would be encoded as \texttt{li1ei2ei3ee}.
\begin{enumerate}
	\item 
	Dictionaries: A dictionary in Bencode is a collection of key-value pairs, where the keys are strings and the values can be any Bencode data type.\\
	It is encoded as follows: \texttt{d<key1><value1>...<keyN><valueN>}. Here, \texttt{<key1>...<keyN>} are the keys in the dictionary, and \texttt{<value1>...<valueN>} are their corresponding values.
\end{enumerate}

For example, a dictionary containing the key "name" with the value "Alice" would be encoded as \texttt{d4:name5:Alicee}.
\subsubsection{Peer Bootstrap}\label{sec:peer-bootstrap}
In the boostrapping phase, a peer downloads the \texttt{.torrent} of the file it wants to download from the tracker: the peer retrieve the tracker's \texttt{URL} and connects to it by issuing an \texttt{HTTP GET} request. Then sends to the tracker the informationa bout its identity (\textit{identifier, port, etc}), \textbf{the number of the peers of the swarm it needs} and other minor informations.

The \textbf{tracker} return a \textit{random list} of \textbf{50 peers} already in the torrent, providing information for each peer like \textit{peer ID, peer IP, peer Port}.
\textbf{Tracker} are used for boostrap and as a \textbf{certification authority} but are not inolved in file distribution itself: if a \texttt{.torrent} file is certified by the server, there is no way to corrupt the torrent because each $SHA-1$ in the \texttt{.torrent} is used from peers to verify the integrity of the pieces received from the P2P Network.
A peer connects to some peers returned by the tracker open at most \textit{40} outgoing connections so remaining peers keps as a pool of peers to connect if needed.

A node uses only part of its bandwidth to boostrapping while another part is left free to accept incoming connections.
\paragraph{Why blocks?: Pipelining}\label{sec:why-blocks-pipelining}
The idea to divide \textbf{pieces} into \textbf{blocks} derive from the fact that the BitTorrent protocol works on TCP Protocol so the underlying \textbf{Slow Start Mechanism} of TCP enter in action: if data are not regularly sent, TCP  brings the peers connection to a slower speed than normal.
It's crucial to have always something to transfer on a given connection to sustain the transfer rate constant.
Each peer for each connection have always some blocks (\textit{typically 5 blocks}) ready to sent for each connection.

The mechanism that allows to determine the order in which the pieces are selected is called \textbf{Peer Selection}: this mechanism is fundamental because an inefficient policy may end up in a situation where each peer has all identical set of easily avaiable pieces and none of the missing ones.
Several policies that provide efficiency exists:
\paragraph{1. Strict Priority}\label{sec:1-strict-priority}
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230311101310.png}
	\caption{Strict priority order enforced by Peer Selection}
	\label{strict-priority}
\end{figure}

if a subpiece of a piece has been required, all the other subpieces of the same piece are required before requiring another block, as sketched in \ref{strict-priority}. It favors a fast assemblage of the pieces: only the complete pieces may be exchanged with other peers so each peer tries to assemble in the fastest way complete pieces.
\paragraph{2. Rarest First}\label{sec:2-rarest-first}
Each peer knows the pieces owned by the others so it have a \textbf{local view} (\textit{by gossip algorithms}) of the \textbf{availability of each piece}: this allows to form the \textbf{Rarest Piece Set}  that contains the pieces with the \textit{minimal availability}.
The algorithm select a piece among the rarest, as pictured in \ref{rarest1} and \ref{rarest2}:
\begin{figure}[b!]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230311101518.png}
	\caption{Rarest selection process among nodes}
	\label{rarest1}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230311101953.png}
	\caption{Rarest pattern behavior}
	\label{rarest2}
\end{figure}



Imagine that there are a set of peers, the edges indicates the ownership of a piace: the pink piece is the rarest. So the upload rate is higher of the seed and because the pink piece is highly requested, in exchange everyone want to download from us so we can download faster from others. It's likely that the peers that own the rarest piace will be insweted in the upload list of several peers.

One \textbf{advantage} is that it can increase download speeds because the more peers that hold a piece of the file, the faster the download. P2P networks can also prevent rarest piece missing, which can make it impossible to assemble the entire file if a seeder disconnects from the swarm. Additionally, using a P2P network can decrease pressure on the seeder because new downloaders can download parts of the file from other peers. This guarantees that the entire file is replicated and the download load on the seeder is decreased.
\paragraph{3. Random First Piece}\label{sec:3-random-first-piece}
Initially, a lecher does not own any piece and cannot offer anything to the other peers of the swarm: it is important that a \textbf{peer acquires a piece as soon as possible, to start the negotiation} of the pieces with other peers (\textit{\textbf{unchoking algorithm}}).
In the \textit{rarest first} politics is not initially exploited because the download of a rare peer may be slow the process, because:
\begin{enumerate}
	\item 
	less piece availability, larger request
	\item 
	larger probability to choose a slow peer
	\item 
	sharing of upload bandwidth of the owner of the rare piece
\end{enumerate}

This introduces the \textit{Random First Piece Policy} at least for the \textbf{first 4 pieces to download}: they are chosen at random. This allows a \textbf{fast starting} and, after that, the \textit{rarest first policy} is exploited.
\paragraph{4. Endgame}\label{sec:4-endgame}
The last piece is downloaded using the \textbf{Endgame} policy: in the final phase the peers are characterized by low bandwidth, slow down when transfer is going to end.

The key idea of this policy is that the last pieces of the file to download are required to \textbf{all the peers that own the file}: to avoid bandwidth waste, when the piece is received from the peer which has requested it, the download started in parallel are cancelled.
There is only a little waste of bandwidth, since the end game is executed for a small period of time, as showed in \ref{timeline}.

\begin{figure}[b]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230311102701.png}
	\caption{undefined undefined}
	\label{timeline}
\end{figure}


\subsection{Free riders problem}\label{sec:free-riders-problem}
The \textit{free riders} in a general definition are "\textit{individuals hiding his/her preference for a common good, so avoiding to pay its price and giving to others the burden to pay the good}". So if there are other individuals interested in the common good, the free rider is aware that he/she can benefit of the common good without paying for it.

In BitTorrent, the \textit{free riders} are \textbf{peers that do not put their bandwidth at disposal of the community}. The solution to this problem in P2P context is complex due to an absence of centralized entity that may control the nodes and it's not possible to impose a given behaviour to the BitTorrent clients, because it's possible to modify the of the client by reverse engineering.
The used approach is to based on a \textit{dynamic monitoring of the connection}: the \textbf{reprocity approach} states that \textit{a client obtains a good service if and only if it gives a good service to the community}, implemented by \textit{\textbf{Choking/Unchoking Algorithm}}.
\subsubsection{Choking Algorithm}\label{sec:choking-algorithm}
Each peer, periodially, \textit{evaluate its neighbour} 's download speed in the previous round and decides which neighbours it's going to \textit{"choke"}.
The decision on which peers to \textit{unchock} is taken every 10 seconds by each peer ans it's based on:
\begin{enumerate}
	\item 
	The download rate of the last $X$ seconds
	Because the use of TCP slow-start mechanism, rapidly choking and unchocking is bas thus the timeframe of 10 second is suitable to match the timeframe of the slow-start mechanism.
	If our upload rate is high more peers will allow us to download from them. This means that \textbf{we can get a higher download rate if we are a good uploader. This is the most important feature of the BitTorrent protocol}.
\end{enumerate}

In \ref{people-scenario} is a pictured scenario:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230311103905.png}
	\caption{Leecher exchange}
	\label{people-scenario}
\end{figure}


BitTorrent divides the time in \textbf{round} (\textit{generally 10 seconds}): for each round, decides \textbf{to whom it wants to send data (upload)}. Each connection with a peer in the neighbor set is controlled by the following variables:
\begin{itemize}
	\item 
	\texttt{interested/uninterested}: want/do not want a piece from you? (download)
	\item 
	\texttt{chocked/unchocked}: want/do not want to send data to you? (upload)
	The connections are \textbf{bidirectional} so each connection has associated a pair of the previous listed variables.
\end{itemize}

Each peer maintains for each remote peer it is connected the following state:
\begin{itemize}
	\item 
	\textit{\textbf{am\_choking}}: the local peer is choking the remote peer. it does not want to send data to the remote peer because the local peer is not satisfied about how this peer collaborates
	\item 
	\textit{\textbf{am\_interested}}: the local peer is interested in at least one piece on the remote peer
	\item 
	\textit{\textbf{peer\_choking}}: the remote peer is choking the local peer.  The remote peer does not want to send data to the local peer, because it is not satisfied by the collaboration with the local peer
	\item 
	\textit{\textbf{peer\_interested}}: the remote peer is interested in at least one piece of the local peer
\end{itemize}

So the \textit{local peer} can receive data from the \textit{remoe peer} if:
\begin{enumerate}
	\item 
	the local peer is \textbf{interested} in the remote peer, and
	\item 
	the remote peer \textbf{unchoked} the local peer, as showed in \ref{chocked-scenario}
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230311104352.png}
		\caption{Choking scenario between node A and B}
		\label{chocked-scenario}
	\end{figure}
	

\end{enumerate}
\subsubsection{Optimistic Unchoking}\label{sec:optimistic-unchoking}
The previous algorithm does not take into account the newly entered peers because initially have nothing to trade and not obtain any interesting pieces. To overcome this limitation, BItTorrent adopt \textbf{optimistic unchoking}: one random selected peer is unchocked so the current download rate from that peer is ignoreted and allow newcomers to download resources.
\subsection{BitTorrent at a glance}\label{sec:bittorrent-at-a-glance}
The overall exchange specified by the protocol is pictured in \ref{full-bitt}.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230311104808.png}
	\caption{BitTorrent at a glance}
	\label{full-bitt}
\end{figure}

Horizontal arrows represents the exchange of messages in P2P fashion (as discussed till now).
\subsubsection{Two-way handshake}\label{sec:two-way-handshake}
Once a TCP connection is established with one of the peer received by the tracker, a client perform a two-way handshake. The header of the message \ref{two-way-header} contains:
\begin{figure}
	\includegraphics[scale=0.50]{images/Pasted image 20230311105046.png}
	\caption{Header of BitTorrent message}
	\label{two-way-header}
\end{figure}

\begin{itemize}
	\item 
	name length:”0x13”
	\item 
	protocol name: “BitTorrent protocol”
	\item 
	"Reserved": used to signal extensions to the basic protocol. 
	\item 
	SHA-1: hash of the torrent file's infohash that contains the hash of the content the peer is looking for.
	\item 
	peerID: the client random ID
\end{itemize}

The peer which receives a TCP connection request \textbf{may refuse the connection} based on two checks:
\begin{itemize}
	\item 
	if the hash does not correspond to \textbf{any hash of the files it is participating to download}. The tracker has returned the hash of each pieces so if the hash is not present, the connection is not allowed.
	\item 
	if the ID of the peer does not correspond to those received by the tracker so the ID is not present in the \textit{swarm} group (\textit{returned by the tracker}.)(\ref{handshake})
	\begin{figure}[b]
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230311105313.png}
		\caption{Nodes handshake with the leecher}
		\label{handshake}
	\end{figure}
	

\end{itemize}
\subsubsection{Peer Wire Protocol}\label{sec:peer-wire-protocol}
Then, after the handshake, the first thing that peer exchange is the \texttt{<bitfield>}: it's a bitmask in which if bit $i$ is set to 1 the peer has the piece $i$, 0 otherwise. The exchange is sumamrized in \ref{wire-proto}

	\begin{figure}[h!]
		\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230311105716.png}
	\caption{Peer wire protocol exchange}
	\label{wire-proto}
\end{figure}


The \textit{message exchanged} are:
\begin{itemize}
	\item 
	\textbf{Interested}: sent from a peer A to another peer B.  It indicates that A is interested in any of the B’s pieces and contains the piece index.
	\item 
	\textbf{Unchoke /(Choke)}: sent from B to A if B unchokes A. It notifies that the request of download coming from A is accepted.
	\item 
	\textbf{\texttt{Request<index, begin, length>}}: this message is sent from peer A to peer B to \textit{request a subpiece (block)} with \texttt{<index>} index and starting with an offset \texttt{<begin>} within the piece, of length \texttt{<length>}. A requested can be sent \textbf{only after receiving Unchoke message from B}.
	\item 
	\textbf{\texttt{Piece<index><begin><block>}}: only one message is used to \textit{send pieces}. The message is sent from peer A to B to send a block to peer B: the block of index \texttt{<index>}, starting with offset begin within the piece and payload  \texttt{<block>}.
	\item 
	\textbf{Have}: notifies that a new piece is completely downloaded and is available for sharing.  It contains information useful for monitoring the swarm: who has what. When a peer receives a Have message, it updates its view of the swarm.
	\item 
	\textbf{Not Interested} indicates that the sender is not interested in that piece anymore. May be sent after receiving a HAVE message
	\item 
	\textbf{Cancel}: sent from a peer to another to indicate that it already got a piece and it is not interested in it anymore. It's sed in end game mode only: sent from peer A to peer B to cancel a request already sent to peer;  for the piece with index starting with an offset within the piece of a length.
\end{itemize}
\subsection{BitTorrent Mainline DHT}\label{sec:bittorrent-mainline-dht}
Bittorrent Mainline DHT allows to \textbf{decentralizes the tracker services} that usually represent the bottleneck. This allows to o provide a “trackerless” peer discovery mechanism to locate peers belonging to a swarm by asking to the DHT, instead of the tracker.
Each node of the DHT \textbf{stores a part of the tracker information}: now each peer implement two different functionalities:
\begin{enumerate}
	\item 
	a client/server listening on a TCP port that implements the BitTorrent wire protocol
	\item 
	a client/server listening on a UDP port implementing the distributed hash table protocol.
	So the DHT plays the role of the tracker and \textbf{stores the content's infohash (\textit{key})} and \textbf{the list of the peers in the swarm (\textit{value})}.
\end{enumerate}
The protocol messages includes basic messages like:
\begin{itemize}
	\item 
	\texttt{PING}: probe a node’s availability or announce one's existence
	\item 
	\texttt{GET\_PEERS(H)}: look for peers belonging to the swarm for the content with InfoHash H. The contacted node may
	\begin{itemize}
		\item 
		store peers for H, replies with a PEER message containing them
		\item 
		have no info for H: replies with the identifiers of the 8 peers closest to H
	\end{itemize}
	\item 
	\texttt{ANNOUNCE\_PEER}: peer announces it belongs to a swarm.
	\item 
	\texttt{FIND\_PEER (target\_id)}: request for nodes which are close to the node with node ID target\_id
\end{itemize}
\subsubsection{Example}\label{sec:example}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230311111416.png}
	\caption{Node contacted by Alice}
\end{figure}

For example Alice wants to download the piece of content stored by Bob and identified by $id=14$. Alice only knows the peers $6,7,13$.
Following the Chord idea of contacting the clostest node (\textit{with XOR distance to the content as in Kademlia}), the clostest to the result node is peer $13$.
Now 13 does not known who has piece 14, so it sends back to Alice the clostest peer to it, being peer $15$.
Peer 15 knows that peer 4 has the content, and sends the contact information to Alice, which can then use the BitTorrent TCP protocol to exchange the content with peer 4.

After downloading the piece, Alice sends (\textit{in broadcasts}) an \textbf{announce} message to tell all the peers it stores piece 14 and can exchange it, as shown in \ref{alice-exchange}.

\begin{figure}
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230311111432.png}
	\caption[scale=0.50]{Broadcast message}
	\label{alice-exchange}
\end{figure}

The announce message has key 14 and value $(11(peerid),info=(ipaddr,port))$. All the other nodes will add it to their "tracker"informations. The internet uses NAT to face the scarcity of IP address, this is a problem for Peer to Peer network.



\chapter{Cryptographic tools and data structure}


\section{Cryptographic toolbox for DHT and Blockchains}\label{sec:cryptographic-toolbox-for-dht-and-blockchains}
The following tools are used for the development of DHT and blockchains: they include hash function, cryptographic hash functions and digital signatures. More advanced tools are accumulators and zero-knowledge principles.
\subsection{Hash function}\label{sec:hash-function}
It's a function that converts a binary string of arbitrary length to a binary string of fixed length. The \textbf{input} is described by its length counted in bits, normally a maximum length but even zero length is permitted.
The \textbf{output} represent the compression and usually have a fixed length among $128-160-256-512$ bit.

There are noticeable differences among \textbf{non-cryptographic} and \textbf{cryptographic} one hashing function: in case of 8-bit block parity (\textit{as shown in picture \ref{8-bit-parity}}), it's easy to find a collision by inverting any even number of bits in $m$ that are in the same column and the parity will not change.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230315112141.png}
	\caption{Collision by inverting even number of bits}
\label{8-bit-parity}
\end{figure}


One of the main property desiderable from cryptographic hash function is the minimum probability to find a value that determine a collision. Another example is the \textbf{CRC - CyclIc Redundancy Check}: the CRC is the remainder in a long division calculation. In the past has been used to detect burst errors.
The \textbf{hash collision} are inevitable since the codomain of the hasing function is smaller than the domain. It follows the \textbf{Pigeon Principle} for which if $n$ items are put into $m$ containers, with $n \ge m$ then at least one container must contain more than one item.
The \textbf{hash security} implies that it's very hard to \textit{find collisions} because would require a huge amount of computational power.
To bound the probability of having a collision, it's necessary to determine the maximum number of guesses to certainly find a collision by a brute force attack.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230315113050.png}
	\caption{Hash function domain and codomain set}
\label{hash-domain}
\end{figure}

Using a brute force approach, picking $2^{256} + 1$ distinct values in the domain and compute the hashes of each of them, hecking if any two output are equal: for the pigeon principle at lest a collision will be founded.
The maximum number of guesses required is:
\begin{itemize}
	\item 
	$O(2^{n})$ time complexity
	\item 
	$O(1)$ space complexity
	\item 
	$n = len(H)$ number of elements to try
\end{itemize}

The \textbf{birthday paradox} show the correlation between the size of the domain and the maximum number of samples required. Specific for the paradox, it states that in a room with $n$ people, the value of $n$ to have the probability that two share a birthday becomes larger than $50\%$ under the hypothesis of.
\begin{itemize}
	\item 
	a year of 365 days
	\item 
	all days equally probable
	This result in the correlation of $n = 23$ ($\sqrt(365)$)
\end{itemize}

The paradox show a connection with hashing function H with $n$ possible outputs: there are $2^{n}$ possible different hashes.
If $H$ is applied to $k$ random inputs, what must be the value of k so that the prob. that at least a pair of $x,y$ satisfy $H(y) = H(x) = 0.5$?
If hashing about $2^{n/2}$ random values then you expect to find a collision because $\sqrt(2^{n}) = 2^{n/2}$ .
\subsection{Cryptographic hash functions}\label{sec:cryptographic-hash-functions}

A \textit{cryptographic} hash function is an hash function that minimize the \textbf{chance of collision} if the inputs are chosen at random: in case of an adversarial that look specifically to create a collision, it's necessary to guarantee a more robust property called \textit{\textbf{adversarial collision resistance}}, among other properties.

Must respect other property than non-cryptographic one:
\begin{enumerate}
	\item 
	\textbf{Adversarial collision resistance}: ensures that it is computationally infeasible for an attacker to find two distinct inputs that hash to the same output (i.e., a collision) even if the attacker can choose both inputs.
	Let $H$ be a hash function with an $n$-bit output. Adversarial collision resistance can be enforced by ensuring that for any efficient adversary $A$, the probability that $A$ can find distinct inputs $x$ and $y$ such that $H(x) = H(y)$ is negligible, i.e.,

	\begin{center}
		$Pr[A(x,y) = 1] \leq \xi(n)$
	\end{center}
\end{enumerate}

where $\xi(n)$ is a negligible function of $n$, meaning that it approaches zero faster than any inverse polynomial in $n$ as $n$ grows.
\begin{enumerate}
	\item 
	\textbf{One-way function (Pre-image resistance)}: let $X$ be the domain and $Y$ the codomain of hash function $h$. For any $y \in Y$ it's hard to find $x \in X$ such that $h(x) = y$. Must be a one-way function.
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230319105914.png}
		\caption{\textbf{One-way function (Pre-image resistance)}}
	\end{figure}
	\item 
	\textbf{Collision resistace}: it's hard to find a pair of value $x_{1} \neq x_{2}$ such that $H(x_{1}) \neq H(x_{2})$.\\
	\begin{figure}
		\centering
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.6\linewidth]{images/Pasted image 20230319110056.png}
			\caption{\textbf{Collision resistace}}
			\label{fig:sub1}
		\end{subfigure}%
		\begin{subfigure}{.5\textwidth}
			\centering
			\includegraphics[width=.6\linewidth]{images/Pasted image 20230315114245.png}
			\caption{\textbf{Second pre-image resistance}}
			\label{fig:sub2}
		\end{subfigure}
		\label{fig:test}
	\end{figure}

	\item 
	\textbf{Second pre-image resistance}: given $M$ and thus $h=H(M)$ it's hard to find another value $M'$ that $H(M') = h$. This property is also kwnown as \textit{wak collision resistance}

	\item 
	\textbf{Hiding}: (\textit{see later})
	\item 
	\textbf{Puzzle-friendliness}: (\textit{see later})
\end{enumerate}

The approaches followed for \textit{attacking} an hash function:
\begin{itemize}
	\item 
	Cryptanalysis involves exploiting logical weaknesses in the algorithm
	\item 
	Performing \textit{brute force} attack: in cryptography it corresponds to an exhaustive search that might be used when it's not possible exploit other mechanism.
	The strenght of a hash function against brute force attacks depends on the length of the hash code produced by the algorithm: for a hash code of length $n$, the level of effort is \textit{proportional} to the value in table \ref{property-bit-value}.
	\begin{figure}[b]
		\centering
		\includegraphics[scale=0.40]{images/Pasted image 20230319110256.png}
		\caption{Number of bit to for each property}
	\label{property-bit-value}	
\end{figure}
	\end{itemize}
	So given a $m$-bit hash function, the attacker needs $2^{\frac{m}{2}}$ brute force computation to find a collision:
\begin{itemize}
	\item 
	MD5 is 128/2 = 64 bits security
	\item 
	SHA-1 is 160/2 = 80 bits security
	\item 
	SHA-256 is 256/2 = 128 bits security
	\item 
	SHA-512 is 512/2 = 256 bits security
\end{itemize}
\subsection{Hiding}\label{sec:hiding}
To avoid that the attacker is able to guess the input domain, a solution is to pick a \textbf{random integer $R$} of 256 bits from a distribution with high min entropy (\textit{no particular value is more likely then others}) and append $R$ to the original input. The input space becomes extremely hard to enumerate ($2^{257}$ possibilities).
The property can be defined formally as:
\begin{center}
	"\textit{A hash function $H$ is said to be hiding if when a secret value R is chosen froma probability distribution that has \textbf{high min-entropy}  then given $H(R || x)$ it is infeasible to find $x$."}
\end{center}

Referring the definition, $x$ is the \textbf{nounce} in Blockchain corresponding mechanism.
\subsubsection{Commitment scheme (Hiding)}\label{sec:commitment-scheme-hiding}
As briefly sketched in \ref{commitment-scheme}, it allows to commit to a value and reveal it later: seal a value in an envelope and put that envelope out on the table where everyone can see it.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230315115544.png}
	\caption{Commitment scheme for hiding}
	\label{commitment-scheme}
\end{figure}
An implementation of commitment scheme by using hash function, in an exchange scenario between Alice (\textit{$A$}) and Bob (\textit{$B$}), is the following:
\begin{enumerate}
	\item 
	$A \rightarrow B : h_{A} = H(RA || paper)$
	\item 
	$B \rightarrow A$: scissors
	\item 
	$A \rightarrow B: RA, paper$
	
	
\end{enumerate}
At the end of the protocol Bob need to verify that the $h_{A}$ sent by Alice is equal to $H(RA || paper)$ so if the values agree Bob will known that Alice has not cheated.\\
This scheme allows Bob to not determine priorly that Alice has committed to the value Paper because he does't known the random value $RA$ used (\textbf{Hiding property}) and he is unable to invert the hash function (\textbf{Pre-image resistance property}).  As soon as Bob sends the value scissors to Alice, she knowns she has lost but is unable to cheat: she would need to come up with a different value of $RA$, say $R0A$, which satisfies:
\begin{center}
$H(RA||paper) = H(R0A || stone)$
\end{center}

but this would mean that Alice could find collisions in the hash function: this will not happen if the hash function guarantee the \textbf{Second pre-image property}. The overall scenario is pictured in \ref{alice-bob-commitment}

	\begin{figure}[b!]
		\centering
	\includegraphics[scale=0.30]{images/Pasted image 20230319111359.png}
	\caption{Commitment scheme between Alice and Bob}
	\label{alice-bob-commitment}
\end{figure}


\subsubsection{Search Puzzles}\label{sec:search-puzzles}
An hash/search puzzle consists of:
\begin{itemize}
	\item 
	a cryptographic hash function $H$
	\item 
	a random value $r$
	\item 
	a target set $S$
	\item 
	a solution of the puzzle is a value $x$, such that $m =  r||x$, $H(m) \in S$.
	Based on \textit{\textbf{partial pre-image attack}}, you have to find a part of the input such that the output belongs to a set (\textit{not a single value like in the pre-image attack}) as showed in \ref{set-size}.
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.30]{images/Pasted image 20230319111651.png}
		\caption{Solution on input/output set for puzzle}
		\label{set-size}	
\end{figure}
	
	The difficult of may be tuned by defining the size of the set $S$: if it's large, the puzzle is less difficult. For example, in Bitcoin, $m$ is defined by the number of leading zeroes of SHA-256.
\end{itemize}

The \textbf{Puzzle-friendliness property} can be defined as: \textit{"A hash function $H$ is said to be puzzle-friendly if}:
	\begin{center}
	\textit{For every possible $n$-bit output value $y$, if $k$ is chosen from a distribution with high min entropy then it's infeasible to find $x$ such thath $H(k||x) = y$ in time significantly less than $2^{n}$}.
	\end{center}

This property implies that \textbf{no solving strategy to solve a search puzzle is much better than trying exaustively all the values of x}.
\subsubsection{Cryptographic hash applications}\label{sec:cryptographic-hash-applications}
The peculiar class of hash function already defined allows to implement an \textbf{anti-tampering} property of the information by usin the hash value as the \textit{checksum} to check if the data is changed or modified. To recognize if a content $C$ is the same of a contwent $C1$ that we saw before it's necessary to remember the hash of $C1$, compute the hash of $C$ and compare the two hashes so if they're equal, the content has not been tampered. This property is also embedded in the Bitcoin blockchain to store transaction ledger in a P2P Network.


\section{Data structure for DHT \& Blockchains}\label{sec:data-structure-for-dht--blockchains}
In the following section we'll address the following data structure (\textit{also used for DHT and IPFS}): \textit{	Hash Pointer, Bloom filters, Merkle trees, Trie, Patricia Merkle Trie}.

\subsection{Hash Pointers}\label{sec:1-hash-pointers}
An \textit{hash pointer} is a pointer to where the information is stored using a cryptographic hash on the information itself. Starting from a given pointer we can ask to get the information back or verify that it hasn't changed.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230317155927.png}
	\caption{Single hash pointer}
	
\end{figure}


The key idea is to build data structures with hash pointers embedded: in the \textbf{blockchain} view, a list is linked with hash pointers by computing the hash to a block, hash again the entire block with its own hash pointer:
\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230317160103.png}
	\caption{Hash pointer with multiple blocks}
\end{figure}

If someone \textit{tampers} the $k^{th}$ block of the chain, the hash of block $k+1$ is not going to match up because the \textbf{hash is collision resistant} so an adversary cannot tamper the data so that its hash is the same of the data before tampering.

Some \textbf{use cases} are useful applying this schema, like:
\begin{itemize}
	\item 
	\textbf{tamper-evident log}, a basic data structure in Bitcoin and Ethereum
	\item 
	in PoW-based blockchain, the block contains also the proof that PoW has been succesfully executed
	\item 
	if data is changed, PoW has to be re-executed for all the blocks
	\item 
	computationally infeasible
\end{itemize}
\subsection{Bloom filter}\label{sec:2-bloom-filter}
Consider the set $S = \{s_{1}, s_{2}, ..., s_{n}\}$ of $n$ elements with $n$ very large. Usually we want to define an efficient data structure that support queries like "$k$ is an element of $S$" also called as \textbf{membership queries}: a given function $f$ returns value $true$ or $false$ according to the presence of $k$ in the given set $S$.

The Bloom filter differently allows to provide an \textit{approximate solution} to the set membership problem \ref{membership-problem}:
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230317160722.png}
	\caption{Membership problem sketcged}
	\label{membership-problem}
\end{figure}

The problem is translated into choosing a representation of elements in $S$ such that the result of the qery is computed \textit{efficiently} and the space for the representaiton of the element is reduced. The result may be approximated to save space and arises the possibility of returning  \textbf{false positives}.
\paragraph{Building a Bloom Filter}\label{sec:building-a-bloom-filter}
Given a set  $S = \{s_{1}, s_{2}, ..., s_{n}\}$ of $n$ elements, a vector $B$ of $m >> n$ (\textit{generally $m > n*k$}) bits, $b_{i} \in \{0,1\}$. Choose $k$ \textit{\textbf{independent hash functions}} $h_{1},...,h_{k}$ such that:
$\forall i. h_{i}: S \rightarrow [1..m]$, $h_{i}$ returns a value \textit{uniformely distributed} in the range $[1..m]$ .
Construct the filter $B[1..m]$ such thath:
\begin{center}
	$\forall x \in S: B[h_{j}(x)] = 1, \forall j = 1,2, ..., k$
\end{center}

Note that a bit in $B$ may be target for more than 1 element:
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230317161513.png}
\end{figure}

\paragraph{Look up}\label{sec:look-up}
To verify if $y$ belongs to the set $S$ mapped on the bloom filter, apply $k$ hash functions to $y$ so we can determine that $y \in S$ if $B[h_{i}(y)]=1, \forall i = 1...k$: if at least a bit is equal to $0$, the element \textit{does not belong to the set}.
The problem of the \textbf{false positives} can occur if all bits are positive because another element or some combination of other elements could have set the same bits.

Compute the probability that, after all the $n$ elements are mapped to the vector, a specificbit of the filter (\textit{of size $m$}) has still value $0$:
\begin{center}
$p^{'} = (1 - \frac{1}{m})^{kn} \approx e^{\frac{-kn}{m}}$
\end{center}

The approximation is derived from the definition of $e$:
\begin{center}
$\lim_{x\to\infty} (1-\frac{1}{x})^{-x} = e$
\end{center}

A percentage of $e^{\frac{-kn}{m}}$ bits are $0$, after its construction. If we consider an element \textit{not belonging} to the set, by applying the $k$ functions, a false positive is obtained if all the $k$ hash functions applied to that element return a value equals to $1$ and this happen with probability of:
\begin{center}
	$(1 - e^{\frac{-kn}{m}})^{k}$
\end{center}

The \textbf{probability of false positives} depends on two parameters:
- $\frac{m}{n}$: number of bits exploited for each element of the set
- $k$: number of hash functions
If the first parameter is set:
\begin{itemize}
	\item 
	decreasing k increases the number of 0 and hence the probability to have a false positive should decrease \ref{false-positive}
	\item 
	increasing k increases the precision of the method. Hence the probability of false positive should decrease \ref{false-negative}.
	Fixed the ratio $\frac{m}{n}$, the probability of false positives first decrease, then increases, when considering increasing values of $k$, as shown in \ref{false-positive}.
	\begin{figure}
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230317163638.png}
		\caption{undefined undefined}
		\label{false-positive}	
\end{figure}
	
	Let us now suppose that $k$ is fixed, the probability of false positives \textit{exponentially decreases} when $m$ increases (\textit{$m$ number of bits in the filter}).
	For \textit{\textbf{low values} of $\frac{m}{n}$} (a few bits for each element), the probablity is higher for large values of $k$, as shown in \ref{false-negative}
	\begin{figure}
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230317163622.png}
		\caption{undefined undefined}
		\label{false-negative}	
\end{figure}
	
\end{itemize}


A bloom filter becomes effective when $m =  c*n$, with $c$ constant value.
\subparagraph{Other operations}\label{sec:other-operations}\begin{itemize}
	\item 
	\textit{\textbf{Union}}:Given two Bloom Filters, B1 e B2 representing, respectively, the set S1 and S2 through the same number of bits and the same number of hash functions, the Bloom filter representing $S1 \cup S2$ is obtained by computing the bitwise OR bit of B1 and B2
	\item 
	\textit{\textbf{Delete}}: note that it is not possible to set to $0$ all the elements indexed by the output of the hash functions, because of the conflicts. This operation is supported in a different version called \textit{Counting Bloom Filter} in which each entry is a counter (\textit{instead of a single bit}): at insertion time the counter in incremented while it's decremented at deletion.
	\item 
	\textit{\textbf{Intersection}}: given two Bloom Filters B1 and B2 representing respectively, the sets S1 and S2 through the same number of bits and the same number of hash functions, the intersection of the Bloom filters obtained by computing the bitwise and of B1 and B2 and approximates $S1  \cap S2$.
\end{itemize}
\subparagraph{Bloom Filter usages}\label{sec:bloom-filter-usages}
The set $S$ mapped on a bloom filter may be a set of \textit{\textbf{Bitcoin addresses}}: light-weight mobile nodes do not store the blockchain and build only the bloom filter with the addresses they are interested in. They send the $BF$ to a full node allowing bandwidth saving and privacy. The full node receives  a block $B$ of the blockhain and uses $BF$ to check if some address of $B$ belongs to $BF$.
In \textit{\textbf{Ethereum}} is used to summarize events generated by a smart contract by finding all the tokens sold by a specific user in a block of 500 transanction. Instead of parsing all transaction, query a Bloom Filter (*or \textit{\textbf{log bloom}}) in the header of a block for the presence of that users and perform a search in the block only if a match is found.
\subsection{Merkle Hash Tree}\label{sec:3-merkle-hash-tree}
A merkle hash tree it's a data structure that allows to \textit{summarize} a big quantity of data with the goal of verifying the correctness of the content. It's a \textbf{complete binary tree} of hashes built starting from a initial set of data:
\begin{itemize}
	\item 
	$i^{th}$ leaf stores the has of $h_{i}$ of $f_{i}$ (*$i^{th}$ \textit{file})
	\item 
	an internal node contains the concatenations of the hashes of the sons of the node
	\item 
	the last hash stored in the root is called \textit{\textbf{Merkle Root Hash}}. The structure obtained is pictured in \ref{merkle-root-tree}
	\begin{figure}
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230317164834.png}
		\caption{Merkle hash tree chains}
		\label{merkle-root-tree}	
\end{figure}
	

\end{itemize}

Suppose have $n=8$ files $f_{1}...f_{8}$ and a collision resistant hash function $H$: go on hashing every two adjacent hashes by applying $H(x,y) = H(x|y)$  where $|$ indicate concatenation.
A \textit{\textbf{Collision-Resistant Hash Function}} for \textbf{Merkle Hash Tree (MHT)} takes $n$ input $(x_{1}...x_{n})$ and outputs a \textit{Merkle root hash} $h = MHT(x_{1},...,x_{n})$.\\
The $MHT$ has an important proof-property: if a \textit{verifier (Alice)} only known the Merkle root has $h$, the \textit{prover (Bob)} can give Alice one of the values $x_{i}$ and convince ALice that is was the $i^{th}$ input used to compute $h$: to convince her, Bob gives Alice an associated \textit{\textbf{Merkle proof}} without shoging all the other inputs. So if a merkle proof says that $x_{i}$ was the $t^{th}$ input used to computed $h$, no attacker can come up with another Merkle proof that says a differnet $x_{i} \neq x_{j}$ was the $i^{th}$ input used in $MHT$.


\paragraph{Merkle Proof}\label{sec:merkle-proof}
The key idea is to have a given file $f_{i}$ and to download a small part of the Merkle tree called \textit{Merkle Proof} of \textbf{Membership proof}: it contains the subset of hashes of the Merkle tree, that, together with $f_{i}$, allow to recompute the root hash. A proof is given for a specific \textit{leaf node} and is comprises the leaf's siblings, and the siblings of each node on the path from the leaf to the root, as shown in \ref{merkle-proof}.
The proof enables you to verify that $f_{i}$ was not modified by checking if the root hash obtained by the proof matches the Merkle root.


To verify the proof, \textit{"fill the blanks"} by computing the missing hashes in the dotted lines, then check if the computed Merkle root you kept locally is equel to the Merkle root obtain from the computation.

*It is unfeasible to output a Merkle root h and two “inconsistent” proofs $\pi_{i}$ and $\pi_{i}'$ for two different inputs $x_{i}$ and $x_{i}'$ at the $i^{th}$ leaf in the tree of size $n$.
\begin{itemize}
	\item 
	\textit{\textbf{Proof (by intuition)}}:
	if the Merkle proof is verified, you were able to recompute the root hash by using $f_{i}$ as the i-th input and the Merkle proof as the remaining inputs. If the proof verification had yielded the same hash but with a different file  as the i-th input, this would yield a collision in the underlying hash function H used to build the tree. \textit{Is not possible if H is collision resistant}.
\end{itemize}

\begin{figure}[b!]
	\includegraphics[scale=0.50]{images/Pasted image 20230317165901.png}
	\caption{Merkle proof sketched}
	\label{merkle-proof}
\end{figure}
\clearpage
\paragraph{Rationale behind large merkle proofs}\label{sec:rationale-behind-large-merkle-proofs}
The main reason to not simply use the has of the files to check their integrity is that the hashes $h_{i}$ are much smaller than the files themselves: can be done by storing the hash $h_{i} = H(f_{i})$ of every file, rather than the Merkle root so when you download a file, only compute the hash $y_{i}=H(f_{i})$ and check thath $h_{i} = y_{i}$.
The merkle proof solution is suitable in case of a huge number of files as in \textit{certificate transparency project} which stores millions of digital certificates for HTTPS websites. The Merkle Tree may have hundres of millions of leaves and it's designed to scale to billions by mantaining a $O(log(n))$ size.
\subparagraph{Merkle Tress in BitTorrent}\label{sec:merkle-tress-in-bittorrent}
In BitTorrent can help ensuring that \textit{data blocks received from other peers are received undamaged and unaltered}: a trusted third party, like the site indexing the \texttt{.torrent} stores the \textit{root hash} and the \textit{total size of the file and the piece size}. So a \textbf{peer} receives a piece and a \textit{Merkle proof} for it, calculate the has of that piece, request the root hash from the trusted site and by combining this information the client can recalculates the root has of the tree and caompares it to the root hash it received from the trusted source.
\subparagraph{Merkle Tress in Bitcoin}\label{sec:merkle-tress-in-bitcoin}
In a transaction scenarios between Alice and Bob, if Alice need to verify if the transaction has been inserted in the blockchain and don't want to download the entire blockchain, can use different solution:
\begin{itemize}
	\item 
	\textit{Insicure-polling}: Alice simply asks the nodes storing the full blockchain if Bob's transaction has been inserted in the blockchain. Bob can lie by sending a fake transaction.
	\item 
	\textit{Merkle-based solution}: build a Merkle tree of the transactions in a block, a full node sends a Merkle Proof to Alice so she can finds the root of the Merkle tree in the block headers. In this way she must download only the block headers and not the entire blockchain.
\end{itemize}
\subparagraph{Merkle Tress Complexity Summary}\label{sec:merkle-tress-complexity-summary}
$n$ is the number of data items, $m$ hash size:
\begin{itemize}
	\item 
	size of the Merkle tree: $O(n)$
	\item 
	size of the Merkle root: $O(m)$
	\item 
	size of the authentication path: $O(m log(n))$
	\item 
	$log(n)$ hashes are sufficient for checking each data block
\end{itemize}
\subsection{Trie}\label{sec:4-trie}
The Trie data structure is a tree-like data structure that is commonly used to store and retrieve strings efficiently. In a Trie, each node represents a prefix or a complete string, and each edge represents a single character.
The key operations of a Trie are inserting a string, searching for a string, and deleting a string. The complexity of these operations depends on the length of the strings being processed and the size of the character set. The main operations are
\begin{itemize}
	\item \textbf{Insertion} in a Trie involves traversing the tree until the end of the string is reached, and then adding a new node for each character that does not already have a corresponding child node. If the string is already in the Trie, no new nodes are added. The time complexity of insertion is $O(m)$, where $m$ is the length of the string being inserted.
	\item \textit{\textbf{Searching}} in a Trie involves traversing the tree from the root to the node corresponding to the last character of the string. If the path does not exist in the Trie, the search fails. The time complexity of searching is $O(m)$, where m is the length of the string being searched for.
	\item \textbf{Deleting} a string from a Trie involves first searching for the string, and then removing the nodes that correspond to the string's characters. If the string is not in the Trie, no nodes are removed. The time complexity of deletion is also $O(m)$, where m is the length of the string being deleted.
\end{itemize}

The space complexity of a Trie is determined by the number of unique strings that are stored in it. The worst-case space complexity is $O(n*m)$, where n is the number of strings and m is the length of the longest string. However, in practice, the space complexity of a Trie is usually much less than this, since many strings share common prefixes and can be stored using shared nodes.
\subsubsection{Patricia Trie}\label{sec:patricia-trie}
Patricia stands for "\textit{Practical Algorithm To Retrieve Information Coded In Alphanumeric}". It compress long one-child branches into single node. In the \ref{comparing-trie}, on the left a standard Trie, on the right the associated Patricia Trie.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230317172227.png}
	\caption{Trie vs Patricia trie}
	\label{comparing-trie}
\end{figure}

\subsection{Patricia Merkle Trie}\label{sec:5-patricia-merkle-trie}
The \textbf{Patricia Merkle Trie} is a combination of both:
\begin{itemize}
	\item 
	Patricia Tries: to enable faster search of data, stores keys, while grouping their common path in a node
	\item 
	Merkle Tree: to maintain data integrity and tamper proof validation
	It is organized as a tree with every node hashed in the sense of \textit{Merkle proof}, grouping common paths in the sense of \textit{Patricia tries}.
\end{itemize}

Regarding the Patricia Trie, it is not limited to string representation but can be used to store (\texttt{key,value}) pairs. Keys are string represented by the trie and the value will be stored in, which is at the end of a key path.

\begin{itemize}
	\item 
	\textbf{Branch node}: a node that has more than one child node. It stores links to child nodes, may also store a value.
	\item 
	\textbf{Extension node}: a non-leaf node representing a sequence of nodes that has only one child. It sotes a key value that represents the combined nodes and a link to the next node.
	\item 
	\textbf{Leaf Node/Value Node}: similar to an extension node. Instead of link, it stores a value.
	\begin{figure}
		\includegraphics[scale=0.35]{images/Pasted image 20230317173027.png}
		\caption{Patricia Merkle Trie example}
		\label{pamerkle-trie}	
	\end{figure}
	
\end{itemize}

In the example pictured in \ref{pamerkle-trie}, Key-value mapping are represented in the Patricia trie \texttt{(BIN, 10) (BINARY, 8) (MOVE, 30) (MOVIE, 55) (TREE, 20) (TRIE, 48)}.


It's possible to \textit{\textbf{"Merkelizing"}} a patricia trie by making the tree cryptographically secure, pairing each node with its hash. The root node becomes a cryptographic fingerprint of the entire data structure. The hash may be used for \textit{lookup} in a database and to refenrence child nodes, as shown in \ref{example3}.
\begin{figure}
	\includegraphics[scale=0.40]{images/Pasted image 20230317173304.png}
	\caption{Merklezized patricia trie: root act as a fingerprint for entire data structure}
	\label{example3}
\end{figure}


The \textbf{Ethereum blockchain} store:
\begin{itemize}
	\item 
	the state of the contracts on the blockchain
	\item 
	a set of transactions in blocks
\end{itemize}


	The state is a combination of \texttt{key/value} pair, may be that:
\begin{itemize}
	\item 
	\texttt{Key} is the address of an account, \texttt{value} is the account balance
	\item 
	\texttt{Key} is the address of a transaction, \texttt{value} is the transferred amount
	Ethereum uses Merkle Patricia tries to store all the information on the blockchain.
\end{itemize}

The nodes of the Patricia Trie are \textit{multi-element, structured records}, while hash function is applied to binary string  so it requires some kind of \textit{\textbf{"serialization"}} to encode structured records as byte array (\textit{like JSON, but more efficient}).
Different techniques are used to encode a variety of data structures; two main techniques used by Ethereum are:
\begin{itemize}
	\item 
	\textit{\textbf{Hex Prefix Encoding (HP)}}: HP encoding is used for encoding/decoding Keys (Paths).
	\item 
	\textit{\textbf{Recursive Length Prefix (RLP)}}:  RLP is used for encoding/decoding Values, corresponding to keys (which may be structured values
\end{itemize}

\chapter{Bitcoin}

\section{Blockchain introduction}\label{sec:blockchain-introduction}
We'll introduce first basic concepts like \textbf{ledgers, consensus in distributed environment, tamper freeness, proof of ownership, permissioned and permissionless blockchain}.\\
A \textbf{blockchain}, as a general idea, is a \textit{replicated ledger} on the nodes of the P2P network: it's consistent and immutable, despite the ledger can differs each other for a short period of time but they'll converge. The immutability derive from the nodes approvation, guaranteeing tamper freeness.
Inside the blockchain there can be at most 3 types of data:
\begin{enumerate}
	\item 
	Hash of the current block
	\item 
	Hash of the previous block
	\item 
	Associated data within the current block
	
\end{enumerate}
The data, in case of transactions, are related to the source, destination and the amount. The two hash represent the chain, allowing chaining each block with the previous one.
The \textbf{tamper freeness} guarantee that if changing one hash causing changing the hash of the following block but this does not imply to recompue some hashes, but it's necessary to find a value of the new hash that solves the Proof of Work. This property is also guaranteed by the distributed consensus algorithm.
\subsubsection{Ledger}\label{sec:ledger}
A ledger store operations and mantains the order of operations. It have properties like:
\begin{enumerate}
	\item 
	\textit{Append-only} list of event
	\item 
	\textit{Tamper-proof}: inside an approved block is not possible to modify or remove a data. This guarantee also auditability.
	\item 
	\textit{Consensus}: everyone agrees on the content
	It can be used in each application that require a log of events.
\end{enumerate}

if the ledger is organized as a list of blocks it forms a blockchain but other topologies are possible like \textit{graphs}. Assume as hypothesis that a block contain only a single operation (\textit{not true for Eth or Btc}): the linearity of the structure and the consensus algorithm allows to avoid redundancy problems (\textit{like the Double Spending probem}), ensuring that the  information stored are consistent each other.

The \textbf{consensus} is the mechanism which defines:
\begin{enumerate}
	\item 
	who decides which operation will be added to the blockchain. This also implies select an \textit{honest} node among the candidates.
	\item 
	which operation among those to be confirmed, will be added
\end{enumerate}

The consensus so represent an \textbf{agreement on the same value}: the nodes agree on one of the node's input and this proves the \textbf{validity} so, agree on someone's proposal.
The \textbf{tamper freeness} is also guarantee through hash: computing the hash of each entry and storing in each entry the \textit{predecessor's hash}. If one entry is \textit{tampered}, there is thhe need to recompute the has of all the following one and this operation must be \textit{\textbf{computationally hard}} so the hash of proof of work must be re-associated with the block.

This poses several challenges, like:
\begin{itemize}
	\item 
	Mantain consistency in opresence of different network jitter, delay, eyc
	\item 
	Some nodes can \textbf{cheat} so it's necessary to create \textbf{bizantine parties} (\textit{see \href{https://en.wikipedia.org/wiki/Byzantine_fault}{Byzantine Fault}})
	A classical result is that if the majority of the node is honest the consensus algorithm works well: the definition of \textit{majority} change with the protocol used.
	As a \textbf{honest majority} we refer to the nodes which follows correctly the protocol by implementing and executing the consensus by voting: broadcast every operation on the network and collect all the votes properly.
\end{itemize}

The \textbf{double spending} problem is correlated to the consensus algorithm: the problem cannot be avoided totally and it depends on the notion of \textit{"majority nodes"}, as we will see.

\paragraph{Sybil attack}\label{sec:sybil-attack}
It consists in inject \textbf{multiple fake indetities} into the network: it's necessary to register with the DHT multiple times.
This type of attack can have as a goal to control data replica, attack routing or disrupt network connectivity.
To guarantee that a single node cannot impersonates multiple logical identies some solutions are:
\begin{enumerate}
	\item 
	\textit{Proof of Work}: require computational power, impling that the identity is not a single one
	\item 
	\textit{Proof of Stake}: require stake
	\item 
	\textit{Certified Node-IDs}: requires a central authority
\end{enumerate}

Those methods poses a solution to define the majority in a context where everybody can easiily join the network and assume multiple identity. Using the \textbf{computing power controlled by each identity} allows to create multiple identities but are not usefull if in a single node/computer/controlled only by one subject.
\paragraph{Proof of Work}\label{sec:proof-of-work}
As an example, the \textit{Proof of work} is like a lottery to choose which node will decide the next block and the tickets are the production of proof of work by solving a complex computational problem. The nodes that win the lottery is paied when endorses validity and decies which is the next node of the blockchain.

If two nodes "\textit{win}" simultaneosly, so they have both the right to choose the next block this causes a \textbf{fork}: the two winner attach their new block to the blockchain, so those blocks are linked in parallel with the previous block. This scenario is infrequent but not impossible: it's solved when later winner decide which forks win, prouning the other.
\paragraph{Proof of Ownership}\label{sec:proof-of-ownership}
In case of an \textit{ICO - Initial Coin Offer} there is the necessity, after registering tokens on the blockchain, that the ownership of those tokens is tracked for each transaction executed on them. Because there is not centralized certification authority, a completely distributed solution is using \textbf{Asymmetric Key Cryptography}: generate the pair of key and anyiine who knows the private key matching the public key of Alice also owns the Alice tokens.
The \textit{public key identifies} the owner of the token publicly, the effective ownership is demonstrated by the propriety of the \textit{private key} by signing the transfer operation.
The transactions are registered on the ledge along with the signed transaction that can be verified by the receiver.
\subsubsection{Blockchain access types}\label{sec:blockchain-access-types}
Two main type:
\begin{enumerate}
	\item 
	\textbf{Permissionless blockchain}: the property of a \textbf{permissionless blockchain} means that anyone can partecipate to the consensus of the blockchain, participating to the governance of the blockchain itself. Of course, in those type of blockchain, other operations are allowed like reading transactions etc. There is no central authority and the partecipation to the consensus is based on reward.
	\item 
	\textbf{Permissioned blockchain}: the involves parties have identities (\textit{human have password, sensors/automated nodes have keys}) and there is the guarantee to avoid the Sybil attack.
\end{enumerate}

Based on the specific case of a supply chain, we can \textbf{restrict the access} to only the actors involved in the process of consensus: they can also be automated actors/nodes. 

An interesting proposal is the \textbf{Practical Byzantine Fault Tolerance} (\textit{see \href{https://pmg.csail.mit.edu/papers/osdi99.pdf}{MIT - PBFT}}) consensus algorithm for small number of nodes.


\section{Transactions and scripts}\label{sec:transactions-and-scripts}
Bitcoin is a Purely P2P version of digital cash without a controlling authority, no server and no banks as intermediary. It's also \textit{permissionless}, thus without a regulator and \textit{censorship resistant}, avoiding the frozen funds problem.
Initially was basically \textit{free}, with neglectible transaction costs (\textit{today the costs skyrocketed}) and \textit{borderless} without geographic/national limits.


The proposed system allows \textit{disintermediation} and  \textit{pseudo-anonimity} because a transaction is performed without identity disclosures but still exists methods to discover the identity (\textit{at least partially}) behind a transaction.
\subsection{Decentralized Identity Management}\label{sec:decentralized-identity-management}
The identity is represented in a complete decentralized system as a cryptographic information, usually a \textit{random key-pair values}:
\begin{itemize}
	\item 
	\textit{sk}: private (secret) key
	\item 
	\textit{pk}: public key. Is the public \textit{name} of a user, despite usually as a public name is used \textit{Hash(pk)}
	The pair allows only the owner of \textit{sk} to control the identity: a transaction signed with a signature \textit{sig} such that \textit{verify(pk, data, sig) == true} so \textit{pk} has generated the transaction because the \textit{pk} is public and can be associated to a given user (\textit{identified by \textit{Hash(pk)}}).
\end{itemize}

The main cryptographic tool used in Bitcoin is \textit{ECDSA - Elliptic Curve Signature Algorithm} (\textit{secp256k1 curve}): it's used to sign transaction with the private key and to verify the signature of the transactions (\textit{having the corrisponding publick key}). ECDSA is not a \textit{post-quantum algorithm}.
Bitcoin does not encrypt any information: keys are used only to prove the ownership of a given transaction that is public.
\subparagraph{Keys and addresses}\label{sec:keys-and-addresses}
The \textbf{privte key} \textit{K} is a umber, usually picked at random: the ownership control over the private key is fundamental to control all fund associated with the corresponding BTC address.
From the private key \textit{K}, it's possible generate the \textit{public key} \textit{Q} through elliptic curve \textit{multiplication} operation (\textit{a one-way function}). From \textit{Q} is possible to generate the BTC address \textit{A} using another one-way function.
The address generation is sketched in \ref{address-generation-btc}:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{images/Pasted image 20230329115703.png}
	\caption{Address generation}
	\label{address-generation-btc}

\end{figure}
\clearpage

Using the \textit{\textbf{base 58} (\ref{base58})} implies that the number of char left with when using all the characters in the alphanumeric alphabet (62), byt remove all the easily mistakable characters, avoiding using \textit{0,O,l,I} that can appear identical when displayed in certain fonts.
The advantages are that a large of character still remain and cna represent large numbers in a shorter format.
\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230329115921.png}
	\caption{Base 58 vs classical alphanumeric}
	\label{base58}
\end{figure}

\subsection{Payment}\label{sec:payment}
The general workflow is sketched in \ref{payment-workflow}, where:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230329120000.png}
	\caption{undefined undefined}
	\label{payment-workflow}
\end{figure}

\begin{enumerate}
	\item 
	Bob shares its address \textit{A} with Alice
	\item 
	Alice generate a transaction  \textit{t} which pays to \textit{A} and broadcast \textit{t} on the P2P network
	\item 
	Miners collects broadcasted transaction into a candidate block
	\item 
	Bob wait for confirmation on \textit{t} before providing the good
\end{enumerate}

Inside a single wallet there are several addresses (\ref{wallet-simplified}): it contains a list of \textit{private-public} key and for each pair it's associated an address.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230329120356.png}
	\caption{Wallet simplified}
	\label{wallet-simplified}
\end{figure}

The output goes partially to Bob and partially is the \textit{change}: usually is retuned to the same address or, to increase anonimity, is created another address associated within the Alice wallet to return the change.
All the input must be consumed, so input canot be splitted to let a change in the input address.
The \textit{transaction fee} is $\sum{input} - \sum{output}$: the difference between the two represent the fee. The higher the fee the fastest the registration and validation protocol by the miners.

We can also have \textbf{multi-input transaction} (\ref{fig:multiin}): having several addresses in the wallet and having the need to aggregate the several amounts in different addresses to only one address.
Each input can also be owned by \textit{different users}: the joint payment must be signed by all the  input's owners to produce and validate the transaction.
This type of transaction is also susceptible to the \textbf{dustying attack} (\textit{see later}).
Another type of payment is the \textbf{mono-input transaction} (\ref{fig:multiout}) with one input and multiple output: it allows to distribute the value in input to multiple recipients.

\begin{figure}[h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{images/Pasted image 20230329120856.png}
		\caption{Multi-input transaction}
		\label{fig:multiin}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.7\linewidth]{images/Pasted image 20230329121128.png}
		\caption{Multi-output transaction}
		\label{fig:multiout}
	\end{subfigure}
	\label{btc:transaction-types}
\end{figure}


\subsubsection{Unspent TXransacton Output Model}\label{sec:unspent-txransacton-output-model}
The transaction model explained is called \textit{\textbf{UTXO Model}} or \textbf{Unspent TXransacton Output Model}: the \textit{unspent output addresses} are addresses that contains bitcoins that are not spent in any transaction.
According to this model, each transaction input is linked to the output of the previous transaction: each transaction generate a new UXTO, which isincluded in the user's wallet and is available to spent.
Each UXTO (\textit{so it's no more an UXTO}) is spent if it's linked to the input of a the next transaction, as sketched in \ref{utxo-model}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.60]{images/Pasted image 20230329121518.png}
	\caption{UTXO model}
	\label{utxo-model}
\end{figure}

Usually only the last UTXO not spent is tracked to avoid to mantain in memory all the blockchain's blocks.
Each UXTO \textit{locks} the newly generated UXTO to the new owner's public key: if the owner decides to use the UXTO in a new transaction, it must \textit{unlock} the funds with the private key, signing the transaction. Who receive the transaction, became the owner of the unused UTXO. Another way to visualize the model is pictured in \ref{utxo-graph}:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230329122837.png}
	\caption{Different payments under UTXO model}
\label{utxo-graph}
\end{figure}


In figure \ref{utxo-graph}, the red circle cannot be used as transaction input, the green circle are the active addresses and new transaction can only use this as inputs. Only the unspent output are significative and mantained by the UXTO: to find the \textbf{balance of one address} is necessarily to sum the unspent UTXO of a given wallet, summing all the amounts in the different addresses in the same wallet.

The concept of a user’s bitcoin balance is a derived construct created by the wallet application: the wallet calculates the user’s balance by \textbf{scanning the blockchain and aggregating all UTXO belonging to that user} so an address balance is the sum of bitcoins in unspents outputs.
\subsubsection{Scripts}\label{sec:scripts}
It's contained inside a transaction: it's a simple program written in a simple programming lanaguage and it's \textbf{used to verify that the signature in the transaction} correspond to the public key. It allows to verify the ownership of the transferred coins: the code is executed by all the node of the blockchain, particularly the miners.

Here is presented a real example. The \textbf{transaction header} is reported in \ref{tx-header}.
The relevant fields are:
\begin{itemize}
	\item 
	\textit{hash}:  report the hash of all the information contained in the transaction itself.
	\item 
	\textit{housekeeping}: to specify the protocol version, the fork, etc, allowing to use values in different way based on version. It also contains the size of input and output and the \textit{lock\_time} define the earliest time that a transaction can be added to the blockchain: if setted to 0 is immediately executed.
\end{itemize}
The \textbf{transaction body} is pictured in \ref{tx-body}
\begin{figure}[h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{images/Pasted image 20230329123352.png}
		\caption{Transaction header}
		\label{tx-header}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{images/Pasted image 20230329123816.png}
		\caption{Transaction body}
		\label{tx-body}
	\end{subfigure}
\end{figure}




The \textit{in} array is a JSON array in which each element contains a key-value pair where the key is the hash pointer to a previous transaction and index of the previous transaction's output to be spent. The \textit{in} contains also the \textbf{unlocking script} as a \textit{signature}.
The second JSON array is \textit{out} (\ref{out-array}):  contains a pair where the value is the value to be transferred in output and te \textbf{locking scripts} that contains the address (\textit{the public key or its hash}) where that value has to be transferred.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230329124024.png}
	\caption{Out array content}
\label{out-array}
\end{figure}

The JSON array

\subparagraph{Scripting language model}\label{sec:scripting-language-model}
The Bitcoin scripts is based on a \textit{\textbf{stack-based, non-Turing complete}}: this avoid to create infinite loops to avoid that the nodes who validates the transaction can enter in a infinite loop, disrupting the network.

It's \textbf{stateless} because there is no state prior to execution because all the information needed to execute are contained within the script.
It's also \textbf{determinsitic} so will predictably execute the same way on different system.
It's a compact scripting language, consisting of one bytecode for the \textit{OPCODE}, allowing a total of 256 instructions: basic arithmetic, basic logic (\textit{IF...THEN...ELSE}), special purpose instructions to support cryptography (\textit{hashes, signature verification, multisignature verification}).
So a script can be defined as \textit{"a piece of code that verifies \textbf{a set of arbitrary conditions} that must be met in order to spend coins"}. There are several script types, from the most \textit{simple signatures checks} that reedem a previous transaction signing it to the most complex like \textit{MultiSig, proof-of-burn, Pay-to-Script-Hash, \textbf{escrow transactions, green addresses, micro payments}.}

\subsection{Bitcoin scripts}\label{sec:bitcoin-scripts}
Following the pictured example in \ref{btc-script1}:


\begin{itemize}
	\item 
	\texttt{B} notifies its public key (\textit{green key}) to A
	\item 
	\texttt{A} sends its bitocin to the public key of B (\textit{use public key is a semplification of the B's addresses})
	\item 
	\texttt{A} unlock some of its bitcoin that were locked by a previous transaction. He creates a lock on the bitcoin sent to B (\textit{to the public key of B})
	\item 
	Only \texttt{B} will be able to unlock the received bitcoins using its \textit{private key (red key)}
	\begin{figure}
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230331141911.png}
		\caption{B is able to unlock using the private key (red key)}
\label{btc-script1}	
\end{figure}
	
	The script is executed in the \textit{locking} and \textit{unlocking phase}: referring the previous example, it's executed when the signature of \texttt{A} is verified in the transaction to trasnfer it to \texttt{B} (\ref{verified-transaction}).
\end{itemize}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230331142136.png}
	\caption{Locking and unlocking script execution}
	\label{verified-transaction}
\end{figure}

The script complexity can change both in terms of key involved in the signing process and operations itself.
The simplest example of script it \textbf{Pay to PubKey (P2PK)}: in this case, the locking script is inside the output of the transaction while the unlocking script is given as an input to the transaction. The figure \ref{p2pk} describe the script execution for this scenario.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230331143056.png}
	\caption{\textbf{Pay to PubKey (P2PK)}}
	\label{p2pk}
\end{figure}

The locking script is formed by \texttt{<Public Key> CHECKSIG}, while the unlocking script is only formed by the \texttt{<Signature>}. The execution of the CHECKSIG operation is executed by using the stack, taking the signature on the stack and veryfing that the actual owner have the rights to spend the given amount of BTC.
Another type of script, the most used, it's known as \textbf{Pay To Public Key Hash (P2PKH)}: in this case, the locking script contain hash of the key, instead of the public key directly embedded into the script.
The unlocking script must provide a public key which returns that hash of the address contained in the locking script and the signature corresponding to the public key. The script execution first hash the public key and compare to the hash in the locking script, chekcing if the signature is valid (\textit{as in P2PK}).


\paragraph{Transaction Lifecycle}\label{sec:transaction-lifecycle}
It starts with the transaction's creation, then the transaction is \textit{signed} with one or more signatures idnicating the authorization to spend the fund referenced by the transaction. It's then broadcasted on the Bitcoin P2P Network and each network node (\textit{partecipant}) validates and propagates the transaction until it reaches every node in the network.
The transaction is verified by the miner nodes and included in a block of transaction, recorded on the blockchain. From that moment, the transaction is a permanent part of the blockchain: the fund llocated to a new owner by the transaction can then be spent in a new transaction, extending the chain of ownership.

There is the pseudo-code to receive a transaction \texttt{t}:
% C null
\begin{verbatim}
	for each input (h, i) in t do 
	if output (h, i) is not in local UTXO or signature invalid 
	then Drop t and stop 
	end if 
	end for 
	
	if sum of values of inputs < sum of values of outputs then 
	Drop t and stop 
	end if 
	
	for each input (h, i) in t do 
	Remove (h, i) from local UTXO 
	end for 
	
	Append t to local memory pool (waiting for confirmation) 
	Forward t to neighbors in the Bitcoin network
\end{verbatim}

The algorithms does not contempalte the case for a 0 input transaction.
All the nodes execute the previous algorithm when receiving a transaction, describing what is called as a \textbf{Local Acceptance Policy}: the transaction which are locally accepted by executing this algorithm \textit{\textbf{may not be globally accepted}} so the transaction considered \textit{unconfirmed} are added to a pool called the \textbf{Local Memory Pool} so when they will be added to the Bitcoin blockchain when they are globally confirmed.
There are different local memory pools for different \textit{unspent transaction output} in different nodes because of the \textbf{double spending problem}: this implies that the nodes will only guarantee \textit{\textbf{eventual consistency}} by executing \textbf{Consensus Algorithms}.
\section{Distributed Consensus}\label{sec:distributed-consensus}
It's a procedure to reach a \textit{common agreement} in a distributed/decentralized environment with multi-agent system.
In a traditional distributed system there is a small number of nodes and fault tolerance is considered. The faulty nodes can crash or become unavailable.
One of the most notable concepts is known as \textbf{Byzantine Fault}, referring to a node that start acting maliciously.
The \textbf{Nakamoto Consensus}, proposed initially for Bitcoin, was based on few principles:
\begin{itemize}
	\item 
	\textbf{Implicit approach to consensus}: there is no voting so there is an implicit agreement where the majority wins. There is no collective message passing alg. executed by the nodes.
	\item 
	\textbf{Eventual consistency}: occasionally nodes see an incosistent view of the ledger but \textit{eventually} everyone sees the same history of the ledger. In this scenario the main assumption is that majority of the nodes must be honest.
\end{itemize}

The proposed Nakamoto consensus works in practice but it's difficult to make a theoretical proof, in fact \textit{"the mechanism through which Bitcoin achieves decentralization is not purely technical, but it’s a combination of technical methods and \textit{\textbf{clever incentive engineering}}}".

The \textbf{consensus algorithm} is necessary mainly to avoid the problem of \textbf{Double Spending}: if during the broadcasting of a transaction to all nodes another transaction occur, referring the same Bitcoin, it will be registered in the ledgers, realizing the double spending of the same amount.
Even try a rollback when a node recognizes the double spending, still remain the problem of two conflicting transaction on how determine which is valid and which one will be discarded. The described scenario shows the necessity to have a consensus algorithm.

In Bitcoin, every node mantains in RAM a \textit{temporary memory} called \textbf{MemPool} that contains a collection of all Bitcoin \textit{\textbf{transaction awaiting confirmation}}. Those transaction wait until a consensus is reached and are included in the next ledger blocks. This pool is not an \textit{UXTO} so they're not yet registered.
The \textit{conficting transaction} may occur in MemPool and not in the ledger: whena  node receive a double spend, mark it as a conflicting transaction and discard it.
Of course some nodes can try to get the transaction out from the MemPool and put them onto the ledger: the final decision it's based on a \textbf{competition} between nodes. In case of \textbf{Nakamoto consensu}, the competition is implemented like a \textit{lottery}: the process for cmpeting to add transaction from the MemPool to the ledger is called \textit{\textbf{mining}}.
The winner adds the valid transaction from its MemPool to the ledger: broadcast the update version of its ledger to the neighbours by sending them the new added transaction that have been added.
The nodes that receives the new added transaction must ensure that no other transaction in its MemPool are conflicting, kicking out eventually conflictingone so MemPool is like a \textit{clearing house} for transactions.
\subsection{Mining}\label{sec:mining}
The process consisting in adding a new block to the blockchain: a \textit{network-wide competition} where every node in the network can work to try to add the next block to the blockchain. The mining process start with filling a \textbf{candidate block} witht ransaction taken from the memory pool: the node then construct a block header with a short summary of all the transaction in it and some metadata. Finally, the node perfoms the \textit{\textbf{PoW - Proof of Work}}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230331150840.png}
	\caption{Block structure}\end{figure}

Usually the transaction list is almost 1000x larger thhan the block header. The header contains:
\begin{itemize}
	\item 
	\textbf{version of the protocol}: used for bug fixing and new features
	\item 
	\textbf{time}: local clock timestamp. It's used for tuning the difficulty of PoW. It indicates the time of block creation.
	\item 
	\textbf{mhash}: it's the root of the \textit{\textbf{Merkle tree}} built on the transaction. Te leaves of the tree are the block transactions. The merkle tree it's built on demand so it's not explicitly represented in the block. Any change to a transaction rresult in change of both the \textit{mhash} and the hash of the whole block. Having the root of the Merkle tree allows to check the transaction integrity.
	\item 
	\textbf{hashprev}: hash of the previous block, the block over which the miner build the current block. It's a SHA-256 field.
	There are other two fields  called \textbf{target} and \textbf{nonce} that are realted to the POW (\textit{see later}).
\end{itemize}

The \textbf{mining process} works as follows: set the value of the nonc of the block header to 0, then compute the hash of the whole header and check if the resulting hash is under a certain threshold setted by the \textbf{target} field.
If the hash of the block header is not below the target, increment the \textbf{nonce} (\ref{good-nonce}) but mantains all other information equals to the previous: this allows to obtain a completely different hash. \textbf{Keep trying by incrementing the nonce until you find a value under the treshold.} In \ref{failed-nonce} an example of unsuccessfull nonce finding.

\begin{figure}[h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{images/Pasted image 20230331151651.png}
		\caption{Successfull nonce values}
		\label{good-nonce}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=.9\linewidth]{images/Pasted image 20230331151803.png}
		\caption{Unsuccessfull nonce values}
		\label{failed-nonce}
	\end{subfigure}

\end{figure}

The difficulty of founding a suitable nonce can be tuned as well as different blocks may have different \textbf{target values}. The tuning is performed based on the number of nodes and the total computational power of all the nodes in the network.
\subsubsection{Random Node Selection}\label{sec:random-node-selection}
The selection of the nodes is randomly executed: the key idea is that the nodes are selected in proportion to a resource that it's hard to monopolize. In Bitcoin, this resource is the \textbf{computational power} and the selection is done on the basis of the Proof of Work.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230331152559.png}
	\end{figure}


The \textbf{Nakamoto consensus} works by selecting a leader node at random: the selection is implemented through the PoW and who is able to find the right nonce so to win the PoW, is seleted node and entitled to propose the next block. At least 51% of the time, this process must pick an honest node.
The selected node \textit{unilaterally proposes} without contacting other nodes, the next block to be inserted in the ledger: can be viewed as a random leader election on every block.
THe block is broadcasted in the network so all nodes cna check the validity and update their blockchains with the new chosen block.
\paragraph{Proof of Work - Formal definition}\label{sec:proof-of-work---formal-definition}
Let's define as:
\begin{itemize}
	\item 
	$d$: the difficulty as a positive nuber which is used to adjust the time to execute the proof
	\item 
	$c$: the challenge as a given string (\textit{the block header minus the nounce})
	\item 
	$x$: nonce as an unkwnon string
	The proof of work is a function defined as $F_{d}(c,x) \rightarrow \{true,false\}$ that satisfy the following properties:
	\item 
	$c,d$ are fixed
	\item 
	$F_{d}(c,x)$ is fast to compute if all the three parameters are known
	\item 
	Finding $x$ s.t. $F_{d}(c,x)=true$ is computationally difficult but feasible
	
\end{itemize}

The proof of work is \textbf{hard} to solve because the output looks like a random 256 bit string where each bit is equally likely to be 0 or 1, independently of the other bits. No better way of finding the correct output than trying \textbf{brute force}: the probability $p$ that the block hash falls below the target threshold $T$ is:
$p = \frac{T+1}{2^{256}}$
and the average numbers of trials required to find ablock hash below the treshold 1/p.
\paragraph{Mining reward}\label{sec:mining-reward}
The mining activity is rewarded, incentivizing miners to be honest. Two main mechanism are implemented:
\begin{itemize}
	\item 
	\textbf{Block reward}: a payment to the miner in exchange for the service of creating a block. Bitcoins mints new coins whe a new block is mined. It's the only way to create new bitcoins.
	\item 
	\textbf{Transaction fee}Unknown Node :: textDirective
	each transaction is the block, they take the difference between transaction input and output. It was voluntarly inserted to obtain a good quality of service from the miners.
\end{itemize}

The \textbf{coinbase} is the first transaction in each block: it encodes the trasnfer of reward plus the transaction fees to the miner and does not consume previous unspent contained in the blockchain but uses a \textbf{single, dummy input} (\textit{without reference to the previous transaction}) while the output is the sum of the rewards and fees that are given to the miner in one or more addresses.
The rewards dynamicaly varies in time: halve the mining reward after all 210.000 blocks (\textit{every 4 year}). Each period is defined as \textit{"era"}.
Those rewards are the only way to generate new bitcoin: they exists in a limited supply in order of 21 millions.
\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230331154548.png}
	\caption{Bitcoin limited supply over the years}\end{figure}


Due to the arise of the miners and mining pool, it's not possible to compete nowadays with miners: they use specialized hardware.


\paragraph{Mining difficult}\label{sec:mining-difficult}
The mining difficut it's \textbf{variable}: the frequency with which miners mine a new block depends on the computational power inside the overal network. The goal, fixed by Nakamoto, was to have a block mined \textit{every 10 minutes}: this target it's not really fixed but it's adhusted by the protocol to acheive the goal.
The goal depends also on the network condition to propagate the block to all/most of all nodes: the idea was to allows time to propagate across the whole network before the next blockg ets mined.  This allows to avoid incosistency between ledger's node (\textit{differently from Eth that mines a block every 20s}).
The rationale behind the 10 minutes frequency is given by the followign example: if blocks are mined too frequently, iners can \textbf{build competing chains} but only one of this will become the longest so some miners will last energy building ona chain that will be left out.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230405114629.png}
	\caption{Competing chains}\end{figure}

The ideal scenario is represented by all miners concentrating the network's mining power on extending the same chain.
A shorter block time have advantages like \textit{faster confirmation} and \textit{less payout variance for miners} as Ethereum does by implementing more forks, introduction of \textbf{ommers} (\textit{is a term used to refer to a type of block that is a direct descendant of the parent block, but was not included in the main blockchain}) and a more complex rewarding system.

To tune the difficulty, the target can be changed from one block to another: here two different target, with the longest sequence of 0's the more difficult target (\ref{zero-target}). Increase or decrease the number of starting zeros bits in the target, according to the ratio \textit{expected time/actual time} allows to tune the difficulty. If blocks are mined faster than every 10 minutes, the target will adjust \textit{downwards to make it more diificult to get below the target}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.45]{images/Pasted image 20230405115136.png}
	\caption{Two different target complexities based on starting zeros}
	\label{zero-target}
\end{figure}


Every node can determine the checkpoint of mining based on the time fields in each block: 2 weeks is an approximation of the time required to mine $2016$ block (\textit{as $2016=14*24*6$}) that is the \textbf{number of blocks mined in two weeks if a block is found every 10 minutes}. Compute th ratio between the actual time between blocks and the expected amount of time and if it's < 1 it indicates that the mining of new blocks is too fast. This allows the nodes to understand if the \textit{10 minutes goal} is satisfied or not.

Every nodes execute the same algorithms so they \textbf{adjust} the complexity in the same way as the other nodes: every node executes exactly the same algorithm so all nodes adopt the longest chain of blocks as their blockchain. They will end up calculating the same target as every node else thus all nodes end up sharing the same \textit{current target} for the same block.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230405120125.png}
	\caption{undefined undefined}\end{figure}

\paragraph{BTC Blockchain overview}\label{sec:btc-blockchain-overview}
The  \textbf{Bitcoin blockchain} consists of a liner list of blocks where each block is composed by \textit{a block header} and a \textit{list of transaction} structured as already seen: blocks are linked each other through \textbf{hash pointers}.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230405120933.png}
	\caption{Blocks information chaining structure}\end{figure}

Blocks are \textbf{uniquely identified} by:
\begin{itemize}
	\item 
	\textit{\textbf{Block hash}}: it's computed when the block is received and not included in the block. It facilitate the block indexing and retrieval for future checks on transactions.
	\item 
	\textit{\textbf{Block height}}: number of blocks proceding it in the blockchain, starting from the \textit{genesis block}.
\end{itemize}

The \textbf{tamper freeness} is guarantee by a combination of the \textit{nonce} and the \textit{hash pointers}. Image an attacker changing a transaction in a block: the \textbf{root of the Merkle tree} changes so also the block header change but this invalidates the \textit{nonce} and the \textit{PoW} must be re-executed to recompute the right \textit{nonce} for the new block.
In the next block, the \textit{hash pointer} to the previous block changes as well because the \textit{nonce} of the next block is no more valid and the \textbf{\textit{PoW} has to be re-executed for the next block}.  This process is repeated for the entire chain so a potential attacker would have to recompute the PoW for the \textbf{entire chain}, using an enormous computing power.

A \textbf{block} represent the \textbf{unit of work for miners}: the base building block isn't a single transaction because, compared to blocks, those have a \textit{shorter hash chain} that allows to fasten the verification process. Also, mining a single transaction would require more overall mining work and less efficient communication for transferring a single transaction instead of an entire block.
\paragraph{Temporary forks}\label{sec:temporary-forks}
It's possible that at a given time, we have two miners \textit{"winning at the same time"}: this is possible if two miners validate and broadcast a block simultaneously. This scenario result in a \textbf{fork} of the blockchain that now have two different branches. The state of the blockchain is seen by the network consists of two braces both originating from the same \textit{parent block}: both branches are \textit{legitimate} because are originated from the correct execution of mining algorithm by honest nodes.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230411104811.png}
	\caption{Temporary fork}
\end{figure}


This create the problem of \textbf{reconciliate the two versions} of the status of the blockchain: in the Bitcoin blockchain, the applied solution is known as  \textit{\textbf{Nakamoto rule}} in which "\textit{the longest fork wins}". Basically, if a miner receives a block that makes the other fork longer, it \textit{abandons the shorter fork}: the transactions of the abandoned fork that were not approved in the winning fork are return to the pool of \textit{"not yet approved"} transactions.
This is the key idea behind the \textbf{6 confirmation rule}: Bitcoin approves a transaction finaly once there are \textbf{at least five following blocks in the chain}. So a transaction is not considered confirmed until at least 5 blocks follow it in the \textit{longest fork}: 6 it's the default  value but can be choosen by the client itself.
In figure \ref{nakamoto-rule} the sketch of the algorithm. 
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230411105523.png}
	\caption{Nakamoto rule pseudo-code}
	\label{nakamoto-rule}
\end{figure}


The previous rules,combined with randomness introduced in the mining algorithm and block propagation \textbf{ensure that the probability to obtain two parallel chains of equal height is the lowest}.
\subparagraph{Nakamoto consensus}\label{sec:nakamoto-consensus}
The theorem states that:
"\textit{forks are eventually resolved and all nodes eventually agree on which is the longest blockchain. The system therefore guarantees eventual consistency.}"

The proof is here sketched:
\begin{itemize}
	\item 
	in order for the fork to continue to exist, \textbf{pairs of blocks need to be found in close succession}, extending distinct branches
	\item 
	otherwise the nodes on the shorter branch would switch to the longer one
	\item 
	the probability of branches being extended almost simultaneously \textbf{decreases exponentially with the length of the fork}
	\item 
	hence there will eventually be a time when \textbf{only one branch is being extended}, becoming the longest branch.
\end{itemize}

The overall scenario is pictured in \ref{fork-scenario}.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230411110417.png}
	\caption{Branching scenario}
	\label{fork-scenario}
\end{figure}

So instead of a blockchain, a \textbf{tree of blocks} is obtained: the path in the tree corresponding to the longest chain is the blockchain while dead path contains the \textbf{orphan blocks}.

\section{Attacks: selfish mining and malleability}\label{sec:attacks-selfish-mining-and-malleability}
To discuss about attacks, we first describe the simplest scenario: \textit{no blocks are mined at the same time} so no attacks are possible to be carried out.
A new block \texttt{B} is mined by a miner: this block is shared by other nodes so when other nodes receives B, they add it to their blockchain. Every miner will start trying to mine a new block \textit{on top of \texttt{B}}.
Another scenario is when we have to concurrent node, mined at the same time, that form a fork in the blockchain in \textit{two directions}: both blocks are correct because are mined by following the protocol by trusted nodes. For this scenario, as discussed in L12 - 5-04-2023, the solution is to use the \textbf{6 confirmation rule} or \textbf{Nakamoto rule}: all the transactions in the dead branch are not valid because are not recognized officially by all nodes as the longest and thus the valid chain.

This approach follows the \textbf{longest chain rule} that incentivize the miners to focus only on the longest chain. This implies to reorganize the chain: this lead to the possibility of \textit{replacing blocks} that can be exploited for attacks.

Here an overview of attacks in \textit{Bitcoin Network} with some countermeasures:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230412112839.png}
	\caption{Taxonomy of BTC blockchain's attacks}
\end{figure}

The malleability attack was based on an problem regarding the transaction algorithm that allows nodes to violate the trustness and modify the transaction information.
\subsubsection{1. Double Spending Attack}\label{sec:1-double-spending-attack}
Basically, it tries to spend the \textit{same bitcoin twice} by sending them to two different recipient at the same time.
\subparagraph{\textbf{Type 1}:}\label{sec:}
First, simple strategy to carry out this type of attack is to send two transaction to the network: both transaction go in the \textit{MemPool} of the miners so only one will be inserted in the next block from a \textit{honest miner} while the second will be considered \textit{invalid} because recognizes that the sender is trying to spend the same UTXO in two different transactions.
\subparagraph{Type 2}\label{sec:type-2}
The scenario get more complex if \textit{those two transaction are validated by \textbf{different} miners}: this is the scenario where the blockchain forks, realizing the case already mentioned, solved by the \textit{Nakamoto rule}.
\subparagraph{Type 3}\label{sec:type-3}
Another scenario is when the sender is also a \textbf{malicious miner} so he can validates a block and includes both transactions in the same block. Other nodes check the validity of the block and simply reject it: the attack does not succeed so mining effort is wasted.
\subparagraph{Type 4}\label{sec:type-4}
From the previous case, we can derivate another method, pictured in \ref{type-4}: the sender is still a \textbf{malicious miner} and tries to perform a double spending attack by \textit{"reversing"} the longest chain by \textbf{performing mining in stealth mode} so do not broadcast/propagate it's chain to the rest of the nodes immediately, delaying the propagation to the entire network.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230412113653.png}
  	\caption{Type 4 scenario}
  	\label{type-4}
  \end{figure}

\subparagraph{Type 5}\label{sec:type-5}
Another type of method involves using an \textit{honest branch} mined by a \textit{honest miner}: the sender is still an \textbf{untrusted miner} so in his \textit{stealth blockchain} he exclude his own transaction (\textit{that was in the green, legitimate branch, pictured in \ref{type-5-attack}}), inserting the \textit{orange} blocks.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230412113953.png}
	\caption{Type 5 scenario}
\label{type-5-attack}
\end{figure}

\subparagraph{Type 6 (51\% attack)}\label{sec:type-6-51-attack}
Another method is that the malicious sender creates a longer chain, broadcasting his version of the chain to the rest of the netwrok. It will be acceptd by the miners due to the \textbf{longest chain rule}: the malicious miner needs more hashing power than the rest of the miners, known as \textit{51\%} of the hashing power. So this allows to add blocks to his version of the blockchain faster and eventually build a longer chain, as shown in \ref{51-attack}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417104836.png}
	\caption{Type 6 (51\% attack)}
	\label{51-attack}
\end{figure}

As soon as the corrupted miner creates a longer blockchain, it \textit{\textbf{suddenly broadcasts}} its blockchain to the rest of the network that must accepts the "\textit{corrupted}" version of the blockchain as enforced by the \textbf{longest chain rule}. The chain is longer than the one they were working on and they switch to this chain.
If the attack succeeds,  the old chain is abandoned, and transaction in that chain are no more valid so the malicious sendr is able to spend again the same amount, already spended ion the abandoned branch.

An example of 51\% attack was carried out by the mining group called \textit{Ghash.io}. It came close to reaching 50\% in 2014 but even with 50\% this doesn't necessarily mean that it will perform an attack. The case of Ghash shows that is more remunerative to mining respect to perform an attack that lead to a price crash.
\subsubsection{Transaction Malleability Attack}\label{sec:transaction-malleability-attack}
It's based on the fact that you can modify the \textit{transaction hash (\textbf{TXID})} \textbf{without modifying} the signature of the transaction. It's noticeable to remember that the input of a transaction is signed by the private key of the owner. All the nodes receiving the transaction verify that the sender is really the owner of the transaction.
The transaction identifier \texttt{TXID} is the SHA-256 of all the fields in the transaction data: so it depends from the \textit{unlocking script (signature script)} but a node can \textbf{change the unlocing script} in such a way that:
\begin{itemize}
	\item 
	the transaction has the same effect
	\item 
	the signature is still valid
	\item 
	the \texttt{TXID} \textbf{changes}
	This implies that the signature is still valid despite the transaction ID changes.
\end{itemize}

Alice issues a BTC payment to Bob, and signs the transaction $TXID_{1}$: Bob alters Alice's transaction signature, before $TXID_{1}$ is confirmed, this results in a new transaction identifier, $TXID_{2}$, on the same content.
$TXID_{2}$ gets confirmed on the blockchain before $TXID_{1}$ so the latter will not be confirmed, because it appears as a double spending. Alice does not see her transaction confirmed amd Bob could then defraud Alice by asking her to issue a new payment.
Alice belives this, because she see another transaction confirmed, not her transaction: a double spending attack performed by the receiver of the transaction allows Bob receives twice the intended amount.

The solution to avoid the \textbf{malleability attack} was to change the structure of bitcoin transaction data, kwnown as \textbf{Segregated Witness (SegWit)}.
The key idea was to separate all the malleable information into a separate \textit{witness data} and compute the TXID without the \textit{unlocking script} so the transaction identifier will never be able to change again. Here is pictured the process before the fork, called \textit{SegWit}, and after:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230412120506.png}
	\caption{Pre SegWit vs After SegWit}
\end{figure}

\subsubsection{Denial of Service}\label{sec:denial-of-service}
As an example, imagine that a miner, say Alice, really dislikes some other user, say Bob, and want to denies service to him.
Alice decides that she will not include any transactions from Bob’s addresses in any block that she proposes for the block chain but if Bob’s transaction is not inserted into the next block that Alice proposes, it remains in the pool of \textit{unconfirmed transactions} of all the miners
Bob will just wait until that an honest node proposes a new block so his transaction will get into that block, so being confirmed by the network thus the block will be inserted in the blockchain.
\subsection{Bitcoin ecosystem}\label{sec:bitcoin-ecosystem}
A bitcoin client can implement different features, based on its specific type:
\begin{itemize}
	\item 
	\textbf{Reference Ciient (Bitcoin Core)}:
	\item 
	\textbf{Full Block Chain Node}: contains the full blockchain database and network routing but not partecipate to the mining of blocks.
	\item 
	\textbf{Solo Miner}: contains mining function with a full copy of the blockchain and the bitcoin P2P network routing protocol.
	\item 
	\textbf{Lightweight Wallet (SPV)}: contains a wallet and a network node on the bitcoin P2P protocol, without having the full blockchain.
\end{itemize}
\subsubsection{Miners}\label{sec:miners}
Basically execute a continue HASH computation, with the core cycle composed by:

\begin{lstlisting}
	while (1) 
	HDR[kNoncePos]++; 
	if (SHA256(SHA256(HDR)) < (65535 << 208)/ DIFFICULTY) 
	return;
\end{lstlisting}

Those activity lead to the design of specific hardware for mining, impliying an \textbf{increasing difficulty} over the year to be able to mine a new block. This was solved by Ethereum with PoS.
The first generation of mining was \textbf{CPU-based}: was based on the sequential search of right nonces or a few core parallization, compuitng  a SHA-256 directly in software, without specialzied hardware.\\
The second generation was based on \textbf{GPUs} designed for high-performance graphics: this allowed to use an high degree of parallelism, computing different hashes with different nounces. This allowed the miners to achiee high throughput. This approach lead to an under-use of GPU, consuming a lot of power.\\
The hird generation was \textbf{FPGA-based}: they were programmed in Verilog and ensure performances as close as possible close to the custom hardware. This lead to design high performance GPUs, allowing excellent performance on \textit{bitwise} operations.\\
The fourth generation was based on \textbf{ASIC Application Specific Integrated Circuits}:  is an integrated circuit chip designed for a specific purpose. An ASIC miner is a computerized device that uses ASICs for the sole purpose of mining digital currency. Generally, each ASIC miner is constructed to mine a specific digital currency. So, a Bitcoin ASIC miner can mine only bitcoin. One way to think about bitcoin ASICs is as specialized bitcoin mining computers optimized to solve the mining algorithm by implementing a fast computation of \textit{SHA-256}.

Two main approaches to mining:
\begin{itemize}
	\item 
	\textbf{Solo mining}: a single miner try to solve the computation problem. This scenario is described as a Poisson process
	\item 
	\textbf{Mining pools}: miners group together to create \textbf{mining pools} that allows to reduce the variance of their income.
\end{itemize}

I the first case, the mining is a very risky task even if the reward is high: there is an high probability of spending a lot for mining hardware and electricity withouut obtainin a reward  for a long time.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230412121738.png}	\caption{Hashrate computation example}
\end{figure}


The bitcoin mining follows the Poisson distribution, having a large standard deviation.

For the second case, we have \textbf{mining pools} that ma operate in two different ways:
\begin{enumerate}
	\item 
	throuht a \textbf{centralized mining operator} so the miners should trust the pool manager
	\item 
	in a P2P way, using a private blockchain to manage the pool
\end{enumerate}

For the \textbf{centralized} one, the pool manager send the blocks to all the miners, distributes revenues to members based on the work they have performed but the manager must be trusted by everyone. This implies also that nodes in the pool need to produce a measure of their work to be rewarded proportionally for his work, even if they are not able to solve the given problem and find the nounce.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230412122342.png}
	\caption{Centralized mining operation workflow}
\end{figure}


This approach poses challenges like \textit{how does the pool mananger known how much work the node of the pool are performing?}
The proposed solution is called \textbf{Mning shares}: it's a proof of the work done by a miner, sent to the mining pool cordinator. It's based on an hash called \textit{near-valid blocks} or \textit{near optimal hashes}: the hasesh contains fewer zeroes than those required by the current difficulty. This does not entirely shows that hard work have been done but probabilistically prove how much work has been done.
\paragraph{Payout}\label{sec:payout}
In the \textbf{pay per share} model, the miner send to the mining pool operator the \textit{partial solution} and receive a \textit{reward} based on fair share of work executed and demonstrated.
The instant payout guarenteed to the miner presenting a share: this guarantees a reward without waiting for the pool to find a block but no bonus is paid to the miner who actually mines the block. The miners are payed from pool's existing balance so the risk is at the pool's operator but he is also protected by the participant fees.
The main disadvantages are that workers do not have valid incentives to send valid blocks to the manager so they can discard valid blocks but still be paid the same reward.

In the \textbf{pay proportional} model, the amount of payment depends on the whether or not the miner actually found a valid block. Every time a valid block is found, the rewards from that block are distributed to the members proprtional to how much work they actually did.
This lower the risk for the pool manager because he payout only when a valid block is found.
\subsubsection{Decentralized mining pool}\label{sec:decentralized-mining-pool}
The key idea is that no operators is required to verify each miner's contribution to the pool: this is possible by building a \textbf{separate, private chain} that include also \textit{"weak blocks"}, mined with lower difficulty. It's necessary to store in the private chain the transaction rewarding for mining weak blocks, until a valid block is found, then distribute the reawrd through a side blockchain which is then merged to the main chain, by a process kwnon as \textbf{merge mining}.

So miners in the pool create a private blockchain, called \textbf{sharechain}: the difficulty of mining a block can be $n^{1} << n$ where $n^{1}$ is choosen such that a new block appears every 30 seconds. The block is built on top of the last block of the \textit{public blockchain} so each block of the private blockchain correspond to a \textit{share of work} done by one of the miners: this allows to avoid a central operator to check, by making the process transparent.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417110834.png}
	\caption{Sharechain creation}
\end{figure}

The first block of the shared chain inclue the payment to \texttt{AAA}, the first miner generating a share. The second block includes a payment both to \texttt{AAA} and to \texttt{BBB}, the second miner solving the \textit{reduced} ($n^{1} << n$) PoW. The process iterates.
When a miner solves the PoW, the last block is linked to the "\textit{real}" public blockchain so no miner can cheat avoiding to insert in the next blocks a payment all the payment to the previous ones.
This is the blockchain as seen by the rest of the network after a valid block is found in the mining pool:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417111102.png}
	\caption{Blockchain after merging with the real one}
\end{figure}


\chapter{Ethereum}\label{chap:ethereum}
Ethereum is a blockchain platform for building decentralized applications: \textit{application code and state} is stored on a blockchain   and transactions can cause code execution and update state, emit events, and write logs. Even frontend web interfaces can respond to events and read logs.
It's the most used platform for NFTs and ICOs (Initial Coin Offers). ICOs are based on ERC-20 token contract. It's useful in a scenario where a company seeking to raise money to create a new app, or service can launch an ICO as a way to raise funds. The interested investors receive a new cryptocurrency token issued by the company. This token may have some utility related to the product or service that the company is offering or represent a stake.

Ethereum allows to implemented \textbf{smart contracts} that are \textit{decentralized, replicated, processed} on all the nodes on the network, without a central coordinator. The consensus mechanisms assure that all the nodes agree on the \textbf{results of the execution} and update the state in the same way so each node changes its own version of the ledger with the result of the smart contract evaluation. This is implemented by a a \textbf{distributed state machine} that define how change the \textbf{global state}, which is the status of all the smart contracts. A single transactions allows to change the global state.
\subsection{Overview}\label{sec:overview}
As Bitcoin, Ethereum is based on a \textit{\textbf{transaction-based deterministic state machine}}: a virtual machine that applies changes to a global, replicated state. The state change is triggered by a transaction but Ethereum allows anyone to create its own \textbf{state transition functions} without imposing any script.
Differently from Bitcoin, Ehereym uses \textbf{accounts} that keep track of balance: the global shared state of Ethereum is stored in a \textbf{multitude of accounts}, from small objects interacting with one another through a message-passing paradigm.

Compared to BTC, Ethereum is a a \textbf{public} and \textbf{permissionless} blockchain where the addresses are generated by \textit{keys} and the transactions are signed through a \textit{digital signatures}: in Ethereum blocks contain data and smart contracts, in Bitcoin blocks contain data and scripts.
The \textbf{consensus algorithm} was Proof of Work until 2022, when Ethereum introduced Proof of Stake. As Bitcoin, Ethereum is deployed on a P2P Network: Kademlia i'ts used at P2P levelto discover peers.
\subsubsection{Accounts overview}\label{sec:accounts-overview}
Each account has an identifier of $20$ byte plus a state indicator. There are two maint ypes of accounts:
\begin{itemize}
	\item 
	\textbf{Externally owned (EOA)}Unknown Node :: textDirective
	by private keys so they don't have any code associated with them.
	\item 
	\textbf{Contract accounts (CA)}: have code associated with them thus are controlled by the associated code.
	The first type of accounts usually contains informations like \textit{address, Ether balance, nonce (total transactions emitted from that account)} and are able to send transaction to transfer Ether or send transaction to trigger a smart contract. Differently from BTC, a transaction it's not based on UTXO but it's \textbf{account-based} (\textit{as suggested by the balance and nonce}).
\end{itemize}

In case of \textbf{Externally Owned Account (EOA)}, the transaction format must include \textit{Signature, Receiver address and the Amount}.
In case of \textbf{Contract accounts (CA)}, the account contains:
\begin{itemize}
	\item 
	\textit{contract code}
	\item 
	persistent storage for contract variables
	\item 
	\textit{balance}: like EOAs, contract accounts have an Ether balance and can receive/transfer Ether
	\item 
	\textit{nonce}: number of messages sent from this account
\end{itemize}
\paragraph{Smart Contract}\label{sec:smart-contract}
A smart contract is a computer program in which the code cannot change after being deployed on the blockchain because it's execuded in parallel by all the \textit{full nodes} of the network. The code must define a \textbf{deterministic computation} because the output of a smart contract must be the same for every node: to execute a contract, an \textit{execution context} myst be provided. The context include data taken from the transaction that has activated the contract, the internal storage of the contract and information from block headers of the blockchain.
We can distinguish three phases in the lifecycle of a smart contract:
\begin{enumerate}
	\item 
	\textbf{Creation}: To deploy a smart contract,the developer need to have an \textbf{EOA}: the transaction to create a contract involve using the information alredy defined for EOA transaction but with the \textit{Receiver address} empty and with an extra field called \texttt{data} that contains the code of the smart contract.
	\item 
	\textbf{Interaction}: The \textit{EOA} calls a method of a smart contract through a transaction, enabling the execution and passing the required arguments. This phase uses a transaction with the \textit{Receiver address} setted with the address of the contract and with the \texttt{data} field containing the method to call and the parameter to pass.
	Smart contracts are triggered by transactions from EOA or from messages from other smart contracts which call functions inside a contract, specifying the address of the contract and the parameters of the function. The transaction may even contains Ether to transfer to the smart contract.
	Contract account \textbf{cannot initiate a transaction by themselves}: when activated may call other contracts, but not themselves. This can lead to build complex execution paths.
	Upon reception of a transaction/message, the \textbf{Ethereum Virtual Machine (EVM}) is executed: it can perform different actions like \textit{computation, write internal storage, send messages to another contract or create a new contract}. The process is sketched in \ref{interaction-contract-process}.

	
	\item 
	\textbf{Destruction}: this phase is triggered by a transaction with the \textit{Receiver address} setted as the contract address and the \texttt{data} field containing the name of a method that calls the \textit{self-destruction operation}.
\end{enumerate}

	\begin{figure}[h]
		\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417115524.png}
	\caption{Interaction process of a smart contract}
	\label{interaction-contract-process}	
\end{figure}

So, overall, \textbf{EOAs} are a bridge between the external world to the internal state of Ethereum: any action is always set in motion by transactions fired from externally controlled accounts.
\subsubsection{Accounts and transactions insights}\label{sec:accounts-and-transactions-insights}
An account, as mentioned, contains:
\begin{itemize}
	\item 
	\texttt{nonce}: number of transactions sent/contracts created
	\item 
	\texttt{balance}: owned \textit{gwei (see Gas section)}
	\item 
	\texttt{storageRoot}: i'ts the digest of the Ethereum's state as a hash of the root node of a Merkle Patricia trie.
	\item 
	\texttt{codeHash:} hash of the code of contract account account. The \texttt{hash("")} function is used for external accounts.
	
\end{itemize}

Focusing on the \textbf{nonce}, the yellow paper states that is "\textit{a scalar value equal to the number of transactions sent from this address or, in the case of accounts with associated code, the number of contract-creations made by this account}" so it's an \textit{attribute of the address that originate the transaction} and not of the transaction itself.
The nonce allows also to records the order of the transactions, protecting against \textbf{transaction duplication} and \textbf{reply attacks} alongisde \textbf{double spending} from the same address.
It's noticeable to remark that there are two types of \textit{nonces}:
\begin{itemize}
	\item 
	\textbf{Transaction nonce}: not as Bitcoin nonce
	\item 
	\textbf{Block nonce}: used by PoW, like Bitcoin's nonce
\end{itemize}


In case of \textbf{reply attacks}, because Ethereum stores account balances, the attacker takes any existing transaction and resend it on the network more and more time. All these replayed transactions try to withdraw funds from the same account and are considered valid because are signed with by the account's owner. Thus if the account has enough Ethers, the attack is successfully.
Ethereum prevents this with the using the \textbf{account/transaction nounce}: suppose that the \texttt{nonce} of the original transaction is $22$,after receiving the original one, the network does not accept another transaction from the same account with nonce setted as $22$ and this prevent the attacker to change the nonce because would invalidate the signaure of the transaction.
Each time an account sends a transaction the nonce is increased by 1 so it's used to enfroce the rules to consider a \textbf{transaction valid}.
The transactions \textbf{must be in order} so a transaction with nonce 1 cannot be mined before one with nonce of 0. Also, transaction \textbf{cannot be skipped}: if a transaction has nonce 2 cannot be mined if the miner has not already sent transactions with nonce of 1 and 0.

To \textbf{propagate a transaction}, Ethereum uses a \textit{flooding approach}: the propagation starts with the node creating a \textit{signed transaction} so the transaction is validated by each node and then it's transmitted to all other nodes that are directly connected to the originating node. On average, Ethereum node mantains connection to at least \textbf{13 other nodes}: each neighbor validate the transaction as soon as it receive it. If the received transaction is valid, they store a copy and propagate it to all their neighbords (\textit{except the one it came from}).

The process of \textbf{transaction mining} modify the global state of Ethereum: the balances of the involving accounts are modified and all contracts are activated by transactions/messages that are executed. The state of the accounts are updated and stored in a \textbf{Patricia Merkle tree} so a new  \texttt{stateRoot} is stored in the block header and the \textbf{Receipt Root} it's updated to contains the generated events.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417122024.png}
	\caption{Transaction mining and propagation}
\end{figure}

The winning miner will publish the block to the rest of the network,the other nodes execute the contracts and check the result. If the result is valid, they add the block to their blockchains: the entire network agrees on the \textit{current balance, storage state, contract code, etc}, of every single account.
\subsubsection{Ethereum State Machine}\label{sec:ethereum-state-machine}
The state of the Ethereum network comprehends the \textbf{state of all its accounts}. A simplified version of an account state the \textit{account address, balance and code and state of the variables for contract accounts.}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417122348.png}
	\caption{State of an account}\n\end{figure}

Here a simplified version of \textbf{state transition fired by a transaction}:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417122434.png}
	\caption{Account's state transition after a transaction occurred}\n\end{figure}

\subsection{Gas}\label{sec:gas}
Every node in the network evaluates all transactions and store all the \textit{contract state}: it's not possible to tell, just by looking at the program, whether it will take forever or not to execute. The program must be executed to verify this: due to Turing completeness, this may happen in Ethereum.
To avoid the scenario in which a malicious user try to execute a never stopping contract-code, leading to a DoS (\textit{because the EVM is a \textbf{single-threaded machine without scheduler}}), Ethereum introduced the concept of \textit{\textbf{gas}}.

The key idea is to \textit{pay for contract execution}, giving payed \textit{gas} to your smart contract: this make attacks expensive and allows the EVM to stop the execution when the contract goes out of gas.
Each computational step has a fixed \textit{gas fee}, as the \textit{storage} that require also gas fees to perform contract actions.
The \textit{EVM} implement a \textbf{quasi-Turing-complete machine}: can run any program but only if the program has paied enough gas: at any time, there is a defined \textit{computational limit} given by the amount of gas of the contract.
\paragraph{Gas price}\label{sec:gas-price}
The explained model require to buy gas to run a smart contract, so purchasing a distributed, trustless computational power.
The gas price in Ether is determined by the \textit{caller}: the price is based on the amount of Ether you are willing to spend per gas unit thus low prices means low priority. The gas prace is also measured in \textit{"gwei (giga wei)"} where one $gwei$ correspond to 1 million $wei$. The unit of gas spent of each instruction is fixed:
\begin{itemize}
	\item 
	\textbf{adding two numbers} : 3 gas
	\item 
	\textbf{computing a Keccak-256 hash}: 30 gas + 6 gas for each 256 bits of data being hashed
	\item 
	\textbf{sending a transaction}: 21,000 gas
\end{itemize}

Both \textbf{gas price} and \textbf{gas limit} are set for each transaction: the \textit{gas limit} is the maximum amount of gas the sender is willing to pay so the fees are computed as $fees = gas_{price}*gas_{limit}$ which determine the max amount of \textit{wei} the sender is willing to pay for the transaction.
The fees are \textbf{rewards for miners} for the effort to run computations and validate transactions: the higher the gas price, the more likely miners will select the transaction.
\begin{enumerate}
	\item 
	if \texttt{gas\_limit * gas\_price > balance} then \textbf{halt}
	\item 
	deduct \texttt{gas\_limit * gas\_price} from \texttt{balance}
	\item 
	set \texttt{gas = gas\_limit}
	\item 
	run code deducting from gas the amount required to run code
	\item 
	after termination return remaining gas to balance
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230417124601.png}		\caption{Gas workflow process}
	\end{figure}
	
\end{enumerate}

If the sender does not provide the necessary gas to execute the transaction, the transaction is \textit{out of gas} and is considered \textbf{invalid}: the transaction aborts and the state reverts to previous state. Also \texttt{gas\_limit * gas\_price} is still deducted from balance because the node has spent the effort to run the calculations before running out of gas.

The \textbf{gas limit} is not considered for internal transaction because is determined by the external creator of the original transction, by some EOA. Surely must be enough to carry out all the transactions, including any sub-executions that occur as a result of that transaction, such as contract-to-contract messages.
If, in the chain of transactions and messages, a particular message execution runs \textit{out of gas}, that message’s execution will revert, along with any subsequent messages triggered by the execution but the parent execution may not need to revert entirely.
\paragraph{Transaction format}\label{sec:transaction-format}
The transaction format, sketched entirely in the following image, is serialized using the \textit{RLP - Recursive Lenght Prefix} encoding scheme.
\begin{figure}
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230417125024.png}
	\caption{Transaction fields}
\end{figure}

The fields are:
\begin{itemize}
	\item 
	\textbf{TO}: 20-byte address of EOA or contract. There is no validation of the field so if invalid, Ether sent is burnt. Compared to bitcoin, there is only one output and not script;
	\item 
	\textbf{value}: the value is directly inserted in the transaction and there is no reference to the previous transaction output. This field is empty for the function invokation but contains a valid value for a payment. The value is transmitted to EOA to be added to the target address account or to contract accounts. In the last case, if no function is found, increase the balance of the contract, otherwise the function named in the data payload must be payable (\textit{can accept Ether from the caller}).
	\item 
	\textbf{Data}: \textbf{to contracts accounts}: work as a function selector, allowing to unambiguously identify which function to invoke. The function arguments are encoded according to the rules for the various elementary types. \textbf{For contract creation transactions}, it allows to deploy a new contract on the blockchain where data payload contains the compiled bytecode which will create the contract.
	\item 
	\textbf{Gas limit}: maximum amount of gas the sender is willing to pay
	\item 
	\textbf{Gas price}: determined price of a single unit of gas
	\item 
	\textbf{V,R,S}: represent the signature components of an ECDSA digital siginature of the original EOA. Allows to compute the address of the account sending the transaction.
\end{itemize}

\section{Solidity}\label{sec:solidity}
Differently from Ethereum, Bitcoin it's not considered when talking about smart contract because scripts are only to verify the spending of the token, not to support the full execution of user's code.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.40]{images/Pasted image 20230421143519.png}
	\caption{undefined undefined}
\end{figure}


\textbf{Solidity} is a contract-oriented high level language for the \textit{EVM}. It's a statically-typed, objected oriented language: \textit{smart contracts} are similar to classes. The version of the compiler used it's defined by the \texttt{pragma} instruction.
The overall lifecycle is:
\begin{enumerate}
	\item 
	Write code in high-level language
	\item 
	Compile to EVM bytecode
	\item 
	Deploy witha  transaction. The contract code is \textit{read only}
	\item 
	Call function with a transaction
\end{enumerate}
\subsubsection{Contract example}\label{sec:contract-example}
The purpose of this contract is to create tokens on top of Ethereum, as sort of "layer 2 crypto": only the creator of the contract can mint new tokens and anyone who has an Ethereum account can exchange these tokens.

Differently from coin, \textbf{tokens} are build on existing blockchain and are simpler to create because are implemented as smart contracts and leverage security and reputation of the existing blockchain on which are based.

\begin{lstlisting}
	pragma solidity >=0.4.16 <0.9.0; 
	contract Token { 
		address public minter; 
		
		#associates address to amount of token
		mapping (address => uint) balances; 
		
		constructor() public { 
			minter = msg.sender; 
		}
		function mint(address owner, uint amount) public { 
			require (msg.sender = minter); 
			balances[owner] += amount; 
		
		} 
	function send(address receiver, uint amount) public { 
		if (balances[msg.sender] < amount) return; 
		balances[msg.sender] -= amount;
		 balances[receiver] += amount; 
	 } 
 	function queryBalance(address addr) public view returns (uint balance) { 
 		return balances[addr];
 	} 
}
\end{lstlisting}

The \texttt{constructor()} is autoamtically invoked when the contract is firstly deployed
The type of ech variable is specified at compile time and most types can be \textit{cast}, like \texttt{bool, unit8, int256, address, string, byte[], mapping(keyType => valueType)} where the lastone is similar to an hashmap.
\paragraph{\texttt{pragma} directive}\label{sec:pragma-directive}
The \texttt{pragma solidity} directive or \textit{"version pragma"} defines the versions range of the compiler which can be used. This instructs the compiler to check whether its version matches the one required by the pragma: if does not match, the compiler issue an error. So it's used to reject compilation with future compiler version that might introduce \textbf{incompatible changes}. The caret \texttt{\^} before the version number points in \texttt{pragma solidity >= 0.4.16 <0.9.0} out that not a compiler earlier version of 0.5.2 and not a compiler after 0.6.0. If no caret is specified all the versions newer than the ofe are referred as ok.
\subparagraph{\texttt{address} type}\label{sec:address-type}
The address is a $20$ byte value represented in hexademical prefixed with $0x$: it does not allows arithmetic operations and it's used to store address of contracts. Remember that, based on the account type:
\begin{itemize}
	\item 
	\textit{Address for contract}. defined at the time of contract is created
	\item 
	\textit{Address of EOA}: hash of the public key of an EOA.
	The \texttt{address} has several properties which can be queried, like the \texttt{address.balance} that contains the $wei$ of the address, or the \texttt{address.code} which contains the code of that address  (\textit{that may also be empty}).
	An address can also be assigned as \texttt{address owner = msg.sender} where the right variable is in the \textit{global namespace} thus can be the address that sent the transaction containing the call to the function, either the EOA's address or another contract address.
\end{itemize}
\subsubsection{Data store model}\label{sec:data-store-model}
Data in Solidity are of two types:
\begin{itemize}
	\item 
	\textbf{Storage}: variables stored permanently on the blockchain, stored in a Merkle Patricia trie of the block. It uses gas so must be avoided if not necessary.
	\item 
	\textbf{Memory}: stored during function execution, used mainly for temporary variables and defined by the \texttt{memory} keyword.
\end{itemize}

The \textbf{storage} model is a sort of \textit{huge array}, initially full of zeroes: each value in the array is $32$-bytes wide and there are $2^{256}$ such values so each state variable declared in teh smart contract will occupy a slot of \textbf{depending on its declaration postiion} and its type.

The \textbf{memory} model, differently, is a sort of huge array initially full of \textit{zeroes}: variable, structures and array are mapped to the location of this array so the storage is \textit{sparsely populated} and zeros values \textbf{are not stored} (\textit{thus an absent key is defined as a mapping to zero}).
\textit{Static data} is stored contigously item after item with the first variable, which is stored in slot at position $0$, following according to the order or declaration. Thus for each variable, a size in $byte$
is determine according to its type: multiple, contigous items that needs more than $32$ bytes are packedinto a single storage slot if possible.
As an example, the following snippet:
% python null
\begin{lstlisting}
	contract example { 
		uint256 a; 
		unit256 [2] b; 
		struct exStruct { 
			uint256 name; 
			uint256 value;
		} 
		exStruct c; 
	}
\end{lstlisting}

Determine the following slot in the model at \textbf{compile time}:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230424103001.png}
	\caption{Slot determined at compile time}
\end{figure}


Solidity also have \textbf{dynamic types} (\textit{like dynamic arrays}): in this case, for the mapping, you have an empty slot associated with the map: the slot is computed using the \texttt{kekka256} hash function, thus the location is chosen at random without experiencing a collision (\textit{there is no allocation and release step from a storage pool}).
After computing the hash of the slot, lay the elements of the dynamic arrayas for statically sized-arrays as pictured in \ref{sized-array}:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230424103242.png}
	\caption{Sized array slots}
	\label{sized-array}
\end{figure}

The position $5$ contains the length while the \texttt{kekka256(5)} contains the starting position of the elements.

Consider another code example that involves a \textit{dynamic hashmap \texttt{e}}:
\begin{lstlisting}
	contract example { 
		uint256 a; 
		unit256 [2] b; 
		struct exStruct { 
			uint256 name; 
			uint256 value;
		} 
		exStruct c; 
		exstruct d[];
		mapping(uint256 => uint256) e;
	}
\end{lstlisting}

To avoid collisions we \textbf{concatenate} the key and the mapping slot, hashing the resulting value with \texttt{kekka256} (\textit{SHA-3}).
concatenard with the position of the empty slot allows to retrieve  the associated value.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.50]{images/Pasted image 20230424103523.png}
	\caption{Dynamic mapping example slots}
\end{figure}

The empty slot indicates the starting point of the data structure: the position of the hashed items is obtained concatenating the hash of a given key with the empty slot position.
This is like use the entire 256-bit addressable memory space: when the \texttt{map} is declared is like that all the possible key exists and every key implicitly bound to all-zero value.
The key data is not stored in a mapping, only its hashed value is: the value is stored directly, without double indirection, pointers or linked lists thus the operations are guaranteed to be executed in $O(1)$.
\subsubsection{Constructors}\label{sec:constructors}
Consider:
% python null
\begin{lstlisting}
	contract Token{
		address public minter;
		mapping (address => uint) balances;
		constructor() public {
			minter = msg.sender;
		}
		...
	\end{lstlisting}
	
The  \texttt{constructor} function is invoked only when initially creating the contract and cannot be invoked afterwards. It's an optional function but if used must be declared with the \texttt{constructor} keyword in the new versions. The function is used for customization or setting the initial state of the contract.\\
The \texttt{msg} variable provides information contained in the transaction/message call that actioned the contract: those information are defined in the \textbf{global namespace} to provide the context on the transaction that has invoked a function.
The function signature is structured as pictured in \ref{func-sign}.
	\begin{figure}[h]
		\centering
		\includegraphics[scale=0.50]{images/Pasted image 20230424104409.png}
		\caption{Function signature structure}
		\label{func-sign}
	\end{figure}
	
There are two kinds of modifiers:
\begin{itemize}
		\item 
		\textbf{Visibility}: define who can \textbf{trigger the execution}, defining the behavior of the \textit{caller}, like:
		\begin{itemize}
			\item 
			\texttt{external}: can be triggered by third parties via transacton or from other contracts. (\textit{if \texttt{f} is external, \texttt{f()}  does not work while \texttt{this.f()} works}). This modifier is more efficient respect to \texttt{public} when receive large array of data.
			\item 
			\texttt{internal}: can be accessed by the current contracts and inheriting from it
			\item 
			\texttt{public}: without restrictions (\textit{internal and external})
			\item 
			\texttt{private}: accessible only from the contact where ae they are defined adn not by derived contracts
		\end{itemize}
		\item 
		\textbf{Mutability}: define who can access (\textit{and modify}) the data, like:
		\begin{itemize}
			\item 
			\texttt{view} functions: cannot modify state or call other non-view functions
			\item 
			\texttt{pure} function: cannot read or modify the state, or call other non-pure functions
		\end{itemize}
	\end{itemize}
	\subparagraph{Error handling}\label{sec:error-handling}
	Consider:

	\begin{lstlisting}
		function mint(address owner, uint amount) public { 
			require (msg.sender = minter); 
			balances[owner] += amount; 
			
		}
	\end{lstlisting}
	
	Only the deploter of the contract can mint tokens: \texttt{require} tests conditions on function arguments or transaction fields, ensure condtions that cannot be detected until execution time. It throws an error and stop execution if some condition is not true: it's known as \textit{state revert function} because undoes all the changes made in the current call. It consumes the gas up to the point of failure, refunding the remaining gas.
	\subparagraph{Event logging}\label{sec:event-logging}
	Events are away for smart contracts written in Solidity to log that something has occurred: interested observers can watch for event and react accordingly: \textit{events} are declared with the \texttt{event} jeyword and logged with \texttt{emit} keyword. They can also contains parameters.
	% python null
	\begin{lstlisting}
		pragma solidity ^0.4.21; 
		contract Counter { 
			uint256 public count = 0; 
			event Increment(address who); // declaring event 
			function increment() public { 
				emit Increment(msg.sender); // logging event 
				count += 1; 
			} 
		}
	\end{lstlisting}
	
	Events are an abstraction using the \textit{logging} feature of the EVM: applications in the frontend can subscrube and listen for events as \textbf{callbacks}. The event logs are registered in the \textit{transaction log}, a special data structure on the blockchain thus they can also be indexed and filtered.
	Referring the token contract previously seen, consider to introduce the events in the token contract where the \texttt{emit} instruction emit an event each time tokens are transferred:
	% python null
	\begin{lstlisting}
		
		pragma solidity >=0.4.16 <0.9.0
		contract Token{
			address public minter;
			mapping(address => uint) balances;
			event Sent(address from, address to, uint amount);
			function send(address receiver, uint amount) public {
				if (balances[msg.sender] < amount) return;
				balances[msg.sender] -= amount;
				balances[receiver]+=amount;
				emit Sent(msg.sender, receiver, amount);
				
				
			}
		}
	\end{lstlisting}
	\subsubsection{Example: lottery on blockchain}\label{sec:example-lottery-on-blockchain}
	The main problem is how obtain a \textit{source of entropy} in a deterministic environment. A solution may be:
	\begin{itemize}
		\item 
		\textit{using external information}: this add complexity and external dependencies.
		\item 
		\textit{using blockchain data}: use the blockhas as a source of randomness but miners can perform an attack and change the timestamp of the block.
		More complex solution we'll see involves using \textit{RanDAO} or \textit{VRF - Verifiable Random Functions} used in Algorand.
		The solution here adopted involves using the blockhash to introduce randomization:
	\end{itemize}
	% python null
	\begin{lstlisting}
		pragma solidity ^0.8.0; 
		contract SimpleLottery { 
			uint public constant TICKET_PRICE = 1 gwei; 
			address [] public players; 
			address payable public winner; 
			uint public ticketingCloses;
			constructor (uint duration) {
				owner= msg.sender; 
				ticketingCloses = block.timestamp + duration;
			} 
			function buy () public payable {
				require(msg.value == TICKET_PRICE); 
				require(block.timestamp < ticketingCloses); 
				tickets.push(msg.sender); 
			}
			
		\end{lstlisting}
		
		The instruction \texttt{ticketingCloses = block.timestamp + duration;} takes the \textbf{current block timestamp} (\textit{timestamp of block in which the transaction is validated}) returned as UNIX timestamp and add a duration to indicate for how long is possible to buy tickets.
		The \texttt{require} functions are used to ensure that the condition are valid before execute the specific method actions: they usually refer to the \textit{global namespace}.
		To access the \textit{transaction properties} we can use:
		\begin{itemize}
			\item 
			\texttt{msg.sender}: sender of the call/of the message (address)
			\item 
			\texttt{msg.value}: value sent in wei (\texttt{uint}) (\textit{the investment in our case})
			\item 
			\texttt{msg.gas}: gas unused after the execution of the transaction
			\item 
			\texttt{msg.data}:  complete calldata ($bytes$)
			The methods to determine the winner and send the prize are:
		\end{itemize}
		% python null
\begin{lstlisting}
function drawWinner () public { 
	require(block.timestamp > ticketingCloses + 5 minutes); 
	require(winner == address(0)); //ensure no winner it still chosen, 
	//0x0 as uninitialized address
				
	bytes32 bhash=blockhash(block.number-1); 
	bytes memory bytesArray = new bytes(32); 
				
	for (uint i; i <32; i++){
		bytesArray[i] =bhash[i];
		bytes32 rand=keccak256(bytesArray);
		winner = payable(tickets[uint(rand) % tickets.length]);
		}
}

function withdraw () public { 
		require(msg.sender == winner);
		winner.transfer(address(this).balance);
		} 
	fallback () payable external { 
		buy(); 
	} 

\end{lstlisting}
	
	\texttt{address(0)} corresponds to the \texttt{NULL} value for the address data type.
	To \textit{flip a coin} in the contract we use \texttt{blockhash(block.number-1)}: thie ensure to have the same random value for each node that execute the contract. The function take the hash of the previous block, being determinstic. The computed value \texttt{bhash} is used as a form of seed for \texttt{keccak256} that compute the 256 hash function.
	The  \texttt{winner} variable contains the address of the winner, associated with the \texttt{payable} type that indicates that the transfer of the money in the balance of the smart contract must be directed to this address (\textit{either EOA or another smart contract}).
	
	The \textbf{global variables} allows also to access to information about the specific block, using the variable \texttt{block} or accessing the transaction information using the \texttt{tx} variable. In a chain of transaction, this last variable, for example, is able to retrieve the information about the \textit{origin transaction} that actiond the chain. Differently the \texttt{msg} global variable allows only to access the information about the last recent transaction that activated the executing function.
	\paragraph{Sending and receiving ether}\label{sec:sending-and-receiving-ether}
	There are two main ways for sending Ether:
	\begin{enumerate}
		\item 
		through transaction generated by EOAs
		\item 
		transferring Ether between smart contracts
		This second method can lead to an attack called \textbf{DAO attack or reentrancy attack}: because your code may interact with a contract never seend, transferring Ether and executing third party code with an unknown behavior.
		A solution to this scenario is to \textbf{limit the amount of gas} that a function execution can do: this allows to limit the number of action to be executed in a given smart contract. This forbid recursive call.
		This methods are implemented as:
	\end{enumerate}
	\begin{itemize}
		\item 
		\texttt{address.trasnfer(value)}: allows gas limit on the execution of the function of the contract receiving funds (\textit{2300 unit}). It throws an error if transfer fails and propagate the failure to the caller.
		\item 
		\texttt{address.send(value)}: return \texttt{false} if trasnfer fails but does not throw excetion because the responsibility is delegated to the user to manage failures. The gas limit on the execution of the contract \textbf{receiving funds} is setted to \texttt{2300} unit and
		\item 
		\texttt{(bool, success, ) = address.call{value: 10 ether, gas: 10000}("")}: this method allows to explicitly set the gas limit so if not specified it's not bounded to any value. It's a lower level function.
		The $2300$ gas limit is arbitrary and can be insufficient for certain trusted operations that must be executed: a limit must be setted always to avoid certain type of recursive attacks.
	\end{itemize}
	
	The operation to \textbf{receive Ether} involves using a \texttt{fallback} function without an explicit name.
	% python null
	\begin{lstlisting}
			fallback () payable external {...} }
	\end{lstlisting}

The \texttt{fallback} function is triggered when:
\begin{itemize}
	\item 
	another contract calls a function in the fallback's enclosing smart contract but the called function name does not mach or exists.
	\item 
	if marked \texttt{payable}, a transaction payment is sent to the contract, without an explicit function call by the sender and no receive function is declared.
	This function must be \textit{externally called} thus cannot be called from inside the contract in which they are written. When a user sends money to the contract the fallback function is invoked.
	Respect to the previous lottery example, the \texttt{fallback} function is structured as:
\end{itemize}
% python null
\begin{lstlisting}
	fallback () payable external {...} }
	function buy() public patable {
		require
	....
	}
\end{lstlisting}



A \textit{modifier function} allows to verify a given condition, even parametized, to condition the execution of a function and reuse the check in several different function execution.

\section{Smart Contracts: Security Vulnerabilities}\label{sec:smart-contracts-security-vulnerabilities}
A \textit{\textbf{DAO - Decentralized Autonomous Organization}} is an organization in whose management is decentralized and decision are autoamtized though smart contracts thus rules are encoded in a smart contract, removing the need for a central governing authority. The main goals of this type of organization is to reduce costs and provide more control and access to investors.\\
A \textit{DAO} is a platform that allows everyone with a project to pitch their idea to the community for funding. Investors from around the world can send \texttt{ETHER} to a unique wallet in exchange for \textbf{DAO Tokens}: thosetokens give voting rights so the funds are pooled together.\\
If a proposal passes a preliminary's curator checks, owner of a DA tokens can vote it, proportionally to their token: if a proposal is approved by a \textit{quorum} of all tokens, the DAO automatically trasnfer \textit{Ether} to the smart contract that represents the proposal. Finally, if the proposal increment the project value, stakeholders receive their rewards.\\
Basically a DAO is a \textit{complex smart contract} with many features to reflect laws, respecting the stakeholder's rights, guaranteeing the right of a stakeholde rto require his shares to have back his funds when a prposal they do not want be a part of get approved despite their objection (\textit{Appraisal right}).
\subsubsection{Simplified DAO}\label{sec:simplified-dao}
Imagine the following simplified scenario:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.30]{images/Pasted image 20230427075120.png}
	\caption{Simplified DAO scenario}
\end{figure}

It's noticeable to highlight that the \textit{wallet} contract does not use the function \texttt{send} or \texttt{trasnfer} to send \textit{Ether}: it uses a previous Solidity version of the call function, named \texttt{call.value}, which does not specify any gas restriction.
The \texttt{withdraw} method, the first time it's called, allows to transfer $10$ \textit{Ether} from the wallet: if a second call is made, no transfer can happen because the \texttt{balance} is updated to $0$.
This simple scenario allows to describe a set of vulnerabilities that lead to an attack in which the user contract can withdraw more than 10 \textit{Ether}.
\subsection{1. Re-entrancy vulnerability}\label{sec:1-re-entrancy-vulnerability}
A \textit{re-entrancy} is a scenario in which an attacker performs \textbf{recursive withdrawals} to steal all \textit{Ethers} locked in a contract. A procedure is \textit{re-entrant} if its execution:
\begin{itemize}
	\item 
	can be \textit{interrupted} in the middle
	\item 
	\textit{iniated over (re-entered)}
	\item 
	both runs complete without errors
	For a contract, a \textit{non-recursive}, \textbf{re-entered} function allows the attacker to exploit the \textit{\textbf{fallback/receive}} function to re-enter the function. The \textit{atomicity} and sequentiality of transaction may induce programmers to believe that it cannot be re-entered.
	In general, \textit{re-entrancy} may result in unexpected behavior and \textit{loops of invocations} which eventually consume all the gas.
\end{itemize}

The below code presents the \texttt{InsecureEtherVault} contract, providing a simple vault allowing users to deposit their Ethers, transfer deposited Ethers to other users, withdraw all deposited Ethers, and check their balances.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.30]{images/Pasted image 20230427080137.png}
	\caption{InsecureEtherVault Solidity code}
\end{figure}


As soon as the low-level function \texttt{call} is executed, a number of Ethers indicated by the \texttt{balance} variable would be sent to the user wallet or external contract (Step 4). If an attacker’s \texttt{Attack} contract is the recipient, the contract can do the reentrancy by recursively calling the \texttt{withdrawAll} function (Step 5) to drain out all Ethers locked in the \texttt{InsecureEtherVault} contract. 

The attack is effective here because the \texttt{call} function is executed before updating the withdrawer’s balance to 0 (i.e., \texttt{userBalances[msg.sender] = 0}). Consequently, the \texttt{Attack} contract can interrupt the control flow in the middle and execute the loop calls to the \texttt{withdrawAll} function. \textbf{Since the \texttt{withdrawAll} function would still retain the balance before the update, the \texttt{Attack} contract can steal all Ethers.} (\textit{See \href{https://www.serial-coder.com/post/solidity-smart-contract-security-by-example-02-reentrancy/}{Solidity Security By Example: Reentrancy} for the full description and patching})

The solutions to the proposed attack method are:
\begin{itemize}
	\item 
	to use the functions \texttt{send()} or \texttt{transfer()} instead of \texttt{call.value()} (\textit{in \texttt{InsecureEtherVault}}) or to \textbf{manually limit} the amount of gas passed to \texttt{call.value()}. This last method would not allow for recursive withdrawal calls due to the low gas stipend.
	\item 
	to \textit{update the user balancer prior to the transfer:} any recursive withdrawal call would attempt to trasnfer a balance of $0$ Ether.
	A general rule is that if no \textit{internal state updates} happen after an \textit{Ether} trasnfer or an external function call inside a method then the method is \textbf{safe from the re-entrancy} vulnerability.
\end{itemize}
\subsection{2. Arithmetic over/under flow}\label{sec:2-arithmetic-overunder-flow}
Consider the following contract:
% python null
\begin{lstlisting}
pragma solidity ^0.8.0; 
contract Token { 
		mapping(address => uint) balances; 
		uint public totalSupply; 
	constructor (uint initialSupply) {
			balances[msg.sender] = totalSupply = initialSupply; 
	} 
	function transfer(address to, uint value) public returns (bool) { 
			require(balances[msg.sender] - value >= 0);
			balances[msg.sender] -= balances[msg.sender] - value; 
			balances[to] = balances[to] + _value;
			return true; 
	} 
	function balanceOf (address owner) public view returns (uint balance) { 
			return balances[_owner];
	} 
}
	
\end{lstlisting}

In the previous code the \texttt{require(balances[msg.sender] - value >= 0);} check allows to verify that the \texttt{value} can be subtracted from the sender's \texttt{balance}, but still allows to perform the attack.
The \textit{vulnerability} is created by an operation requiring a \textbf{fixed-size variable} to store a number that is outside th range of the variable's data type like:
% python null
\begin{lstlisting}
		uint8 x = 0;
		uint8 y = x - 1; //y is 255
\end{lstlisting}

In this case, the \texttt{uint} indicates an \textit{unsigned integer of 8 bits, non negative number} thus subtracting $1$ from \texttt{x} results in an underflow that result in $255$.
This scenario can be exploited in the \texttt{trasfer} function because if the attacker has a $0$ balance, the function is called with \texttt{\_value} as a non-vero value that allows to obtain a positive value and thus pass the \texttt{require} check so thebalance will be updated with a positive number.
To avoid this scenario, it's better to not use the Solidity arithmetic operators directly but use third-party library like \textbf{SafeMath library}.
\subsection{3. Front Running attack}\label{sec:3-front-running-attack}
Ethereum nodes pool transactions and form them into blocks: all the transactions are visible in the \textit{Mempool} of a full node for a short period before they are executed (\textit{thus inserted in a block by a miner}) so they can be \textit{observed} by nodes to potentially perform an attack.
The \textbf{miner} who solves the block also chooses which transaction from the pool is elegible to enter the block: typicaly the order is given by the \texttt{gasPrice} of each transaction. The \textbf{attacker} can observe a transaction $T$ before it's commited ina  block so he can create a transaction $T_{i}$ of their own that pays a \textit{higher gas price}, allowing $T_{i}$ to be executed before $T$: the order of the transaction can influence the final price payed when the transaction is executed thus it's possible that $T_{i}$ may indirectly alter the cost payed by the transaction $T$.

Possible solutions to prevent this scenario are:
\begin{itemize}
	\item 
	\textit{upper bound} on \texttt{gasPrice}: prevents users from getting preferential transaction ordering but does work if the \textbf{miners are also the attacker}.
	\item 
	use a \textit{commit-reveal scheme}:  transaction is sent with hidden information so after the transaction is included in the block, the user send another transaction revealing the data that was sent.
\end{itemize}
\subsection{4. Transaction ordering attack}\label{sec:4-transaction-ordering-attack}
This type of attack is a \textbf{race condition attack}: if you purchase an item at a price advertised, you expect to pay that price.  This attack will \textit{change the price during the processing of your transaction} because some one else (\textit{the contract owner, miner or another user}) has \textbf{sent a transaction modifying the price before your transaction is complete}.
Two transactions can be sent to the \textit{mempool/tx-pool}, the order in which they arrive is irrelevant: the attacker could be a \textbf{miner}, as the miner can choose the order in which the transactions are mined, or may be a \textbf{node inserting a transaction with a higher fee}. A problem in Smart Contracts that rely on the state of storage variables to remain at certain value according to the order of transactions. Here an example:
% python null
\begin{lstlisting}
	pragma solidity ^XXXXXX; 
	contract TransactionOrdering { 
		uint256 price; 
		address owner; 
		event Purchase(address _buyer, uint256 _price); 
		event PriceChange(address _owner, uint256 _price);
		
		modifier ownerOnly() { 
			require(msg.sender == owner); 
			_; 
		} 
		constructor TransactionOrdering() { // constructor
			owner = msg.sender; 
			price = 100; 
		}
		function buy() returns (uint256) { 
			Purchase(msg.sender, price); 
			return price; 
		} 
		
		function setPrice(uint256 _price) ownerOnly { 
			price = _price; 
			PriceChange(owner, price); 
		} 
	}
\end{lstlisting}

The \textit{owner} of the contract deploy it with  \texttt{price = 100}: the buyer of digital asset call the \texttt{buy()} function to set a purchase at the price specified. The contract owner calls \texttt{setPrice()} and update the \texttt{price} storage value to $150$. The contract owner sends the transaction with aa \textit{higher gas fees} so it's mined first, updarting the state of the contract due to the higher gas fee.
The buyers transaction gets mined soof after but not the \texttt{buy()} function will use the new update price of value $150$.
\paragraph{4. Miners attack}\label{sec:4-miners-attack}% python null
\begin{lstlisting}
	pragma solidity ^0.8.0; 
	contract Roulette { 
		uint public pastBlockTime; // forces one bet per block
		constructor() payable {} // initially fund contract 
		
		// fallback function used to make a bet 
		fallback () external payable { 
			// must send 10 ether to play 
			require(msg.value == 10 ether); 
			
			require(block.timestamp != pastBlockTime); 
			// only 1 transaction per block 
			pastBlockTime = block.timestamp; 
			if (block.timestamp % 15 == 0) { 
				// winner address 
				payable ap = payable(msg.sender);
				ap.transfer(address(this).balance); 
			} 
		} 
	}
\end{lstlisting}

It's like a \textit{simple lottery}: one transaction per block can bet $10$ ether for a chance to win all the balance of the contract. The \textit{basic assumptions} are:
\begin{itemize}
	\item 
	\texttt{block.timestamp} last two digits are \textit{uniformely distributed}
	\item 
	there would be a $1$ in $15$ chance of winning this lottery
	The \textbf{miners attack} consists in the miners adjust the timestamp: they can choose a timestamp such that \texttt{block.timestamp} \textit{modulo $15 = 0$}. In this way they may win both the \textit{Ether locked in this contract} and the \textit{block reward.}
\end{itemize}

In practice, miners \textbf{cannot choose arbitrary timestamp}, they must be \textit{monotonically increasing} thus block times cannot be set too far in the future. In any other case, the block will be rejected by the network.
\subsection{5. Phishing attack}\label{sec:5-phishing-attack}
Generally speaking, a phishing attack consists in the fraudulent attempt to obtain sensitive information like username, password, credit card details by appearing as a \textit{trustworthy entity} in electronic communication.
A phishing attack in Solidity may be perfomed by exploiting the global variable \texttt{tx.origin} (\textit{address of account that generated the transaction, the original external account}) instead of \texttt{msg.sender} (\textit{\textbf{immediate account}, external or contract that invokes the function}) :
\begin{itemize}
	\item 
	The attacker calls the target contract directlu thus his authorization is checked based on his \textit{personal address}
	\item 
	The attacker creates hiw own contract calling the target contract, runs a phising campaign to run the functionality on the attacker's contract.
	\item 
	The attackers contract makes a transaction call to the target contract but the call originates from the user's address via \texttt{tx.origin}
	\item 
	If the target contract processes the transaction via \texttt{msg.sender} the authorization check will be denied, forbidding to authorize the operation from the attacker
	\item 
	If the target contract checks authorization via \texttt{tx.origin}, the attacker is accessing the target as the victims address thus ca bypass any authorization checks and simply process functionality as the victim user.
	Here an example:
\end{itemize}
% python null
\begin{lstlisting}
pragma solidity ^0.8.0; 
contract Phishable { 
		address payable public owner; 
		constructor (address payable _owner) { 
			owner = _owner; 
		} 
		fallback() external payable {} // collect ether
		function withdrawAll(address payable recipient) public { 
			require (tx.origin == owner);
			recipient.transfer(address(this).balance); 
		} 
}
	
import "Phishable.sol"; 
contract AttackContract {
	Phishable phishableContract; 
	address payable attacker; // The attacker's address to receive funds 
	constructor(Phishable phishableContract, address payable attackerAddress) { 
		phishableContract = phishableContract; 
		attacker = attackerAddress; 
	} 
	fallback () external payable {
		phishableContract.withdrawAll(attacker); 
	} 
}
\end{lstlisting}

The \textbf{attacker}:
\begin{itemize}
	\item 
	deploys the \texttt{AttackContract}
	\item 
	convince the owner of the \texttt{Phishable} contract to send the \textit{Attacker Contract} some amount of Ether
	\item 
	the \texttt{fallback} function is invoked
	\item 
	in turn, the \texttt{withdrawnAll} is invoked
\end{itemize}

The \textbf{victim}:
\begin{itemize}
	\item 
	receives a call to \texttt{withdrawnAll}
	\item 
	the address that first initialised the call was the victim, that is the owner of the \texttt{Phishable} contract.
	\item 
	therefore, \texttt{tx.origin} will be equal to owner and the require of the \texttt{Phishable} contract will pass.
	\item 
	the victim sends all the funds to the attacker
\end{itemize}

\section{Tokenization}\label{sec:tokenization}
Tokens are \textit{coin-like} objets generalli lacking a legal framework: they are issued by a private entity for a specific use. The value of those tokens may be high but only within the community that makes use of them.
There are two main types of tokens:
\begin{itemize}
	\item 
	\textbf{Fungible}
	\item 
	\textbf{Non-fungible (NFT)}
\end{itemize}

The \textit{fungibility} of a token can be defined as \textit{"being freely exchangeable or replaceable, in whole or in part, for another of like nature or kind"}. This implies main properties like:
\begin{itemize}
	\item 
	\textbf{Interchangeability}: each token is interchangeable with other tokens of its same kind but there aren't defined features of that specific token.
	\item 
	\textbf{Merging}: can merge unit of fungible asse to get a higher value in quantity
	\item 
	\textbf{Divisibility}: can sen or receive a fraction of a token
\end{itemize}

Differently, a \textbf{non-fungible} item is when two items may look identical at a glance but each will have \textit{unique information or attributes} that makes them irreplaceable or impossible to swap. They are usually charaterized by \textit{scarcity} and \textit{originality}. In the category of \textit{NFT} there is a sub-category for \textbf{collectibles} that can include \textit{real-world collectible} (\textit{like Pokemon trading card}).

In the area of \textbf{Fungible tokens} we can identify two differen types:
\begin{itemize}
	\item 
	\textbf{Utility token}: application token or user tokens offered by a company giving future access to products or services. They are not an investment but better as a coupon.
	\item 
	\textbf{Security token}: as an hybrid between shares of a company and cryptocurrency. Gives the owner tights and obligation with voting rights and dividends, thus companies sell shares in form of cryptographic token.
\end{itemize}

The advantages of \textit{security tokens} are that the voting rights are realted to the amount of tokens owned: they can be offered throigh an \textit{ICO - Initial Coin Offer}.
The advantages of \textit{utility tokens} are evident when a company want to obtain financing for a project: it can create a \textit{coupon} that can be redeemed in the future for access to its services.
\subsubsection{ICO - Initial Coin Offer}\label{sec:ico---initial-coin-offer}
An ICO is basically a cryptocurrency version of a \textit{crowdfunding campaign}. The developer issue a \textit{limited amount} of tokens, ensuring that the token itself have a value and the ICO has a goal to aim for. The price can be statically \textit{pre-determined} or may increase or decrease depending on how the crowd sale is going. The buying process follows those steps:
\begin{itemize}
	\item 
	if someone wants to buy the tokens they send a particular amount of Ether to the crowd-sale address.
	\item 
	when the contract acknowledges that this transaction is done, they receive their corresponding amount of tokens.
	\item 
	ICO is successful if it is really well-distributed and a majority of its tokens is not owned by one entity
\end{itemize}

Despite the term \textbf{fungible token} and \textbf{currency} are used interchangeably, the technology is different because the first are usually implemented on the blockchain of the second one.
\paragraph{Semi-fungible token (SFT)}\label{sec:semi-fungible-token-sft}
Alonside the \textit{fungible} and \textit{non-fungible (NFT)} tokens, a third type is  known as \textbf{Semi-fungible Token (SFT)}: it can \textit{change} the state from being \textit{fungible} to \textit{non-fungible}.
An example is represented by a \textit{ticket} for the final football championship match:
\begin{itemize}
	\item 
	interchangeable for any other ticket of the same match, and same seating class
	\item 
	after the match is over, can no longer be used for entering to the stadium
	\item 
	may become a collector’s item for fans with a different value assigned to it.
\end{itemize}
\subsection{ERC Tokens}\label{sec:erc-tokens}
\textit{ERC (Ethereum Request for Comments} standard define smart contract that have:
\begin{itemize}
	\item 
	a \textbf{pre-established standard structure} for storing and managing tokens
	\item 
	a set of \textbf{pre-defined functions} that can be executed on the token
	\item 
	give developers the guarantee that assets will behave in a specific way and describe exactly how to interact with the basic functionality of the assets.
\end{itemize}
	The most widespread standard is \textbf{ERC-20}, now used as standard for \textit{Fungible tokens (FTs)}, while the \textbf{ERC-721} is used for \textit{NFTs} and \textbf{ERC-1155} is for semi-fungible tokens.
Those three standard define different way of mapping addresses to data it represent:
\begin{itemize}
	
	\item 
	ERC 20 maps \texttt{addresses} to \texttt{amount}
	\item 
	ERC 721 maps unique \texttt{IDs} to \texttt{owners}
	\item 
	ERC1155 has a nested mapping of \texttt{ID} to \texttt{owners} to \texttt{amount}
\end{itemize}

\subsubsection{ERC-20 tokens}\label{sec:erc-20-tokens}
The \textbf{ERC-20 tokens} allows to implement a \textbf{sub-accounting system parallel to the Ethereum} main ledger, having their own unit of account.  There is no mixing with the Ether balances of the addresses while, at the same time, guarantees the transparency, traceability and security provided by the main Ethereum network.

A \textit{\textbf{token contract}} contains a map of account addresses and their \textbf{balance}: the concept of balance may vary depends from the token contract (\textit{it may represent an amount of object, right, monetary values, etc}).

The \textit{\textbf{mandatory functions}} the standard define are
\begin{itemize}
	\item 
	\texttt{totalSupply}: returns the total units of tokens that currently exist in the token smart contract
	\item 
	\texttt{balanceOf}: given an address (\textit{user}) returns the token balance of that address
	\item 
	\texttt{transfer()}: given ana ddress and amount, trasnfer the tokens to that address from the balance of the address that executes the transfer. It's a \textbf{single-step transaction}: just like a conventional crypto transaction between two wallets.
	\item 
	\texttt{transferFrom()}: allows to transfer tokens from an address that is not that you own
	\item 
	\texttt{approve}: it's used in tandem with \texttt{transferFrom} function, allowing the owner to approves a delegate address to withdraw tokens to trasnfer to other account. It define also the \textbf{maximum amount of allowed token} to trasnfer.
	\item 
	\texttt{allowance}: implement a \textbf{two-step payment process}, allowing a third party to carry out a transaction of token on your behalf. It's used for cyclic payments (\textit{like subscription}). It checks also the current \textit{approved number of tokens by an owner to that specific delegate} (\textit{the max setted by \texttt{approve} function}).
	while the \textit{\textbf{optional fields}} defined are:
	\item 
	\texttt{name}: return human readable name of the token
	\item 
	\texttt{symbol}: human-readable symbol for the token
	\item 
	\texttt{decimal}: number of digits (\textit{up to 18}) that come after the decimal place, when displying values on the screen. If the decimal is $2$, the token amount is divided by $100$ to get its visual representation. This field is required because Ethereum does not work with decimal number but only integers.
\end{itemize}
\subparagraph{Allowance example}\label{sec:allowance-example}
Consider user \texttt{A}  with 100 tokens and user \texttt{B}. \texttt{A} want to give permission to \texttt{B} to spend all $100$ tokens, so:
\begin{enumerate}
	\item 
	\texttt{A} calls \texttt{approve(address(B), 100)}
	\item 
	\texttt{B} checks how many tokens \texttt{A} gave him permission to use by calling \texttt{allowance(address(A), address(B)}
	\item 
	\texttt{B} sends to his account some of these tokens by calling \texttt{trasnferFrom(address(A), Address(B), 50)}
	in subsequent withdrawals, \texttt{B} can finish withdrawing the rest of the funds, but he can only go up to $100$ tokens.
\end{enumerate}
\subsubsection{ERC-721 Interface}\label{sec:erc-721-interface}
As mentioned, the \textbf{ERC-721} is the Ethereum token standard for \textit{NFTs} on the Ethereum blockchain. The \textit{main functions} to be implemented are:
\begin{itemize}
	\item 
	\texttt{ownerOf(ID)}: each ERC721 token is referenced on the blockchain via a unique \texttt{ID}. It return the owner's address.
	\item 
	\texttt{transferFrom}: transfer ownership of an NFT. The caller is responsible to confirm that the receiver is capable of receiving the NFTs, otherwise they are \textbf{permanently lost}.
	\item 
	\texttt{approve}: approves, or grants, another entity permission to transfer one of the tokens on the owner’s behalf
	\item 
	\texttt{SetApprovealForAll}: enable or disable approval for a third party to manage all the assets of the user (address) while executes this command
	\item 
	\texttt{SafeTransfer}: transfer the ownership of a NFT from one address to another address
	\item 
	\texttt{TransferFrom}: transfers ownership of an NFT, under the hypothesis the receiver is capable of receive NFTs.
\end{itemize}

Other information defined in a NFT contract are \texttt{name}, used to indicate the name of the token to external contracts and \texttt{symbol} that provides a token's shorthand name.
Other token-specific information can be associated to an NFT by using the \textit{\textbf{metadata}} section that provide nformation for a specific token \texttt{ID}. The metadata section can contains \textit{image, description, preview content, traits, unlockable content, supply, royalty etc}.

The \textbf{ongoing royalties} metadata, if setted, when the NFT is sold in the future, allows a certain percentage to go back to the original creator automatically. The creator is able to indicate the address to which the royalties will be sent,
The \textbf{unlockable content} metadata contains content that only the owner of the NFT can see or access.
\subparagraph{Storing metadata}\label{sec:storing-metadata}
It's possible to store the metadata in the smart contract, thus \textbf{on-chain data} or host it separately, obtaining \textbf{off-chain data}.
The \textbf{on-line} storage may be extremely expensive and not recommended, except for:
\begin{itemize}
	\item 
	\textit{information that must be persistenly recorded on-chain} (\textit{digital art})
	\item 
	on-chain logic must interact with metadata (\textit{e.g. age of Cryptokitties influence how kitty can breed})

\end{itemize}
	Differently, the \textbf{off-line} storage can be implemented in two different way: using a \textit{Cloud provider} or using \textit{IPFS -  InterPlanetary File System} that is a decentralized peer-to-peer network of computers around the world where data content is stored across multiple locations.




\end{document}