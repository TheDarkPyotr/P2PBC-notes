
# Data structure for DHT & Blockchains

In the following lecture the following data structure will be addressed (*also used for DHT and IPFS*):
1. Hash Pointer
2. Bloom filters
3. Merkle trees
4. Trie
5. Patricia Merkle Trie

## 1. Hash Pointers
An *hash pointer* is a pointer to where the information is stored using a cryptographic hash on the information itself. Starting from a given pointer we can ask to get the information back or verify that it hasn't changed. 
![[Pasted image 20230317155927.png]]

The key idea is to build data structures with hash pointers embedded: in the **blockchain** view, a list is linked with hash pointers by computing the hash to a block, hash again the entire block with its own hash pointer:
![[Pasted image 20230317160103.png]]

Is someone *tampers* the $k^{th}$ block of the chain, the hash of block $k+1$ is not going to match up because the **hash is collision resistant** so an adversary cannot tamper the data so that its hash is the same of the data before tampering (*as shown in the following picture*). 
![[Pasted image 20230317160241.png]]

Some **use cases** are useful applying this schema, like:
- **tamper-evident log**, a basic data structure in Bitcoin and Ethereum 
- in PoW-based blockchain, the block contains also the proof that PoW has been succesfully executed 
- if data is changed, PoW has to be re-executed for all the blocks 
- computationally infeasible

## 2. Bloom filter
Consider the set $S = \{s_{1}, s_{2}, ..., s_{n}\}$ of $n$ elements with $n$ very large. Usually we want to define an efficient data structure that support queries like "$k$ is an element of $S$" also called as **membership queries**: a given function $f$ returns value $true$ or $false$ according to the presence of $k$ in the given set $S$. 

The Bloom filter differently allows to provide an *approximate solution* to the set membership problem: 
![[Pasted image 20230317160722.png]]
The problem is translated into choosing a representation of elements in $S$ such that the result of the qery is computed *efficiently* and the space for the representaiton of the element is reduced. The result may be approximated to save space and arises the possibility of returning  **false positives**. 

#### Building a Bloom Filter
Given a set  $S = \{s_{1}, s_{2}, ..., s_{n}\}$ of $n$ elements, a vector $B$ of $m >> n$ (*generally $m > n*k$*) bits, $b_{i} \in \{0,1\}$. Choose $k$ ***independent hash functions*** $h_{1},...,h_{k}$ such that: 
	$\forall i. h_{i}: S \rightarrow [1..m]$, $h_{i}$ returns a value *uniformely distributed* in the range $[1..m]$ .
Construct the filter $B[1..m]$ such thath:
	$\forall x \in S: B[h_{j}(x)] = 1, \forall j = 1,2, ..., k$
Note that a bit in $B$ may be target for more than 1 element:
![[Pasted image 20230317161513.png]]
#### Look up
To verify if $y$ belongs to the set $S$ mapped on the bloom filter, apply $k$ hash functions to $y$ so we can determine that $y \in S$ if $B[h_{i}(y)]=1, \forall i = 1...k$: if at least a bit is equal to $0$, the element *does not belong to the set*. 
The problem of the **false positives** can occur if all bits are positive because another element or some combination of other elements could have set the same bits. 

###### Probability of false positives
Compute the probability that, after all the $n$ elements are mapped to the vector, a specificbit of the filter (*of size $m$*) has still value $0$:
		$p^{'} = (1 - \frac{1}{m})^{kn} \approx e^{\frac{-kn}{m}}$
The approximation is derived from the definition of $e$:
		$\lim_{x\to\infty} (1-\frac{1}{x})^{-x} = e$
A percentage of $e^{\frac{-kn}{m}}$ bits are $0$, after its construction. If we consider an element *not belonging* to the set, by applying the $k$ functions, a false positive is obtained if all the $k$ hash functions applied to that element return a value equals to $1$ and this happen with probability of:
			$(1 - e^{\frac{-kn}{m}})^{k}$
The **probability of false positives** depends on two parameters:
	- $\frac{m}{n}$: number of bits exploited for each element of the set
	- $k$: number of hash functions
If the first parameter is set:
- decreasing k increases the number of 0 and hence the probability to have a false positive should decrease,
- increasing k increases the precision of the method. Hence the probability of false positive should decrease.
Fixed the ratio $\frac{m}{n}$, the probability of false positives first decrease, then increases, when considering increasing values of $k$.
![[Pasted image 20230317163638.png]]
Let us now suppose that $k$ is fixed, the probability of false positives *exponentially decreases* when $m$ increases (*$m$ number of bits in the filter*).
For ***low values** of $\frac{m}{n}$* (a few bits for each element), the probablity is higher for large values of $k$:
![[Pasted image 20230317163622.png]]

![[Pasted image 20230317163655.png]]
A bloom filter becomes effective when $m =  c*n$, with $c$ constant value. 

##### Other operations
- ***Union***:-Given two Bloom Filters, B1 e B2 representing, respectively, the set S1 and S2 through the same number of bits and the same number of hash functions, the Bloom filter representing $S1 \cup S2$ is obtained by computing the bitwise OR bit of B1 and B2
- ***Delete***: note that it is not possible to set to $0$ all the elements indexed by the output of the hash functions, because of the conflicts. This operation is supported in a different version called *Counting Bloom Filter* in which each entry is a counter (*instead of a single bit*): at insertion time the counter in incremented while it's decremented at deletion.
- ***Intersection***: given two Bloom Filters B1 and B2 representing respectively, the sets S1 and S2 through the same number of bits and the same number of hash functions, the intersection of the Bloom filters obtained by computing the bitwise and of B1 and B2 and approximates $S1  \cap S2$. 

##### Bloom Filter usages
The set $S$ mapped on a bloom filter may be a set of ***Bitcoin addresses***: light-weight mobile nodes do not store the blockchain and build only the bloom filter with the addresses they are interested in. They send the $BF$ to a full node allowing bandwidth saving and privacy. The full node receives  a block $B$ of the blockhain and uses $BF$ to check if some address of $B$ belongs to $BF$. 
![[Pasted image 20230317164352.png]]
  In ***Ethereum*** is used to summarize events generated by a smart contract by finding all the tokens sold by a specific user in a block of 500 transanction. Instead of parsing all transaction, query a Bloom Filter (*or ***log bloom***) in the header of a block for the presence of that users and perform a search in the block only if a match is found.


## 3. Merkle Hash Tree
A merkle hash tree it's a data structure that allows to *summarize* a big quantity of data with the goal of verifying the correctness of the content. It's a **complete binary tree** of hashes built starting from a initial set of data:
- $i^{th}$ leaf stores the has of $h_{i}$ of $f_{i}$ (*$i^{th}$ *file*)
- an internal node contains the concatenations of the hashes of the sons of the node
- the last has tored in the root is called ***Merkle Root Hash***. 
 ![[Pasted image 20230317164834.png]]
Suppose have $n=8$ files $f_{1}...f_{8}$ and a collision resistant hash function $H$: go on hashing every two adjacent hashes by applying $H(x,y) = H(x|y)$  where $|$ indicate concatenation. 
A ***Collision-Resistant Hash Function*** for **Merkle Hash Tree (MHT)** takes $n$ input $(x_{1}...x_{n})$ and outputs a *Merkle root hash* $h = MHT(x_{1},...,x_{n})$.
The $MHT$ has an important proof-property: if a *verifier (Alice)* only known the Merkle root has $h$, the *prover (Bob)* can give Alice one of the values $x_{i}$ and convince ALice that is was the $i^{th}$ input used to compute $h$: to convince her, Bob gives Alice an associated ***Merkle proof*** without shoging all the other inputs. So if a merkle proof says that $x_{i}$ was the $t^{th}$ input used to computed $h$, no attacker can come up with another Merkle proof that says a differnet $x_{i} \neq x_{j}$ was the $i^{th}$ input used in $MHT$. 

#### Merkle Proof
The key idea is to have a given file $f_{i}$ and to download a small part of the Merkle tree called *Merkle Proof* of **Membership proof**: it contains the subset of hashes of the Merkle tree, that, together with $f_{i}$, allow to recomput the root hash. A proof is given for a specific *leaf node* and is comprises the leaf's sivlings, and the siblings of teach node on the path from the leaf to the root. 
The proof enables you to verify that $f_{i}$ was not modified by checking if the root hash obtained by the proof matches the Merkle root. 
![[Pasted image 20230317165901.png]]
To verify the proof, *"fill the blanks"* by computing the missing hashes in the dotted lines, then check if the computed Merkle root you kept locally is equel to the Merkle root obtain from the computation. 

###### Merkle Proof Consistency Theorem
*It is unfeasible to output a Merkle root h and two “inconsistent” proofs $\pi_{i}$ and $\pi_{i}'$ for two different inputs $x_{i}$ and $x_{i}'$ at the $i^{th}$ leaf in the tree of size $n$.
- ***Proof (by intuition)***:
	if the Merkle proof is verified, you were able to recompute the root hash by using $f_{i}$ as the i-th input and the Merkle proof as the remaining inputs. If the proof verification had yielded the same hash but with a different file  as the i-th input, this would yield a collision in the underlying hash function H used to build the tree. *Is not possible if H is collision resistant*.

#### Rationale behind large merkle proofs
The main reason to not simply use the has of the files to check their integrity is that the hashes $h_{i}$ are much smaller than the files themselves: can be done by storing the hash $h_{i} = H(f_{i})$ of every file, rather than the Merkle root so when you download a file, only compute the hash $y_{i}=H(f_{i})$ and check thath $h_{i} = y_{i}$. 
The merkle proof solution is suitable in case of a huge number of files as in *certificate transparency project* which stores millions of digital certificates for HTTPS websites. The Merkle Tree may have hundres of millions of leaves and it's designed to scale to billions by mantaining a $O(log(n))$ size. 

##### Merkle Tress in BitTorrent
In BitTorrent can help ensuring that *data blocks received from other peers are received undamaged and unaltered*: a trusted third party, like the site indexing the `.torrent` stores the *root hash* and the *total size of the file and the piece size*. So a **peer** receives a piece and a *Merkle proof* for it, calculate the has of that piece, request the root hash from the trusted site and by combining this information the client can recalculates the root has of the tree and caompares it to the root hash it received from the trusted source. 

##### Merkle Tress in Bitcoin
In a transaction scenarios between Alice and Bob, if Alice need to verify if the transaction has been inserted in the blockchain and don't want to download the entire blockchain, can use different solution:
- *Insicure-polling*: Alice simply asks the nodes storing the full blockchain if Bob's transaction has been inserted in the blockchain. Bob can lie by sending a fake transaction.
- *Merkle-based solution*: build a Merkle tree of the transactions in a block, a full node sends a Merkle Proof to Alice so she can finds the root of the Merkle tree in the block headers. In this way she must download only the block headers and not the entire blockchain. 

##### Merkle Tress Complexity Summary
$n$ is the number of data items, $m$ hash size
- size of the Merkle tree: $O(n)$
- size of the Merkle root: $O(m)$ 
- size of the authentication path: $O(m log(n))$ 
- $log(n)$ hashes are sufficient for checking each data block

## 4. Trie
The Trie data structure is a tree-like data structure that is commonly used to store and retrieve strings efficiently. In a Trie, each node represents a prefix or a complete string, and each edge represents a single character.

The key operations of a Trie are inserting a string, searching for a string, and deleting a string. The complexity of these operations depends on the length of the strings being processed and the size of the character set.
![[Pasted image 20230317173742.png]]

**Insertion** in a Trie involves traversing the tree until the end of the string is reached, and then adding a new node for each character that does not already have a corresponding child node. If the string is already in the Trie, no new nodes are added. The time complexity of insertion is $O(m)$, where $m$ is the length of the string being inserted.

***Searching*** in a Trie involves traversing the tree from the root to the node corresponding to the last character of the string. If the path does not exist in the Trie, the search fails. The time complexity of searching is $O(m)$, where m is the length of the string being searched for.

**Deleting** a string from a Trie involves first searching for the string, and then removing the nodes that correspond to the string's characters. If the string is not in the Trie, no nodes are removed. The time complexity of deletion is also $O(m)$, where m is the length of the string being deleted.

The space complexity of a Trie is determined by the number of unique strings that are stored in it. The worst-case space complexity is $O(n*m)$, where n is the number of strings and m is the length of the longest string. However, in practice, the space complexity of a Trie is usually much less than this, since many strings share common prefixes and can be stored using shared nodes.

### Patricia Trie
Patricia stands for "*Practical Algorithm To Retrieve Information Coded In Alphanumeric*". It compress long one-child branches into single node. In the following pictures, on the left a standard Trie, on the right the associated Patricia Trie:
![[Pasted image 20230317172227.png]]



## 5. Patricia Merkle Trie
The **Patricia Merkle Trie** is a combination of both:
- Patricia Tries: to enable faster search of data, stores keys, while grouping their common path in a node 
- Merkle Tree: to maintain data integrity and tamper proof validation
It is organized as a tree with every node hashed in the sense of *Merkle proof*, grouping common paths in the sense of *Patricia tries*. 

Regarding the Patricia Trie, it is not limited to string representation but can be used to store (`key,value`) pairs. Keys are string represented by the trie and the vaue will be stored in the which is at the end of a key path. 
![[Pasted image 20230317172816.png]]

- **Branch node**: a node that has more than one child node. It stores links to child nodes, may also store a value.
- **Extension node**: a non-leaf node representing a sequence of nodes that has only one child. It sotes a key value that represents the combined nodes and a link to the next node.
- **Leaf Node/Value Node**: similar to an extension node. Instead of link, it stores a value. 
![[Pasted image 20230317173027.png]]

Key-value mapping represented in the Patricia trie `(BIN, 10) (BINARY, 8) (MOVE, 30) (MOVIE, 55) (TREE, 20) (TRIE, 48)`. 
On another example:
![[Pasted image 20230317173115.png]]
It's possible to ***"Merkelizing"*** the patricia trie by making the tree cryptographically secure, pairing each node with its hash. The root node becomes a cryptographic fingerprint of the entire data structure. The hash may be used for *lookup* in a database and to refenrence child nodes, as shown here:
![[Pasted image 20230317173304.png]]

The **Ethereum blockchain** store:
- the state of the contracts on the blockchain 
- a set of transactions in blocks
The state is a combination of `key/value` pair, may be that:
- `Key` is the address of an account, `value` is the account balance 
- `Key` is the address of a transaction, `value` is the transferred amount
Ethereum uses Merkle Patricia tries to store all the information on the blockchain.

The nodes of the Patricia Trie are *multi-element, structured records*, while hash function is applied to binary string  so it requires some kind of ***"serialization"*** to encode structured records as byte array (*like JSON, but more efficient*). 
Different techniques are used to encode a variety of data structures; two main techniques used by Ethereum are:
- ***Hex Prefix Encoding (HP)***: HP encoding is used for encoding/decoding Keys (Paths). 
- ***Recursive Length Prefix (RLP)***:  RLP is used for encoding/decoding Values, corresponding to keys (which may be structured values