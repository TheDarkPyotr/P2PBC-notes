## P2P Overlays - Unstructured overlays

### Napster/Gnutella overview
The basic idea of *Napster* was to outsource the storage and exchange of files to the users so most of the service was provided by users themselves. Napster was avle to locate the usrs that can provide the file: the server was only an index of contents. 

In a simplified scenario, Napster was a P2P music file sharing with a centralized index server or *Master server* with several peers: a peer get the index of contents from the master server with the address/reference to all the peers which have the desired information. 
There were pros of this system like the **resource sharing** in which every node pays its pariticpation by providing access to its resources. Also some cons are corcerned with the **centralization point** that still exists and were represented by the master server, which is a single point of failure. 

**Gnutella** as Napster was a distributed, irregular network of peers without a central authority or server: the connections between the node define an **overlay network**. Peers establish **non transient direct (e.g. TCP connections) connection** between themselves: they broadcast a query throught the virtual connection of the overlay network. 

![[Pasted image 20230224151453.png]]


As for Napster, the main pros was that there was no additional infrastructure, no administration and not a single point of failure but was an high network traffic with possibility of free riding. 

## Overlay Network
We define an overlay network as a *logical network* build on top of a physical network. Overlay links are **tunnels** through the underlying network: each logical link may correspond to a set of physical links and may transverse of a set of a router. 
![[Pasted image 20230224151810.png]]

Two main types of overlay network and an hybrid type:
![[Pasted image 20230224152607.png]]

### P2P protocol overview
A P2P protocol defines a set of messages that the peers exchange, their formaed and semantics: it's usually defined onver the P2P overlay. 
All P2P protocols shares common charateristics, like: 
- Define a routing strategy at application level of stack TCP/IP stack
- Identification of the peer through **unique identifiers** which are usually computed by an hash function. Particular *cryptographic hashing function* allows to reduce the collision of uuid generated.
- Charaterizedby a hader and payload like packets at IP level

### Unstruncured overlays
In an **unstructured overlay network** peers are arbitrarly connected: the resulting overlay network is unstructured and make use of **look-up algorithms** by flooding the network with queries, expading the ring and use a random walk (*for example, see later*). There are pros like *easy to code/mantain*,*high resiliency* and some cons like **high lookup cost** that usually are linear in n (`n = #nodes`)  due to an absence of centralization autohirty (*like an index in Napster*) and **low scalability**. 
Some example of unstructured network are *Gnutella (v.04), BitTorrent (use DHT) and Bitcoin.*

#### Gnutella: a case of unstructured P2P overlay network
The basic idea is it that propagates the query to the network, **flooding** it: there was no index information used. The connection between peers are defined **at random**: the node that requested the content choose randomly the nodes that have the desired content. The established connection for transfering content is closed after finishing so it's transient, differently from the connections used to query the nodes that are **permanent**. 
Gnutella protocol includes some TTL, representing a constrained on the area of network the query is propagated, limiting the node reacheable from the source: this can cause false negative but it's not reacheable from the requester. 

Some general problem related to P2P network are, for example on **how to boostrap the network** or **how to find content without a central index**.
The first problem on bootstrapping can be solved as pictured:
![[Pasted image 20230224154330.png]]
The image show how a new joining peer can be boostrapped by a third component called **repository** that proivde the peer descriptors: query known DNS servers storing the IP address of a set of stable peers (which are always on the network). It's also widely used an **intenal cache** mechanism in which each client stores the IP address of peers contacted in the current and previous sessions: the cache can be dynamically update by gossiping with neighbour peers to drop addresses of nodes that exited the network. 

Let's deep dive into a **Network Discovery**  for an *unstructured P2P Network* in which the network topology is tipycally random. 

The **Network Discovery** follows those steps:
- **Step 0**: join the network
- **Step 1**: determine “who is on the network” by “ping” message to announce your presence on the network so other peers can respond with a “pong” message and also forward your “ping” to other already connected peers. A pong packet also contains info on the peer sending it, allowing two not-directly connected peers to communicate.
- **Step 2**: after established a connection with a set of peers, the searching is possible by sending a  "*query*"  that asks other peer for some content: an example of a query packet “do you have any content that matches the string “*Back to Black*””?. In unstructured network, the querying is executed by broadcasting, implementing a sort of **flooding**. By receiving the query peers check to see if they have matches and respond (if they have matches), otherwise send packet to connected peers if not to verify if other peers can answer the given query. 
- **Step3**: downloading when the desired resource is founded. The content transfer use **direct connections using HTTP's GET method**. 

The described steps are applied to the following scenario, pictured below: 
![[Pasted image 20230225085817.png]]


The schema refers the *ping-pong* protocol in *Gnutella*. in this schema the *TTL - Time To Live* is used to limit flooding: when TTL is equal to 0 is discarded. 

### Searching by flooding
![[Pasted image 20230301111905.png]]
The connection between the peers (*black one*) are **stable** while the red one is only used for transfer content through an HTTP connection. Finally, the **blue connections** are used to forward query to their neighbours. 
![[Pasted image 20230301112043.png]]
In the upper scenario, red node are searching for red content and yellow node are searching for yellow content: usually there are multiple copies of content for redundancy purpose. 
By **flooding** they are able to detect some of the content they're interested: some of the copies are not finded due to the use of TTL tgat limits the number of nodes to query. 
![[Pasted image 20230301112212.png]]
When the content is found on a node, the protocol allows to implement *backward routing* to the original node that executed the request and carried the information to connect directly to the node and transfer the content. This poses a problem due to *backward routing* mechanism: each node needs to mantain a table and usually an huge number of connesions on the requester (`node S`) is not suitable for scalable networks.
The use of TTL can also result in **false negatives** due to the limit on the number of hops setted by TTL: this also reduce scalability on the entire network. 
So **backward routing** is used to reply messagge through the *non-transient* connections.

Making a parallelism with a *bitcoin transaction*, we have to connect (or we are) a full node (enabled and with the full blockchain data) and to add a transaction, perform the *flooding* to all nodes to propagate this transaction in the P2P net underlying the blockchain.
Many popular P2P network are *unstructued* and use **flooding**: so overlay is used for content detection and use a direct HTTP connection for content download.

### Expanding ring/Iterative deepening
It's a method to avoid TTL to limit and possible not finding the content: the key diea is to use a **sequence of flood with increasing TTL**. Follows those steps:
1. Choose a ratio of the neighbors (*random subset*) or all of them
2. Start a BFS with a low TTL value
3. If the search is not successuffl, repeat BFS at increasing depth by increasing TTL
![[Pasted image 20230301113427.png]]

## Random walk / Drunkard's walk
The key idea is to build a path by taking succesive steps in random directions: the path is described by a *Markov chain* so previous states are irrelevant for predicting the subsequent state. The probability of distribution of the future state is a function of the present state alone. 

Another version if based on sending out **k query message** to an equal number of randomly chosen neighbors: is called **K Random Walk**. Each step follows each own path by choosing one neighboard to forward it and still the TTL s used to stop the search. Each path is called a **walker**. 
![[Pasted image 20230301113813.png]]

The routing is a **content-based routing** so the searching is driven by particular hash data structure (*DHT, see later*). 
There are two main methods to *terminate each walker*:
- Based on TTL
- Checking methods like walkers periodcailly check with the query source if the stop condition has been met. 
There are approaches in which the nodes are not choosen randomly but probabilistic information are used to direct to high degree neighbor: this allows to tune the probability yo choose a neighbor and drive the searching to *good* neighbos (*the one with the desired content*). 

organized s

## Self Organization 
The **Gnutella backbone** showed that a network of server-like nodes emerges from the interactions in Gnutella system. 
![[Pasted image 20230301114602.png]]

# Structured P2P Overlay intro
In this type of overlay network, the choice of neighbors is defined according to a given criteria so the resulting overlay is **structured**.
This approach tends to guarantee scalability: it use a *key-based* loopkup, the network structure guarantees that the lookup of information has a complexity of $log(n)$ and this complxity is also guaranteed for peers joins.


### Hierarchical overlays
We have two different of peers: peers and **super-peers**. The simple peers are connected to super-peers, super-peers are connected each other: they usually have high bandwith and better performance respect to simple peers. Super-peers are used for indexing the resources and usually the flooding is restricted only to them, so too the content trasnfer was limited between super-peers. 
The revolutionary part of this schema in Gnutella and Skype is that the **election** of super peer was automatic: in Gnutella there was a concept of self-promotion, in Skype ultrapeers are statically defined. #TODO page 54?

### Overlay classification summary
![[Pasted image 20230301115346.png]]
In *DHT* the complexities are represented by mantaining the fixed structure, considering also the join/leave of the peers that can give more churn an lose the given fixed structure and the   theoretical cost of operations. 


